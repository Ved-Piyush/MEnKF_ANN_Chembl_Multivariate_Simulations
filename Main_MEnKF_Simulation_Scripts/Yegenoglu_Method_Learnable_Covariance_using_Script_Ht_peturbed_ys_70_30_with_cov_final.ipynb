{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa53e19a-64db-4b1d-9378-c19c8efacd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import block_diag\n",
    "import warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6028973-9799-4d8a-b919-a8dd6283faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d459b853-f520-4181-a9a9-310a6dd20de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, initial_ensembles, size_ens): \n",
    "    \n",
    "    target_dim = 1\n",
    "    \n",
    "    # weights_ann_1 = ann.get_weights()\n",
    "    \n",
    "    # h1  = ann.layers[1].output.shape[-1]\n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "    \n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "    \n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, target_dim)\n",
    "\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + target_dim)].reshape(size_ens, 1, target_dim)\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "    \n",
    "    final_output_1 = final_output_1[:,:, 0]\n",
    "    \n",
    "    # print(final_output_1.shape, initial_ensembles.shape)\n",
    "    \n",
    "    stack = np.hstack((final_output_1, initial_ensembles))\n",
    "\n",
    "    \n",
    "    return final_output_1, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a66ee4c-4112-4dca-a9cc-68a60d4e316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 32, input_shape = 256, output_shape = 1): \n",
    "    input_layer = tf.keras.layers.Input(shape = (input_shape))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(output_shape, activation = \"relu\")\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0b9ef03-af61-4ce4-99ff-2f0b5dca639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_ensembles(num_weights, lambda1, size_ens):\n",
    "    mean_vec = np.zeros((num_weights,))\n",
    "    cov_matrix = lambda1*np.identity(num_weights)\n",
    "    mvn_samp = mvn(mean_vec, cov_matrix)\n",
    "    return mvn_samp.rvs(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe2ea2b5-13a4-41c4-8257-c6c18708501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "758ac30a-bcc7-4b5e-9314-7fb85f284f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_ann =  ann(hidden = 16, input_shape = 32, output_shape = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2548f2de-a4c3-4850-b5cc-439634f5c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ann_1 = samp_ann.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1338dc89-5540-4867-95a6-3d0ea7639cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1  = samp_ann.layers[1].output.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "427b0370-90df-4ab4-85b9-691d082750bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_ann.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06982568-e5c1-4712-895c-7b3d49a09040",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a71c4646-23a6-45ca-9ccc-aa4c3566d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_ann_params = samp_ann.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5f741d7-ba99-4803-8441-5bf2ad3d72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_X_t(data1, data2, size_ens, var_weights = 1.0, var_weight_weights = 4.0):\n",
    "    # samp_ann =  ann(hidden = hidden_neurons, input_shape = 32, output_shape = 1)\n",
    "    \n",
    "    initial_ensembles1 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data1_out1, data1_stack1 = get_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens)\n",
    "    \n",
    "    initial_ensembles2 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data1_out2, data1_stack2 = get_targets_with_weights(data1, initial_ensembles2, size_ens = size_ens)\n",
    "    \n",
    "    initial_ensembles3 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data2_out1, data2_stack1 = get_targets_with_weights(data2, initial_ensembles3, size_ens = size_ens)\n",
    "    \n",
    "    initial_ensembles4 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data2_out2, data2_stack2 = get_targets_with_weights(data2, initial_ensembles4, size_ens = size_ens)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles_for_weights = generate_initial_ensembles(4, var_weight_weights, size_ens)\n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    initial_ensembles_for_L = generate_initial_ensembles(4, var_weights, size_ens)\n",
    "    initial_ensembles_for_L = np.expand_dims(initial_ensembles_for_L,1)    \n",
    "    \n",
    "    initial_ensembles_for_D1 = generate_initial_ensembles(1, var_weights, size_ens).reshape(-1,1)\n",
    "    initial_ensembles_for_D2 = generate_initial_ensembles(1, var_weights, size_ens).reshape(-1,1)\n",
    "    \n",
    "    initial_ensembles_for_D1_zero = np.zeros((size_ens,1,1)).reshape(-1,1)\n",
    "    initial_ensembles_for_D2_zero = np.zeros((size_ens,1,1)).reshape(-1,1)\n",
    "    \n",
    "    initial_ensembles_for_D = np.concatenate((np.expand_dims(initial_ensembles_for_D1,1),\n",
    "                                                       np.expand_dims(initial_ensembles_for_D1_zero,1), \n",
    "                                                      np.expand_dims(initial_ensembles_for_D2,1),\n",
    "                                                       np.expand_dims(initial_ensembles_for_D2_zero,1)), axis = 2)\n",
    "    \n",
    "    # print(X_t.shape, initial_ensembles_for_weights.shape)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D), axis = 1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4))\n",
    "    \n",
    "    return X_t, initial_ensembles, initial_ensembles_for_weights[:,0,:], initial_ensembles_for_L[:,0,:], initial_ensembles_for_D[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ac49c8c-6da0-4ee2-9561-e1d19365f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_targets_with_weights(batch_data, initial_ensembles, size_ens, weights): \n",
    "    \n",
    "    target_dim = 1\n",
    "    \n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "    \n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "    \n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, target_dim)\n",
    "\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + target_dim)].reshape(size_ens, 1, target_dim)\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "    \n",
    "    final_output_1 = final_output_1[:,:, 0]\n",
    "    \n",
    "    final_output_1 = final_output_1*weights\n",
    "    \n",
    "    # print(final_output_1.shape, initial_ensembles.shape)\n",
    "    \n",
    "    stack = np.hstack((final_output_1, initial_ensembles))\n",
    "\n",
    "    \n",
    "    return final_output_1, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b697b7f9-3d50-4d71-a436-cdc6434909a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_targets = pickle.load( open('..//Data//target_scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ace8608-8da1-4b4e-b051-a7b49feae636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_t = np.array([[0.02, 0], [0, 0.02]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d156603a-c127-45b6-a74d-2735987d03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var1 = R_t[0,0]\n",
    "# var2 = R_t[1,1]\n",
    "# cov = R_t[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5a2f9ca-f4b4-445a-ab5f-e0f0557f54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "44ed09c8-f6b0-4b40-86e0-1975541fd0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fudging_beta = beta(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d1a4f5e-7a0d-42b7-ad45-59c708b7b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_operation(data1, data2, combined_ensembles , size_ens, fudging_beta):\n",
    "    # samp_ann =  ann(hidden = hidden_neurons, input_shape = 32, output_shape = 1)\n",
    "    params = samp_ann_params\n",
    "    initial_ensembles1 = combined_ensembles[:, :params]\n",
    "    initial_ensembles2 = combined_ensembles[:, params:(2*params)]\n",
    "    initial_ensembles3 = combined_ensembles[:, (2*params):(3*params)]\n",
    "    initial_ensembles4 = combined_ensembles[:, (3*params):(4*params)]\n",
    "\n",
    "    \n",
    "    initial_ensembles_for_weights = combined_ensembles[:, (4*params):(4*params + 4)]\n",
    "    \n",
    "    initial_ensembles_for_L = combined_ensembles[:, (4*params + 4):(4*params + 4 + 4)]\n",
    "    \n",
    "    initial_ensembles_for_D = combined_ensembles[:,(4*params + 4 + 4):(4*params + 4 + 4 + 4)]\n",
    "    \n",
    "    \n",
    "    softmax_weights = tf.math.softmax(initial_ensembles_for_weights).numpy()\n",
    "    \n",
    "    model_1 = softmax_weights[:, :2].sum(1).reshape(-1,1) +  fudging_beta.rvs(size_ens).reshape(-1,1)\n",
    "    \n",
    "    # model_1 = np.min(model_1 -fudging_factor)\n",
    "    \n",
    "    model_2 = softmax_weights[:, 2:].sum(1).reshape(-1,1) +  fudging_beta.rvs(size_ens).reshape(-1,1)\n",
    "    \n",
    "    \n",
    "    model_1_plus_model_2 = model_1 + model_2\n",
    "    \n",
    "    model_1 = model_1/model_1_plus_model_2\n",
    "    \n",
    "    model_2 = model_2/model_1_plus_model_2\n",
    "    \n",
    "    \n",
    "    # print(np.mean(model_1 + model_2))\n",
    "    \n",
    "    data1_out1, data1_stack1 = get_weighted_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens,\n",
    "                                                                  weights=model_1)\n",
    "    \n",
    "    data1_out2, data1_stack2 = get_weighted_targets_with_weights(data1, initial_ensembles2, size_ens = size_ens,\n",
    "                                                                weights=model_1)\n",
    "    \n",
    "    data2_out1, data2_stack1 = get_weighted_targets_with_weights(data2, initial_ensembles3, size_ens = size_ens,\n",
    "                                                                 weights=model_2)\n",
    "    \n",
    "    data2_out2, data2_stack2 = get_weighted_targets_with_weights(data2, initial_ensembles4, size_ens = size_ens,\n",
    "                                                                  weights=model_2)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4, \n",
    "                        initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D))\n",
    "    \n",
    "    # print(X_t.shape)\n",
    "    \n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    initial_ensembles_for_L = np.expand_dims(initial_ensembles_for_L,1)\n",
    "    \n",
    "    initial_ensembles_for_D = np.expand_dims(initial_ensembles_for_D,1)\n",
    "    \n",
    "    # print(initial_ensembles_for_weights.shape)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D), axis = 1)\n",
    "    \n",
    "    weighted_alogp = data1_out1 + data2_out1\n",
    "    \n",
    "    weighted_psa = data1_out2 + data2_out2\n",
    "    \n",
    "    return X_t, initial_ensembles, weighted_alogp, weighted_psa, model_1, model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c6bd2eb3-86b7-41ed-81b4-4dd8e44e106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_operation_test(data1, data2, combined_ensembles , size_ens):\n",
    "    # samp_ann =  ann(hidden = hidden_neurons, input_shape = 32, output_shape = 1)\n",
    "    params = samp_ann_params\n",
    "    initial_ensembles1 = combined_ensembles[:, :params]\n",
    "    initial_ensembles2 = combined_ensembles[:, params:(2*params)]\n",
    "    initial_ensembles3 = combined_ensembles[:, (2*params):(3*params)]\n",
    "    initial_ensembles4 = combined_ensembles[:, (3*params):(4*params)]\n",
    "\n",
    "    \n",
    "    initial_ensembles_for_weights = combined_ensembles[:, (4*params):(4*params + 4)]\n",
    "    \n",
    "    initial_ensembles_for_L = combined_ensembles[:, (4*params + 4):(4*params + 4 + 4)]\n",
    "    \n",
    "    initial_ensembles_for_D = combined_ensembles[:,(4*params + 4 + 4):(4*params + 4 + 4 + 4)]\n",
    "    \n",
    "    \n",
    "    softmax_weights = tf.math.softmax(initial_ensembles_for_weights).numpy()\n",
    "    \n",
    "    model_1 = softmax_weights[:, :2].sum(1).reshape(-1,1) \n",
    "    \n",
    "    # model_1 = np.min(model_1 -fudging_factor)\n",
    "    \n",
    "    model_2 = softmax_weights[:, 2:].sum(1).reshape(-1,1) \n",
    "    \n",
    "    \n",
    "#     model_1_plus_model_2 = model_1 + model_2\n",
    "    \n",
    "#     model_1 = model_1/model_1_plus_model_2\n",
    "    \n",
    "#     model_2 = model_2/model_1_plus_model_2\n",
    "    \n",
    "    \n",
    "    # print(np.mean(model_1 + model_2))\n",
    "    \n",
    "    data1_out1, data1_stack1 = get_weighted_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens,\n",
    "                                                                  weights=model_1)\n",
    "    \n",
    "    data1_out2, data1_stack2 = get_weighted_targets_with_weights(data1, initial_ensembles2, size_ens = size_ens,\n",
    "                                                                weights=model_1)\n",
    "    \n",
    "    data2_out1, data2_stack1 = get_weighted_targets_with_weights(data2, initial_ensembles3, size_ens = size_ens,\n",
    "                                                                 weights=model_2)\n",
    "    \n",
    "    data2_out2, data2_stack2 = get_weighted_targets_with_weights(data2, initial_ensembles4, size_ens = size_ens,\n",
    "                                                                  weights=model_2)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4, \n",
    "                        initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D))\n",
    "    \n",
    "    # print(X_t.shape)\n",
    "    \n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    initial_ensembles_for_L = np.expand_dims(initial_ensembles_for_L,1)\n",
    "    \n",
    "    initial_ensembles_for_D = np.expand_dims(initial_ensembles_for_D,1)\n",
    "    \n",
    "    # print(initial_ensembles_for_weights.shape)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D), axis = 1)\n",
    "    \n",
    "    weighted_alogp = data1_out1 + data2_out1\n",
    "    \n",
    "    weighted_psa = data1_out2 + data2_out2\n",
    "    \n",
    "    return X_t, initial_ensembles, weighted_alogp, weighted_psa, model_1, model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e15b0bf7-ba00-40bc-933b-c1c3e062e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samp_ann =  ann(hidden = 16, input_shape = 32, output_shape = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af3dd570-7ab3-4eae-bd8e-9a57a333b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = 4*(samp_ann.count_params() + 1 + 1 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e820b010-4396-4b7a-8781-a8e6d503aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e5fbaaf7-afae-4008-a26c-e0691ef9b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = total_weights//reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5111536-1a97-4390-9658-c9848a136a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3f598992-73d6-4b5a-906d-3184f1b9625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_t = [[1, 0, 1, 0], [0, 1, 0, 1]]\n",
    "G_t = np.array(G_t).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a84cb0e3-2f5e-4207-b092-d2768b52205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data1, data2, initial_ensembles, fudging_beta  =fudging_beta): \n",
    "    _,_, weighted_alogp, weighted_psa, w1, w2 = forward_operation(data1, data2, initial_ensembles, size_ens = size_ens, fudging_beta = fudging_beta)\n",
    "    weighted_alogp = np.expand_dims(weighted_alogp,-1)\n",
    "    weighted_psa = np.expand_dims(weighted_psa,-1)\n",
    "    preds = np.concatenate((weighted_alogp, weighted_psa),-1)\n",
    "    return preds, w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "37b60b37-92b1-4784-85fc-59a865d2398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_test(data1, data2, initial_ensembles): \n",
    "    _,_, weighted_alogp, weighted_psa, w1, w2 = forward_operation_test(data1, data2, initial_ensembles, size_ens = size_ens)\n",
    "    weighted_alogp = np.expand_dims(weighted_alogp,-1)\n",
    "    weighted_psa = np.expand_dims(weighted_psa,-1)\n",
    "    preds = np.concatenate((weighted_alogp, weighted_psa),-1)\n",
    "    return preds, w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3af0a9b9-6202-40e2-911f-3c890213099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mu_bar_G_bar(data1, data2, initial_ensembles, fudging_beta):\n",
    "    H_t = np.hstack((np.identity(data1.shape[0]), np.zeros((data1.shape[0], samp_ann_params + 1 + 1 + 1))))\n",
    "    mu_bar = initial_ensembles.mean(0)\n",
    "    X_t,_, _, _, _, _ = forward_operation(data1, data2, initial_ensembles, size_ens = size_ens, fudging_beta = fudging_beta)\n",
    "    X_t = X_t.transpose((0,2,1))\n",
    "    X_t = X_t.reshape(X_t.shape[0], X_t.shape[1]*X_t.shape[2])\n",
    "    script_H_t = np.kron(G_t.T, H_t)\n",
    "    G_u = (script_H_t@X_t.T)\n",
    "    G_u = G_u.T\n",
    "    G_bar = (G_u.mean(0)).ravel()\n",
    "    return mu_bar.reshape(-1,1), G_bar.reshape(-1,1), G_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7334c80c-cfcd-4d5b-b844-11cfb8c137df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_C_u(initial_ensembles, mu_bar, G_bar, G_u): \n",
    "    u_j_minus_u_bar = initial_ensembles - mu_bar.reshape(1,-1)\n",
    "    G_u_minus_G_bar = G_u -  G_bar.reshape(1,-1)\n",
    "    c = np.zeros((total_weights, G_bar.shape[0]))\n",
    "    for i in range(0, size_ens): \n",
    "        c += np.kron(u_j_minus_u_bar[i, :].T.reshape(-1,1), G_u_minus_G_bar[i,:].reshape(-1,1).T)\n",
    "    return c/size_ens, G_u_minus_G_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9148779c-1a3f-455d-a6ad-00fc1bf69c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_D_u( G_bar, G_u): \n",
    "    G_u_minus_G_bar = G_u -  G_bar.reshape(1,-1)\n",
    "    d = np.zeros((G_bar.shape[0], G_bar.shape[0]))\n",
    "    for i in range(0, size_ens): \n",
    "        d += np.kron(G_u_minus_G_bar[i,:].T.reshape(-1,1), G_u_minus_G_bar[i,:].reshape(-1,1).T)\n",
    "    return d/size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6e8459b0-68c1-4d1f-851e-3d7b99f0ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_updated_ensemble(data1, data2, initial_ensembles, y_train, size_ens = size_ens, inflation_factor = 1.0, fudging_beta = fudging_beta):\n",
    "    mu_bar, G_bar, G_u = calculate_mu_bar_G_bar(data1, data2, initial_ensembles, fudging_beta)\n",
    "    C, G_u_minus_G_bar = calculate_C_u(initial_ensembles, mu_bar, G_bar, G_u)\n",
    "    D = calculate_D_u( G_bar, G_u)\n",
    "    _, R_t = create_cov(data1.shape[0],initial_ensembles)\n",
    "    inflation = np.identity(R_t.shape[0])*inflation_factor\n",
    "    D_plus_cov = D + (R_t *inflation_factor)\n",
    "    D_plus_cov_inv = np.linalg.inv(D_plus_cov)\n",
    "    mid_quant = C@D_plus_cov_inv\n",
    "    noise_vec_mean = np.zeros((R_t.shape[0], ))\n",
    "    noise_mvn = mvn(noise_vec_mean, R_t)\n",
    "    fudging = noise_mvn.rvs(size_ens)\n",
    "    interim = (y_train.T.flatten().reshape(1,-1) + fudging)\n",
    "    right_quant = interim - G_u\n",
    "    mid_times_right = mid_quant@right_quant.T\n",
    "    updated_ensemble = (initial_ensembles + mid_times_right.T)\n",
    "    return updated_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c14b236d-6ebf-40e3-9085-97afd2990e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "346d07bc-5b61-4e75-a816-a6e22ffe9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_D = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dc3a216a-4dbb-474d-8219-5f6c071250a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(data, idx):\n",
    "    data_cur = data[idx, :, :]\n",
    "    inv_data_cur = std_targets.inverse_transform(data_cur)\n",
    "    return inv_data_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5abd35fb-ea92-449d-894a-162ed1f4aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "381fc654-8877-41fd-840a-4b35153f923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cov(shape, initial_ensembles):\n",
    "    cov_part = initial_ensembles[:, -8:-4]\n",
    "    cov_part = cov_part.mean(0)\n",
    "    # variances = tf.math.softplus(cov_part[:2]).numpy()\n",
    "    variances = cov_part[:2]\n",
    "    covariances = cov_part[2:]\n",
    "    base_cov = np.identity(target_dim)\n",
    "    base_cov[0,0] = variances[0]\n",
    "    base_cov[1,1] = variances[1]\n",
    "    base_cov[0,1] = covariances[0]\n",
    "    base_cov[1,0] = covariances[1]\n",
    "    \n",
    "    variances1 = tf.math.softplus(initial_ensembles[:, -4:]).numpy()\n",
    "    variances1 = variances1.mean(0)\n",
    "    base_variances = np.identity(target_dim)\n",
    "    base_variances[0,0] = variances1[0]\n",
    "    base_variances[1,1] = variances1[2]\n",
    "    \n",
    "    final = np.linalg.cholesky(base_cov@base_cov.T + base_variances)\n",
    "    cov_mat = final@final.T\n",
    "    cov_mat_final = cov_mat\n",
    "    # cov_mat_final = cov_mat@cov_mat.T\n",
    "    \n",
    "    if is_pos_def(cov_mat_final) != True:\n",
    "        print(\"resulting cov matrix is not positive semi definite\")\n",
    "        pass\n",
    "    \n",
    "    # print(np.linalg.det(cov_mat_final))\n",
    "    \n",
    "    var1 = cov_mat_final[0,0]\n",
    "    var2 = cov_mat_final[1,1]\n",
    "    cov = cov_mat_final[1,0]\n",
    "\n",
    "    n = shape\n",
    "    \n",
    "    ul = var1*np.identity(n)\n",
    "    lr = var2*np.identity(n)\n",
    "    ur = cov*np.identity(n)\n",
    "    ll = ur.T    \n",
    "    \n",
    "    first_row = np.hstack((ul, ur))\n",
    "    second_row = np.hstack((ll, lr))\n",
    "    \n",
    "    R_t = np.vstack((first_row, second_row))\n",
    "    \n",
    "    return cov_mat_final, R_t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "30aea5e4-361f-44ae-9ea3-d1d8743e6ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ed1f9938-cdc5-400f-8bab-22c180a6d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"..//Data//smiles_to_rdkit_70_30_with_cov_minus_0.27_var.pickle\", \"rb\") as f: \n",
    "    catch = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7c59ea29-6484-40d5-8777-80cf9ca6cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "176445fb-4f30-421a-a710-339955111baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(idx, var_weights = 1.0, var_weight_weights = 4.0): \n",
    "    catch_idx = catch[idx]\n",
    "    x_train, x_valid, y_train, y_valid = catch_idx[0], catch_idx[1], catch_idx[2], catch_idx[3]\n",
    "    y_train_actual, y_train = y_train[:,:2], y_train[:,2:]\n",
    "    y_valid_actual, y_valid = y_valid[:,:2], y_valid[:,2:]\n",
    "    smiles_feats_train = x_train[:, :32]\n",
    "    rdkit_feats_train = x_train[:, 32:]\n",
    "    smiles_feats_valid = x_valid[:, :32]\n",
    "    rdkit_feats_valid = x_valid[:, 32:]\n",
    "\n",
    "    X_t, initial_ensembles, initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D = get_initial_X_t(smiles_feats_train, rdkit_feats_train, size_ens = size_ens, var_weights = var_weights, var_weight_weights = var_weight_weights)\n",
    "    initial_ensembles = np.hstack((initial_ensembles, initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D))\n",
    "    \n",
    "    return smiles_feats_train, rdkit_feats_train, smiles_feats_valid, rdkit_feats_valid, y_train, y_train_actual, y_valid, y_valid_actual, initial_ensembles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "82d67093-cbd5-4a2b-bdbc-aa33a082e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smiles_feats_train, rdkit_feats_train, smiles_feats_valid, rdkit_feats_valid, y_train, y_train_actual, y_valid, y_valid_actual, initial_ensembles  = prepare_data(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fa640128-df71-44ec-b20b-6922bdb5b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dc0c894d-db8c-4d88-bd51-ef23ca80fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e5cffacb-8558-45ca-bff9-e803e3fd6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a2e8d41-0775-457c-97a2-4060fd72634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta(1,19).rvs(size_ens).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "65bf21e9-92c6-4824-93c3-87274b072afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(idx, var_weights = 1.0, var_weight_weights = 1.0, inflation_factor = 1.2, fudging_beta = beta(1,19)):\n",
    "    # print('var_weights' + str(var_weights))\n",
    "    # print('inflation_factor' + str(inflation_factor))\n",
    "    # print('var_weight_weights' + str(var_weight_weights))\n",
    "    smiles_feats_train, rdkit_feats_train, smiles_feats_valid, rdkit_feats_valid, y_train, y_train_actual, y_valid, y_valid_actual, initial_ensembles  = prepare_data(idx, var_weights = var_weights, var_weight_weights =var_weight_weights)\n",
    "    # print(R_t.shape)\n",
    "    best_train_width_mean = 100000\n",
    "    \n",
    "    for i in range(0,10000):\n",
    "        # print(i)\n",
    "    \n",
    "        c = np.zeros((2,2))\n",
    "        initial_ensembles = get_updated_ensemble(smiles_feats_train, rdkit_feats_train, initial_ensembles, y_train, size_ens, inflation_factor = inflation_factor, fudging_beta = fudging_beta)\n",
    "        # print(inflation_factor)\n",
    "        G_u_train, w1, w2 = get_predictions(smiles_feats_train, rdkit_feats_train, initial_ensembles, fudging_beta)\n",
    "\n",
    "        catch = Parallel(n_jobs = 15, verbose = 0)(delayed(inverse_transform)(G_u_train, i)  for i in range(G_u_train.shape[0]))\n",
    "        G_u_train = np.array(catch)\n",
    "    \n",
    "        y_train_cur = std_targets.inverse_transform(y_train_actual)\n",
    "    \n",
    "        li_train = np.percentile(G_u_train, axis = 0, q = (2.5, 97.5))[0,:,:]   \n",
    "        ui_train = np.percentile(G_u_train, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "    \n",
    "        width_train = ui_train - li_train\n",
    "        avg_width_train = width_train.mean(0)\n",
    "    \n",
    "        ind_train = (y_train_cur >= li_train) & (y_train_cur <= ui_train)\n",
    "        coverage_train= ind_train.mean(0)\n",
    "    \n",
    "        averaged_targets_train = G_u_train.mean(0)\n",
    "        rmse_train = np.sqrt(((y_train_cur -averaged_targets_train)**2).mean(0))\n",
    "    # print(rmse_train, coverage_train, avg_width_train)\n",
    "    \n",
    "        G_u_test, _, _ = get_predictions_test(smiles_feats_valid, rdkit_feats_valid, initial_ensembles)\n",
    "    \n",
    "        catch = Parallel(n_jobs = 15, verbose = 0)(delayed(inverse_transform)(G_u_test, i)  for i in range(G_u_test.shape[0]))\n",
    "        G_u_test = np.array(catch)\n",
    "    \n",
    "        y_valid_cur = std_targets.inverse_transform(y_valid_actual)    \n",
    "    \n",
    "        li_test = np.percentile(G_u_test, axis = 0, q = (2.5, 97.5))[0,:,:]   \n",
    "        ui_test = np.percentile(G_u_test, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "    \n",
    "        width_test = ui_test - li_test\n",
    "        avg_width_test = width_test.mean(0)\n",
    "    \n",
    "        ind_test = (y_valid_cur >= li_test) & (y_valid_cur <= ui_test)\n",
    "        coverage_test= ind_test.mean(0)\n",
    "    \n",
    "        averaged_targets_test = G_u_test.mean(0)\n",
    "        rmse_test = np.sqrt(((y_valid_cur -averaged_targets_test)**2).mean(0))    \n",
    "    \n",
    "        # weight_norms = np.array(norm(initial_ensembles, ord = 2, axis = 1))\n",
    "        # weight_norm_mean.append(weight_norms.mean())\n",
    "        # weight_norm_sd.append(weight_norms.std())\n",
    "    \n",
    "        cov_mat_final, _ = create_cov(smiles_feats_train.shape[0],initial_ensembles)\n",
    "        \n",
    "        # print(\"standardized_scale_R_t\")\n",
    "        # print(np.diag(cov_mat_final), cov_mat_final[0,1])\n",
    "        \n",
    "        # print(w1.shape)\n",
    "        \n",
    "        li_smiles_weight = np.percentile(w1, axis = 0, q = (2.5, 97.5))[0][0]\n",
    "        \n",
    "        # print(np.percentile(w1, axis = 0, q = (2.5, 97.5)))\n",
    "        \n",
    "        ui_smiles_weight = np.percentile(w1, axis = 0, q = (2.5, 97.5))[1][0]      \n",
    "        \n",
    "        # print(coverage_train.tolist(), avg_width_train.tolist(), rmse_train.tolist())\n",
    "        # print(coverage_test.tolist(), avg_width_test.tolist(), rmse_test.tolist())\n",
    "        # print(w1.mean(), w1.std())\n",
    "        # print(li_smiles_weight, ui_smiles_weight)\n",
    "        # print(avg_width_train.tolist(), coverage_train.tolist(), rmse_train.tolist(), avg_width_test.tolist(), coverage_test.tolist(), rmse_test.tolist(), w1.mean())\n",
    "\n",
    "        if (avg_width_train.mean() < best_train_width_mean) & (coverage_train.mean() > 0.95): \n",
    "            # print(\"went here\")\n",
    "            best_train_width_mean = avg_width_train.mean()\n",
    "            best_train_width = avg_width_train\n",
    "            best_smiles_weight = w1.mean()\n",
    "            best_coverage_train = coverage_train\n",
    "            best_rmse_train = rmse_train\n",
    "        \n",
    "            best_test_width = avg_width_test\n",
    "\n",
    "            best_coverage_test = coverage_test    \n",
    "            best_rmse_test = rmse_test\n",
    "            \n",
    "            best_li_smiles_weight = li_smiles_weight\n",
    "            \n",
    "            best_ui_smiles_weight = ui_smiles_weight\n",
    "    \n",
    "        if coverage_train.mean() < 0.95:\n",
    "            \n",
    "            # print()\n",
    "            # print(best_train_width.tolist(), best_coverage_train.tolist(), best_rmse_train.tolist(), best_test_width.tolist(), best_coverage_test.tolist(), best_rmse_test.tolist(), best_smiles_weight, flush = True)\n",
    "            print(\"done for fold\" + str(idx), flush = True)\n",
    "            print(\"train_width\" + str(best_train_width.tolist()), flush = True)\n",
    "            print(\"test_width\" + str(best_test_width.tolist()), flush = True)\n",
    "            print(\"smiles_weight\" + str(best_smiles_weight), flush = True)\n",
    "            print(\"rmse_train\" + str(best_rmse_train.tolist()), flush = True)\n",
    "            print(\"rmse_test\" + str(best_rmse_test.tolist()), flush = True)\n",
    "            print(\"smiles_weight_ci\" + str([best_li_smiles_weight, best_ui_smiles_weight]), flush = True)\n",
    "            \n",
    "            return [best_train_width.tolist(), best_coverage_train.tolist(), best_rmse_train.tolist(), best_test_width.tolist(), best_coverage_test.tolist(), best_rmse_test.tolist(), best_smiles_weight, best_li_smiles_weight, best_ui_smiles_weight]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "201d8498-7742-4509-94de-4fb1f5d84e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df[results_df[\"indicator\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "14658528-ea1a-4a6f-83bd-f708df0bcd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold45\n",
      "train_width[1.1768901684233888, 21.780142495999254]\n",
      "test_width[0.7814313413999134, 15.899799019630175]\n",
      "smiles_weight0.8082138288620736\n",
      "rmse_train[0.22633814361003401, 4.7246524259256155]\n",
      "rmse_test[0.25983027837722544, 4.832428377708499]\n",
      "smiles_weight_ci[0.6882519053340528, 0.8852767902993528]\n",
      "CPU times: user 3min 12s, sys: 2min 24s, total: 5min 36s\n",
      "Wall time: 1min 30s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1.1768901684233888, 21.780142495999254],\n",
       " [0.9694019471488178, 0.9568845618915159],\n",
       " [0.22633814361003401, 4.7246524259256155],\n",
       " [0.7814313413999134, 15.899799019630175],\n",
       " [0.9208333333333333, 0.9166666666666666],\n",
       " [0.25983027837722544, 4.832428377708499],\n",
       " 0.8082138288620736,\n",
       " 0.6882519053340528,\n",
       " 0.8852767902993528]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_results(45, var_weights = 1.0, var_weight_weights = 2.0, inflation_factor =1.0, fudging_beta = beta(1,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3ac41ba9-2b9e-4b10-b6ad-e415030e40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c0033c73-c13a-492a-8caa-fb16a2d51405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold10\n",
      "train_width[1.383769858105957, 26.70667694807556]\n",
      "test_width[1.1702962251148679, 23.71047411605225]\n",
      "smiles_weight0.722785503716166\n",
      "rmse_train[0.257842306094016, 6.134194283141293]\n",
      "rmse_test[0.25623392180548515, 6.369228967405862]\n",
      "smiles_weight_ci[0.5918996619066429, 0.8007196902192004]\n",
      "done for fold3\n",
      "train_width[1.131138155808941, 25.256141350740307]\n",
      "test_width[0.8828260855358716, 21.260202302716586]\n",
      "smiles_weight0.7603473937206106\n",
      "rmse_train[0.2260089419817095, 6.1626511590900765]\n",
      "rmse_test[0.2661986364001339, 5.944427073476333]\n",
      "smiles_weight_ci[0.6297783235391287, 0.8388915810517905]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:  2.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold14\n",
      "train_width[1.193399030121784, 23.056332692073077]\n",
      "test_width[0.921441051964453, 19.720675924526823]\n",
      "smiles_weight0.765432890399967\n",
      "rmse_train[0.21752952699702724, 4.83551075705332]\n",
      "rmse_test[0.4314010987923803, 11.178773530495858]\n",
      "smiles_weight_ci[0.6263691631414152, 0.8431366291178731]\n",
      "done for fold4\n",
      "train_width[1.233305198288065, 25.311349751425446]\n",
      "test_width[0.9511414787041601, 20.144779125310077]\n",
      "smiles_weight0.734594350184862\n",
      "rmse_train[0.2495899617556342, 5.877236643636227]\n",
      "rmse_test[0.24081019949031393, 5.442407128969248]\n",
      "smiles_weight_ci[0.5963955505972731, 0.8256024754327442]\n",
      "done for fold5\n",
      "train_width[1.1097237368809063, 23.24846146928907]\n",
      "test_width[1.0007183887766697, 22.11367187249369]\n",
      "smiles_weight0.710351938535847\n",
      "rmse_train[0.25654319219499033, 5.5399598436621265]\n",
      "rmse_test[0.7718502122364895, 7.906333606578988]\n",
      "smiles_weight_ci[0.5875140770874827, 0.7972196638331257]\n",
      "done for fold1\n",
      "train_width[1.300792397840385, 22.370514501738423]\n",
      "test_width[0.8832493881883376, 17.64973871797689]\n",
      "smiles_weight0.7660805613760361\n",
      "rmse_train[0.24644877130647438, 5.717386205199213]\n",
      "rmse_test[0.24588829468811438, 5.204644379477605]\n",
      "smiles_weight_ci[0.6329315396488261, 0.8505285301815506]\n",
      "done for fold6\n",
      "train_width[1.1218821104622756, 22.955388813066875]\n",
      "test_width[0.7583838650942312, 18.292248787366137]\n",
      "smiles_weight0.7526394466000835\n",
      "rmse_train[0.2316047248139726, 5.03357895792239]\n",
      "rmse_test[0.19097089851381116, 4.256335579766577]\n",
      "smiles_weight_ci[0.6157767126317489, 0.833303655283156]\n",
      "done for fold2\n",
      "train_width[0.928009699175238, 17.960995848263355]\n",
      "test_width[0.7149196235391775, 15.478349400889268]\n",
      "smiles_weight0.7024898453626781\n",
      "rmse_train[0.19730257566717335, 4.529161939227501]\n",
      "rmse_test[0.12483132595626943, 3.526904090381614]\n",
      "smiles_weight_ci[0.5862200957582456, 0.7889000645921505]\n",
      "done for fold13\n",
      "train_width[1.200687458774546, 22.96469050040094]\n",
      "test_width[0.9520256158751195, 19.07293066818921]\n",
      "smiles_weight0.7081367256198152\n",
      "rmse_train[0.2553695299513271, 4.603502810066758]\n",
      "rmse_test[0.2469154140288074, 4.54301029459702]\n",
      "smiles_weight_ci[0.5867558644492831, 0.7939342637140459]\n",
      "done for fold0\n",
      "train_width[1.08867864158652, 21.295123589637626]\n",
      "test_width[0.7917791606615492, 16.17717371587217]\n",
      "smiles_weight0.755650038353226\n",
      "rmse_train[0.21292971276281517, 5.361182844294615]\n",
      "rmse_test[0.34089437361213587, 14.175548705128381]\n",
      "smiles_weight_ci[0.6289369425789665, 0.8367626810519234]\n",
      "done for fold11\n",
      "train_width[1.0353601395582301, 19.01821648742923]\n",
      "test_width[0.7905683194306479, 16.09954535562248]\n",
      "smiles_weight0.7372117827851142\n",
      "rmse_train[0.23649058636425035, 4.210574471435496]\n",
      "rmse_test[0.18583812276381517, 3.871833060961522]\n",
      "smiles_weight_ci[0.620662565728637, 0.8275260416006408]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  11 tasks      | elapsed:  3.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold12\n",
      "train_width[0.9672371576398279, 19.017440411154702]\n",
      "test_width[0.6996655008715539, 16.252279314094732]\n",
      "smiles_weight0.762485786451626\n",
      "rmse_train[0.21862794205463287, 4.458161611826107]\n",
      "rmse_test[0.2942152366413473, 6.9053779182728645]\n",
      "smiles_weight_ci[0.6489825456046031, 0.8444406555161174]\n",
      "done for fold7\n",
      "train_width[1.0134539875655812, 18.46902621156467]\n",
      "test_width[0.7934724870456946, 16.464674886833286]\n",
      "smiles_weight0.732328851777601\n",
      "rmse_train[0.17975982647132802, 5.648960199009696]\n",
      "rmse_test[0.2954465995984862, 6.757968997954579]\n",
      "smiles_weight_ci[0.6140722761481177, 0.8220292386253257]\n",
      "done for fold8\n",
      "train_width[0.8155897269487488, 17.11280221623901]\n",
      "test_width[0.6634738319105634, 15.95501097443364]\n",
      "smiles_weight0.7420023743556221\n",
      "rmse_train[0.1692896618384954, 4.382509570586058]\n",
      "rmse_test[0.2198836191076287, 4.921364272011749]\n",
      "smiles_weight_ci[0.6284076758421356, 0.81953156634015]\n",
      "done for fold9\n",
      "train_width[0.9127053498288296, 19.41724300131906]\n",
      "test_width[0.5916245284690133, 14.717702397996414]\n",
      "smiles_weight0.74097649450785\n",
      "rmse_train[0.18027420635188987, 4.280563670354839]\n",
      "rmse_test[0.17303033365011883, 4.334307307249644]\n",
      "smiles_weight_ci[0.6224147347647441, 0.8262829198267203]\n",
      "done for fold16\n",
      "train_width[1.7984232538808003, 38.96439431495491]\n",
      "test_width[1.4140328244091447, 34.93299563066068]\n",
      "smiles_weight0.7705799342629722\n",
      "rmse_train[0.5216317471640685, 7.249951460193027]\n",
      "rmse_test[0.3084071226185761, 5.314837643813355]\n",
      "smiles_weight_ci[0.6394953636410642, 0.8538973662466515]\n",
      "done for fold15\n",
      "train_width[1.263136395244328, 23.308736414800016]\n",
      "test_width[0.8659528155285598, 17.87276818788454]\n",
      "smiles_weight0.7753163609326359\n",
      "rmse_train[0.24157251860929718, 5.404586584202962]\n",
      "rmse_test[0.24976376340332984, 4.69519692198642]\n",
      "smiles_weight_ci[0.6434542549479924, 0.8588438776966105]\n",
      "done for fold17\n",
      "train_width[1.0209887745579105, 23.72010482873793]\n",
      "test_width[0.7224007592441632, 18.31876072484714]\n",
      "smiles_weight0.7737380939923163\n",
      "rmse_train[0.1906313073704654, 5.7133871818401545]\n",
      "rmse_test[0.21832500998929955, 5.996333027864372]\n",
      "smiles_weight_ci[0.6489462892383678, 0.8574978689180718]\n",
      "done for fold21\n",
      "train_width[1.203688766034415, 26.8500328841985]\n",
      "test_width[0.8482020365119791, 19.911137414486216]\n",
      "smiles_weight0.7262536482074007\n",
      "rmse_train[0.2797892200504796, 6.806513810417115]\n",
      "rmse_test[0.2215839052916657, 4.442428120237142]\n",
      "smiles_weight_ci[0.5975856405578583, 0.8120045956039966]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:  6.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold18\n",
      "train_width[1.0255355587787167, 17.978169694590715]\n",
      "test_width[0.6297273930984045, 13.094678006862312]\n",
      "smiles_weight0.8031421775314604\n",
      "rmse_train[0.19184763950273948, 4.096748473516895]\n",
      "rmse_test[0.24636196084862008, 3.6470274420505047]\n",
      "smiles_weight_ci[0.6707021218818406, 0.8839173621764638]\n",
      "done for fold20\n",
      "train_width[1.093410034710873, 25.844131650528368]\n",
      "test_width[0.8949781803504886, 21.89702885152485]\n",
      "smiles_weight0.701786969704219\n",
      "rmse_train[0.2515596067785892, 6.585656138973801]\n",
      "rmse_test[0.21503749685657136, 5.496708733798464]\n",
      "smiles_weight_ci[0.5805941864761949, 0.7785573958235862]\n",
      "done for fold25\n",
      "train_width[1.3101949665614618, 23.931823784754886]\n",
      "test_width[0.869483662858647, 16.87877068578701]\n",
      "smiles_weight0.8253763895955214\n",
      "rmse_train[0.2852115605227443, 4.379427435162486]\n",
      "rmse_test[0.7014251164395683, 6.523338240624585]\n",
      "smiles_weight_ci[0.6696913329183231, 0.9033533878605953]\n",
      "done for fold19\n",
      "train_width[0.9161758640105783, 18.78458480333741]\n",
      "test_width[0.7451975180202333, 16.3477882148726]\n",
      "smiles_weight0.689112457624767\n",
      "rmse_train[0.2355944486208237, 4.392049483282309]\n",
      "rmse_test[0.22717925379666443, 3.872318986181686]\n",
      "smiles_weight_ci[0.5769587696008557, 0.7663536241947325]\n",
      "done for fold22\n",
      "train_width[1.0359673799863434, 22.65347836628964]\n",
      "test_width[0.730419029867867, 18.95848726098831]\n",
      "smiles_weight0.7665627159322173\n",
      "rmse_train[0.20537653275921963, 5.1303396446201015]\n",
      "rmse_test[0.20735640578115122, 4.745866875912272]\n",
      "smiles_weight_ci[0.6496455525568616, 0.8511155355859656]\n",
      "done for fold27\n",
      "train_width[1.2155265737128422, 20.968443999966738]\n",
      "test_width[0.7650656592591007, 17.069700064401054]\n",
      "smiles_weight0.813273165313343\n",
      "rmse_train[0.2087259874173344, 5.658341147061023]\n",
      "rmse_test[0.22396150834048936, 6.680547342808719]\n",
      "smiles_weight_ci[0.6850004111526962, 0.9005192648450371]\n",
      "done for fold28\n",
      "train_width[1.147253873196977, 20.38014233399919]\n",
      "test_width[0.7155800349463156, 14.922962658002177]\n",
      "smiles_weight0.8028162015313465\n",
      "rmse_train[0.24292240968626716, 4.742147957573733]\n",
      "rmse_test[0.2236533972924419, 4.540914849134016]\n",
      "smiles_weight_ci[0.6807191140019637, 0.8818794390257844]\n",
      "done for fold23\n",
      "train_width[0.9159547881519862, 17.40281833319262]\n",
      "test_width[0.6424356334855771, 15.206980281144887]\n",
      "smiles_weight0.7961979329129748\n",
      "rmse_train[0.17669296242904325, 4.342988628873193]\n",
      "rmse_test[0.19816811388192496, 4.962161408999119]\n",
      "smiles_weight_ci[0.6868320526186062, 0.868648474062602]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  27 out of  50 | elapsed:  7.2min remaining:  6.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold24\n",
      "train_width[0.7355547199282855, 14.007290316009211]\n",
      "test_width[0.46651112175897563, 10.850178775495376]\n",
      "smiles_weight0.7580051992143725\n",
      "rmse_train[0.14935625309369735, 3.7687785131097717]\n",
      "rmse_test[0.1877624739085207, 3.284207517900468]\n",
      "smiles_weight_ci[0.6373770734998397, 0.832641676720404]\n",
      "done for fold29\n",
      "train_width[0.9390021647846786, 18.858436762473005]\n",
      "test_width[0.6798784457765339, 16.42441914619603]\n",
      "smiles_weight0.7692083912493403\n",
      "rmse_train[0.16069792443679398, 4.435685530713067]\n",
      "rmse_test[0.21635222089595146, 15.214219227979267]\n",
      "smiles_weight_ci[0.6546836452284445, 0.8498767727821674]\n",
      "done for fold30\n",
      "train_width[1.1162859517086676, 23.426754360731486]\n",
      "test_width[0.7503381281989759, 17.58750815641273]\n",
      "smiles_weight0.7689199365429805\n",
      "rmse_train[0.24663333942938534, 4.652510392686731]\n",
      "rmse_test[0.24567291353331236, 4.442502637342233]\n",
      "smiles_weight_ci[0.6454780131803132, 0.8516762504751134]\n",
      "done for fold34\n",
      "train_width[1.4091095788354888, 30.855115430151873]\n",
      "test_width[1.03897383921014, 23.478175359805544]\n",
      "smiles_weight0.7867505910903381\n",
      "rmse_train[0.2871527751614538, 5.889402265276197]\n",
      "rmse_test[0.2982811381958054, 5.942002676939103]\n",
      "smiles_weight_ci[0.66802308585209, 0.8630250316255538]\n",
      "done for fold31\n",
      "train_width[0.9385513228096052, 16.398471833023436]\n",
      "test_width[0.6687938918098028, 13.736561523042635]\n",
      "smiles_weight0.7602164829298982\n",
      "rmse_train[0.1943549240863179, 4.165310633075195]\n",
      "rmse_test[0.1867119403832525, 3.9835308125332927]\n",
      "smiles_weight_ci[0.6477561526379414, 0.8475118137059519]\n",
      "done for fold32\n",
      "train_width[1.1304363274978748, 22.749083703174104]\n",
      "test_width[0.7589904874193857, 17.600295603315434]\n",
      "smiles_weight0.7987904098629799\n",
      "rmse_train[0.21945564932763761, 5.2195588457953725]\n",
      "rmse_test[0.5620332233354849, 4.5205470003815105]\n",
      "smiles_weight_ci[0.6500124449061427, 0.8831912836750391]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  33 out of  50 | elapsed:  9.3min remaining:  4.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold26\n",
      "train_width[0.9727860747139109, 15.612291868467072]\n",
      "test_width[0.4034619623471197, 9.223620947963642]\n",
      "smiles_weight0.8378259318232995\n",
      "rmse_train[0.13459793126561242, 3.3695071746193905]\n",
      "rmse_test[0.25277810292560093, 4.53891502994718]\n",
      "smiles_weight_ci[0.7072618828220528, 0.9034041180676164]\n",
      "done for fold35\n",
      "train_width[1.1770041442713242, 21.204240693590783]\n",
      "test_width[0.8907865029412618, 18.267642160113066]\n",
      "smiles_weight0.7208097893562785\n",
      "rmse_train[0.2286842526550921, 5.020764522927078]\n",
      "rmse_test[0.19996292474741678, 5.26730470865548]\n",
      "smiles_weight_ci[0.6028638793639995, 0.8117339035395609]\n",
      "done for fold39\n",
      "train_width[1.6986903652608483, 35.75172498898063]\n",
      "test_width[1.4537948471502877, 31.402984763264158]\n",
      "smiles_weight0.6903975289190067\n",
      "rmse_train[0.32255999918652106, 7.656626267807969]\n",
      "rmse_test[0.2731170286230813, 7.22935851438235]\n",
      "smiles_weight_ci[0.5698176500725314, 0.7844502639677665]\n",
      "done for fold36\n",
      "train_width[1.3248103585921567, 30.15049099906597]\n",
      "test_width[1.1719722227814615, 28.355005204725934]\n",
      "smiles_weight0.7256831438999083\n",
      "rmse_train[0.29501406529183893, 7.052759286352382]\n",
      "rmse_test[0.5449878095468785, 12.469650034934489]\n",
      "smiles_weight_ci[0.5779294067491675, 0.8194957254736988]\n",
      "done for fold38\n",
      "train_width[0.9251056263950069, 17.408888727416713]\n",
      "test_width[0.6905189168879651, 15.980015300953445]\n",
      "smiles_weight0.7467022807960231\n",
      "rmse_train[0.2493146139821845, 4.132189030217296]\n",
      "rmse_test[0.3057718480911998, 10.462429538245008]\n",
      "smiles_weight_ci[0.6284545382035996, 0.842135896153408]\n",
      "done for fold40\n",
      "train_width[1.025273469600778, 25.043610197146123]\n",
      "test_width[0.920124203898163, 22.61421749394947]\n",
      "smiles_weight0.6108378364423865\n",
      "rmse_train[0.21821021571226587, 4.823339221646616]\n",
      "rmse_test[0.23005724446401662, 5.0199868958361265]\n",
      "smiles_weight_ci[0.5005088419639384, 0.7162400255777849]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  39 out of  50 | elapsed: 10.3min remaining:  2.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold37\n",
      "train_width[0.8509376742406983, 19.146456058476673]\n",
      "test_width[0.6743875495966429, 16.35029637060577]\n",
      "smiles_weight0.7191243829512606\n",
      "rmse_train[0.2059574454620398, 4.8853425778025095]\n",
      "rmse_test[0.26023313873034837, 4.342642848011997]\n",
      "smiles_weight_ci[0.6043610154966433, 0.8136893261890443]\n",
      "done for fold41\n",
      "train_width[1.0108816484936058, 20.73799312241606]\n",
      "test_width[0.7736455902334028, 16.732227365307367]\n",
      "smiles_weight0.7283470392486137\n",
      "rmse_train[0.1790137997500226, 5.071590094894049]\n",
      "rmse_test[0.2134201117953949, 5.225678064397543]\n",
      "smiles_weight_ci[0.6065203012473064, 0.8134661442375807]\n",
      "done for fold44\n",
      "train_width[1.7808179387200673, 38.487986711552686]\n",
      "test_width[1.8111629479886737, 38.63791276133568]\n",
      "smiles_weight0.6202678120708701\n",
      "rmse_train[0.3202632081256564, 8.778254535603335]\n",
      "rmse_test[1.853273719288336, 36.53894944901309]\n",
      "smiles_weight_ci[0.5041108487891021, 0.7140590875963859]\n",
      "done for fold43\n",
      "train_width[1.3436424146903565, 25.898250551181988]\n",
      "test_width[1.0157009442317184, 20.80003797657423]\n",
      "smiles_weight0.698450956722999\n",
      "rmse_train[0.24435254564165468, 6.498658579547639]\n",
      "rmse_test[0.29536255353734464, 7.754133530693638]\n",
      "smiles_weight_ci[0.5730271264520853, 0.7899902327639307]\n",
      "done for fold42\n",
      "train_width[1.1139334400018686, 22.25826056356495]\n",
      "test_width[0.6525241737256787, 15.082011056538573]\n",
      "smiles_weight0.8189119768735166\n",
      "rmse_train[0.2449795154000729, 4.677097732548293]\n",
      "rmse_test[0.3133788186612026, 3.946466423308268]\n",
      "smiles_weight_ci[0.678108129513735, 0.8936723132525557]\n",
      "done for fold33\n",
      "train_width[0.9849159370243972, 15.126662093901484]\n",
      "test_width[0.5809996667877324, 12.044273234068442]\n",
      "smiles_weight0.7865011243428571\n",
      "rmse_train[0.18904121220203676, 4.1710320059050146]\n",
      "rmse_test[0.39470071094713866, 13.28915218688434]\n",
      "smiles_weight_ci[0.6504290038725109, 0.8616714268867499]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  45 out of  50 | elapsed: 10.8min remaining:  1.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold48\n",
      "train_width[1.0845474245344755, 23.38550072922642]\n",
      "test_width[0.7515629106116978, 18.49769663591405]\n",
      "smiles_weight0.7537290174455951\n",
      "rmse_train[0.21931101216837523, 5.912358420210354]\n",
      "rmse_test[0.24232410462948747, 5.808656836587668]\n",
      "smiles_weight_ci[0.624509558537783, 0.835175409317446]\n",
      "done for fold47\n",
      "train_width[1.3595624452164365, 23.319959701476172]\n",
      "test_width[0.9451071024241947, 17.118753740398315]\n",
      "smiles_weight0.8170264981956588\n",
      "rmse_train[0.18327655518198513, 4.970520215693674]\n",
      "rmse_test[0.25465717882491395, 4.250785511329764]\n",
      "smiles_weight_ci[0.6783631695138149, 0.8881797154693055]\n",
      "done for fold45\n",
      "train_width[1.0119630702254458, 18.313373521451712]\n",
      "test_width[0.690238904913027, 14.51333312450441]\n",
      "smiles_weight0.7679207009360155\n",
      "rmse_train[0.21296398756114507, 3.8866964548591825]\n",
      "rmse_test[0.23765227550361098, 4.267008990154959]\n",
      "smiles_weight_ci[0.6337398945135226, 0.8571280677127557]\n",
      "done for fold49\n",
      "train_width[1.2717776774241398, 23.056521984875406]\n",
      "test_width[0.9124338738913609, 18.28139091649684]\n",
      "smiles_weight0.7742475957468401\n",
      "rmse_train[0.23027055886728165, 5.084331033355849]\n",
      "rmse_test[0.7777644671480021, 23.529574491747425]\n",
      "smiles_weight_ci[0.6421555689201388, 0.8604514642167919]\n",
      "done for fold46\n",
      "train_width[1.0446255818598236, 18.784088998479522]\n",
      "test_width[0.7418220725247049, 16.43616578911996]\n",
      "smiles_weight0.7648987989689116\n",
      "rmse_train[0.2311668393431105, 4.852881401948109]\n",
      "rmse_test[0.3015254038690727, 3.900047235425315]\n",
      "smiles_weight_ci[0.6366395052130241, 0.8496381312575495]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  50 out of  50 | elapsed: 11.9min finished\n"
     ]
    }
   ],
   "source": [
    "catch_all = Parallel(n_jobs = 15, verbose = 10)(delayed(get_results)(idx,var_weights = 1.0, var_weight_weights = 2.0, inflation_factor =1.0, fudging_beta = beta(1,11)) for idx in range(0,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1f857358-e5f0-4d43-bf0a-d4d7d034cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3ee2282b-2100-4ed9-972b-ea78eabe2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_all[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "857dc418-a018-4330-868a-47ae36a9f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e456d98-c381-450b-964d-fdbdbd1bd45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_catch = []\n",
    "for item in catch_all:\n",
    "    catch_inner = []\n",
    "    for inner in item:\n",
    "        if type(inner) == list:\n",
    "            for inner1 in inner:\n",
    "                catch_inner.append(inner1)\n",
    "        if type(inner) != list:\n",
    "            catch_inner.append(inner)\n",
    "    all_catch.append(catch_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b17ec0ba-5448-4130-b54f-c8cf20f76128",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(all_catch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "21f8792e-1721-412d-a84e-39bf7ad3c070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 15)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "610306d1-f54e-42be-86c2-70ef6d4fdd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6accc813-8aa7-48a0-abae-f89b6e5f5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.iloc[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "81b223ac-16c3-4547-bb99-9a2e08bbb03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"Alop_Train_Width\", \"PSA_Train_Width\", \"Alop_Train_Coverage\", \"PSA_Train_Coverage\", \n",
    "            \"Alop_Train_RMSE\", \"PSA_Train_RMSE\", \"Alop_Test_Width\", \"PSA_Test_Width\", \"Alop_Test_Coverage\", \"PSA_Test_Coverage\", \n",
    "            \"Alop_Test_RMSE\", \"PSA_Test_RMSE\", \"Smiles_Avg_Weight\", \"Lower_Interval_Smiles_Weight\", \"Upper_Interval_Smiles_Weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1124c374-99bf-4282-9e32-1074a5033ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8e52823b-19de-4bed-ae04-519af1d5021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a4fd350f-4f0a-4f9a-af19-52590d875782",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"indicator\"] = (results_df[\"Lower_Interval_Smiles_Weight\"].values < 0.70) & (results_df[\"Upper_Interval_Smiles_Weight\"].values >= 0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5b5283a6-b5f6-4752-a693-9b1dea85ba9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results_df[\"indicator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b0ebc74a-b0e3-4cb5-8d3f-b2acb6040353",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"width_weight_CI\"] = results_df[\"Upper_Interval_Smiles_Weight\"].values - results_df[\"Lower_Interval_Smiles_Weight\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f36d6343-cfa2-475d-a8dd-01007676f993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alop_Train_Width</td>\n",
       "      <td>1.132644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PSA_Train_Width</td>\n",
       "      <td>22.498574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alop_Train_Coverage</td>\n",
       "      <td>0.963533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PSA_Train_Coverage</td>\n",
       "      <td>0.955271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alop_Train_RMSE</td>\n",
       "      <td>0.230676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PSA_Train_RMSE</td>\n",
       "      <td>5.205049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alop_Test_Width</td>\n",
       "      <td>0.837056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PSA_Test_Width</td>\n",
       "      <td>18.570725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alop_Test_Coverage</td>\n",
       "      <td>0.922917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PSA_Test_Coverage</td>\n",
       "      <td>0.931833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alop_Test_RMSE</td>\n",
       "      <td>0.323468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PSA_Test_RMSE</td>\n",
       "      <td>7.029678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Smiles_Avg_Weight</td>\n",
       "      <td>0.751225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lower_Interval_Smiles_Weight</td>\n",
       "      <td>0.625377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Upper_Interval_Smiles_Weight</td>\n",
       "      <td>0.834958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>indicator</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>width_weight_CI</td>\n",
       "      <td>0.209581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           index          0\n",
       "0               Alop_Train_Width   1.132644\n",
       "1                PSA_Train_Width  22.498574\n",
       "2            Alop_Train_Coverage   0.963533\n",
       "3             PSA_Train_Coverage   0.955271\n",
       "4                Alop_Train_RMSE   0.230676\n",
       "5                 PSA_Train_RMSE   5.205049\n",
       "6                Alop_Test_Width   0.837056\n",
       "7                 PSA_Test_Width  18.570725\n",
       "8             Alop_Test_Coverage   0.922917\n",
       "9              PSA_Test_Coverage   0.931833\n",
       "10                Alop_Test_RMSE   0.323468\n",
       "11                 PSA_Test_RMSE   7.029678\n",
       "12             Smiles_Avg_Weight   0.751225\n",
       "13  Lower_Interval_Smiles_Weight   0.625377\n",
       "14  Upper_Interval_Smiles_Weight   0.834958\n",
       "15                     indicator   0.980000\n",
       "16               width_weight_CI   0.209581"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0636ac66-6077-4a54-9423-542338c64072",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"..//Data//smiles_rdkit_70_30__with_cov_minus_0.27_Simulation_added_beat_noise.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "995e1428-0ed8-4380-a557-ee5d254a5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"..//Data//smiles_rdkit_70_30__with_cov_minus_0.27_Simulation_added_beat_noise.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "851948e2-ff64-43d6-9ebd-bba0107dcfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alop_Train_Width</td>\n",
       "      <td>1.132644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PSA_Train_Width</td>\n",
       "      <td>22.498574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alop_Train_Coverage</td>\n",
       "      <td>0.963533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PSA_Train_Coverage</td>\n",
       "      <td>0.955271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alop_Train_RMSE</td>\n",
       "      <td>0.230676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PSA_Train_RMSE</td>\n",
       "      <td>5.205049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alop_Test_Width</td>\n",
       "      <td>0.837056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PSA_Test_Width</td>\n",
       "      <td>18.570725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alop_Test_Coverage</td>\n",
       "      <td>0.922917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PSA_Test_Coverage</td>\n",
       "      <td>0.931833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alop_Test_RMSE</td>\n",
       "      <td>0.323468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PSA_Test_RMSE</td>\n",
       "      <td>7.029678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Smiles_Avg_Weight</td>\n",
       "      <td>0.751225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lower_Interval_Smiles_Weight</td>\n",
       "      <td>0.625377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Upper_Interval_Smiles_Weight</td>\n",
       "      <td>0.834958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>indicator</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>width_weight_CI</td>\n",
       "      <td>0.209581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           index          0\n",
       "0               Alop_Train_Width   1.132644\n",
       "1                PSA_Train_Width  22.498574\n",
       "2            Alop_Train_Coverage   0.963533\n",
       "3             PSA_Train_Coverage   0.955271\n",
       "4                Alop_Train_RMSE   0.230676\n",
       "5                 PSA_Train_RMSE   5.205049\n",
       "6                Alop_Test_Width   0.837056\n",
       "7                 PSA_Test_Width  18.570725\n",
       "8             Alop_Test_Coverage   0.922917\n",
       "9              PSA_Test_Coverage   0.931833\n",
       "10                Alop_Test_RMSE   0.323468\n",
       "11                 PSA_Test_RMSE   7.029678\n",
       "12             Smiles_Avg_Weight   0.751225\n",
       "13  Lower_Interval_Smiles_Weight   0.625377\n",
       "14  Upper_Interval_Smiles_Weight   0.834958\n",
       "15                     indicator   0.980000\n",
       "16               width_weight_CI   0.209581"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b6a2dba8-e55c-4931-94e5-b50375e7abf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alop_Train_Width</th>\n",
       "      <th>PSA_Train_Width</th>\n",
       "      <th>Alop_Train_Coverage</th>\n",
       "      <th>PSA_Train_Coverage</th>\n",
       "      <th>Alop_Train_RMSE</th>\n",
       "      <th>PSA_Train_RMSE</th>\n",
       "      <th>Alop_Test_Width</th>\n",
       "      <th>PSA_Test_Width</th>\n",
       "      <th>Alop_Test_Coverage</th>\n",
       "      <th>PSA_Test_Coverage</th>\n",
       "      <th>Alop_Test_RMSE</th>\n",
       "      <th>PSA_Test_RMSE</th>\n",
       "      <th>Smiles_Avg_Weight</th>\n",
       "      <th>Lower_Interval_Smiles_Weight</th>\n",
       "      <th>Upper_Interval_Smiles_Weight</th>\n",
       "      <th>indicator</th>\n",
       "      <th>width_weight_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.972786</td>\n",
       "      <td>15.612292</td>\n",
       "      <td>0.956885</td>\n",
       "      <td>0.955494</td>\n",
       "      <td>0.134598</td>\n",
       "      <td>3.369507</td>\n",
       "      <td>0.403462</td>\n",
       "      <td>9.223621</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.252778</td>\n",
       "      <td>4.538915</td>\n",
       "      <td>0.837826</td>\n",
       "      <td>0.707262</td>\n",
       "      <td>0.903404</td>\n",
       "      <td>False</td>\n",
       "      <td>0.196142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Alop_Train_Width  PSA_Train_Width  Alop_Train_Coverage   \n",
       "26          0.972786        15.612292             0.956885  \\\n",
       "\n",
       "    PSA_Train_Coverage  Alop_Train_RMSE  PSA_Train_RMSE  Alop_Test_Width   \n",
       "26            0.955494         0.134598        3.369507         0.403462  \\\n",
       "\n",
       "    PSA_Test_Width  Alop_Test_Coverage  PSA_Test_Coverage  Alop_Test_RMSE   \n",
       "26        9.223621               0.575           0.854167        0.252778  \\\n",
       "\n",
       "    PSA_Test_RMSE  Smiles_Avg_Weight  Lower_Interval_Smiles_Weight   \n",
       "26       4.538915           0.837826                      0.707262  \\\n",
       "\n",
       "    Upper_Interval_Smiles_Weight  indicator  width_weight_CI  \n",
       "26                      0.903404      False         0.196142  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df[\"indicator\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "747d11c8-4f75-4ec9-aacc-930747d74047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5cb7839f-ac6e-4930-85ec-e58da91ec1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
