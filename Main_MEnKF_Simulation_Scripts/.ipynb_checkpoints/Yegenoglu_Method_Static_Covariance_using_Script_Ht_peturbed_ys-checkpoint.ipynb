{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa53e19a-64db-4b1d-9378-c19c8efacd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 21:31:55.752948: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-12 21:31:55.855961: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-12 21:31:55.861717: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :\n",
      "2023-06-12 21:31:55.861734: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-12 21:31:56.743621: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :\n",
      "2023-06-12 21:31:56.745576: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :\n",
      "2023-06-12 21:31:56.745586: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import block_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d459b853-f520-4181-a9a9-310a6dd20de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, initial_ensembles, size_ens, ann): \n",
    "    \n",
    "    target_dim = 1\n",
    "    \n",
    "    weights_ann_1 = ann.get_weights()\n",
    "    \n",
    "    h1  = ann.layers[1].output.shape[-1]\n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "    \n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "    \n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, target_dim)\n",
    "\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + target_dim)].reshape(size_ens, 1, target_dim)\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "    \n",
    "    final_output_1 = final_output_1[:,:, 0]\n",
    "    \n",
    "    # print(final_output_1.shape, initial_ensembles.shape)\n",
    "    \n",
    "    stack = np.hstack((final_output_1, initial_ensembles))\n",
    "\n",
    "    \n",
    "    return final_output_1, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a66ee4c-4112-4dca-a9cc-68a60d4e316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 32, input_shape = 256, output_shape = 1): \n",
    "    input_layer = tf.keras.layers.Input(shape = (input_shape))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(output_shape, activation = \"relu\")\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b9ef03-af61-4ce4-99ff-2f0b5dca639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_ensembles(num_weights, lambda1, size_ens):\n",
    "    mean_vec = np.zeros((num_weights,))\n",
    "    cov_matrix = lambda1*np.identity(num_weights)\n",
    "    mvn_samp = mvn(mean_vec, cov_matrix)\n",
    "    return mvn_samp.rvs(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe2ea2b5-13a4-41c4-8257-c6c18708501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f741d7-ba99-4803-8441-5bf2ad3d72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_X_t(data1, data2, size_ens, var_weights = 1.0):\n",
    "    samp_ann =  ann(hidden = 16, input_shape = 32, output_shape = 1)\n",
    "    \n",
    "    initial_ensembles1 = generate_initial_ensembles(samp_ann.count_params(), var_weights, size_ens)\n",
    "    data1_out1, data1_stack1 = get_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens, ann = samp_ann)\n",
    "    \n",
    "    initial_ensembles2 = generate_initial_ensembles(samp_ann.count_params(), var_weights, size_ens)\n",
    "    data1_out2, data1_stack2 = get_targets_with_weights(data1, initial_ensembles2, size_ens = size_ens, ann = samp_ann)\n",
    "    \n",
    "    initial_ensembles3 = generate_initial_ensembles(samp_ann.count_params(), var_weights, size_ens)\n",
    "    data2_out1, data2_stack1 = get_targets_with_weights(data2, initial_ensembles3, size_ens = size_ens, ann = samp_ann)\n",
    "    \n",
    "    initial_ensembles4 = generate_initial_ensembles(samp_ann.count_params(), var_weights, size_ens)\n",
    "    data2_out2, data2_stack2 = get_targets_with_weights(data2, initial_ensembles4, size_ens = size_ens, ann = samp_ann)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles_for_weights = generate_initial_ensembles(4, var_weights, size_ens)\n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    # print(X_t.shape, initial_ensembles_for_weights.shape)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights), axis = 1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4))\n",
    "    \n",
    "    return X_t, initial_ensembles, initial_ensembles_for_weights[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ac49c8c-6da0-4ee2-9561-e1d19365f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_targets_with_weights(batch_data, initial_ensembles, size_ens, ann, weights): \n",
    "    \n",
    "    target_dim = 1\n",
    "    \n",
    "    weights_ann_1 = ann.get_weights()\n",
    "    \n",
    "    h1  = ann.layers[1].output.shape[-1]\n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "    \n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "    \n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, target_dim)\n",
    "\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + target_dim)].reshape(size_ens, 1, target_dim)\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "    \n",
    "    final_output_1 = final_output_1[:,:, 0]\n",
    "    \n",
    "    final_output_1 = final_output_1*weights\n",
    "    \n",
    "    # print(final_output_1.shape, initial_ensembles.shape)\n",
    "    \n",
    "    stack = np.hstack((final_output_1, initial_ensembles))\n",
    "\n",
    "    \n",
    "    return final_output_1, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f382d3e-e4dc-4e19-b19a-0eb954236a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "alogp_bottleneck = np.load(\"..//Data/small_mol_phase_3_features_for_both.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4040341b-910b-4ed1-82b3-d40b70377ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alogp_bottleneck.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ccbcd4-20bd-4772-ac63-3aaef7ab95d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ec5c569-3901-4cb8-830a-eaafe50773f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = pd.read_csv(\"..//Data/smiles_with_rdkit_with_small_phase_3_outputs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1856cf5b-a6dd-47db-8bc3-71a4ff0c38be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlogP                  2.690962\n",
       "Polar Surface Area    54.234785\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(((y_valid.iloc[:,1:] - y_valid.iloc[:,1:].mean())**2).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94e5e3f5-e4c6-40f8-ac40-b487543e3711",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = np.load('..//Data/smiles_0.7_rdkit_0.3_signal_plus_noise.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "610b3fd1-b671-450c-b10e-c53f5f7be9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58f65e89-1b5e-4523-b017-18f2c9528c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_actual = np.load('..//Data/smiles_0.7_rdkit_0.3_signal.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de38304b-6569-4387-8868-0837b195e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b697b7f9-3d50-4d71-a436-cdc6434909a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/statgrads/vpiyush2/.conda/envs/enkf/lib/python3.10/site-packages/sklearn/base.py:288: UserWarning: Trying to unpickle estimator StandardScaler from version 1.1.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "std_targets = pickle.load( open('..//Data//target_scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40aa1581-02a9-4c7f-a348-db236a77f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e24a5b32-00d0-43ef-b90f-22bae80e1ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f03ac14e-aa06-4dd8-b3df-82ead28d70bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_actual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ad7f00f-1bd3-40bc-b50b-de0406c72655",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.hstack((y_valid, y_valid_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e148e85d-73c5-4850-bade-41a44a07935f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb75273a-25fe-492a-9fd4-6ea577e9eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_full = pd.read_csv(\"..//Data//y_train.csv\")\n",
    "# y_train_full = std_targets.transform(y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f872f1c-9dfa-4c53-95d9-c0ababa4e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_full_transform = std_targets.transform(y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ece24dc0-fbd4-46a8-b914-13785da70993",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_t = np.cov(y_train_full_transform.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f688646b-78e9-467e-ba33-b7e116aef914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000059, -0.30301738],\n",
       "       [-0.30301738,  1.00000059]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dfffa08-081b-4b5f-8181-ae94a920c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f03896e4-b7c8-4237-a0a8-7af9ed6b1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(alogp_bottleneck, y_train, test_size = 0.25, shuffle = True, \n",
    "                                                     random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2ed02ca-e8a1-4767-8152-4fc17b1afe61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(719, 64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f280aca8-2cb4-42cf-87a3-600d117e7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_train_actual = y_train[:,:2], y_train[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83a78adf-0d01-4162-9613-4001e729cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid, y_valid_actual = y_valid[:,:2], y_valid[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8660cfe1-5d14-4e88-b5ae-f5d39ec41932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_t = np.cov(y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2ea7e9a-2c5f-4603-984c-4acd309fb581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d156603a-c127-45b6-a74d-2735987d03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = R_t[0,0]\n",
    "var2 = R_t[1,1]\n",
    "cov = R_t[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb69be39-625e-4a08-9bec-90a6d312df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ul = var1*np.identity(x_train.shape[0])\n",
    "lr = var2*np.identity(x_train.shape[0])\n",
    "ur = cov*np.identity(x_train.shape[0])\n",
    "ll = ur.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67930509-5afb-458b-90a6-a9bc5b1cb94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = np.hstack((ul, ur))\n",
    "second_row = np.hstack((ll, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "534f2539-a9e7-4ab2-b84b-fcecf628d473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(719, 1438)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a9541bb-5cf5-4adb-baa8-69965781f7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(719, 1438)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63e35567-c2b7-4e1f-9eae-9bbb1ccfd3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_t = np.vstack((first_row, second_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c29b851-3a1f-4d4a-a15a-e8b6bffd6de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1438, 1438)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b98c57b-e85d-46f9-92b4-09f2a1b179a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_feats_train = x_train[:, :32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b91f4be-60b4-44ee-b992-80da2cbe5395",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdkit_feats_train = x_train[:, 32:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dfe0b04f-b7c9-4f72-ac4b-4ba7e50d128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_feats_valid = x_valid[:, :32]\n",
    "rdkit_feats_valid = x_valid[:, 32:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d1a4f5e-7a0d-42b7-ad45-59c708b7b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_operation(data1, data2, combined_ensembles , size_ens ):\n",
    "    samp_ann =  ann(hidden = 16, input_shape = 32, output_shape = 1)\n",
    "    params = samp_ann.count_params()\n",
    "    initial_ensembles1 = combined_ensembles[:, :params]\n",
    "    initial_ensembles2 = combined_ensembles[:, params:(2*params)]\n",
    "    initial_ensembles3 = combined_ensembles[:, (2*params):(3*params)]\n",
    "    initial_ensembles4 = combined_ensembles[:, (3*params):(4*params)]\n",
    "\n",
    "    \n",
    "    initial_ensembles_for_weights = combined_ensembles[:, (4*params):]\n",
    "    softmax_weights = tf.math.softmax(initial_ensembles_for_weights).numpy()\n",
    "    \n",
    "    model_1 = softmax_weights[:,:2].sum(1).reshape(-1,1)\n",
    "    \n",
    "    model_2 = softmax_weights[:,2:].sum(1).reshape(-1,1)\n",
    "    \n",
    "    data1_out1, data1_stack1 = get_weighted_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens,\n",
    "                                                                 ann = samp_ann, weights=model_1)\n",
    "    \n",
    "    data1_out2, data1_stack2 = get_weighted_targets_with_weights(data1, initial_ensembles2, size_ens = size_ens,\n",
    "                                                                 ann = samp_ann, weights=model_1)\n",
    "    \n",
    "    data2_out1, data2_stack1 = get_weighted_targets_with_weights(data2, initial_ensembles3, size_ens = size_ens,\n",
    "                                                                 ann = samp_ann, weights=model_2)\n",
    "    \n",
    "    data2_out2, data2_stack2 = get_weighted_targets_with_weights(data2, initial_ensembles4, size_ens = size_ens,\n",
    "                                                                 ann = samp_ann, weights=model_2)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4, \n",
    "                        initial_ensembles_for_weights))\n",
    "    \n",
    "    # print(X_t.shape)\n",
    "    \n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    # print(initial_ensembles_for_weights.shape)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights), axis = 1)\n",
    "    \n",
    "    weighted_alogp = data1_out1 + data2_out1\n",
    "    \n",
    "    weighted_psa = data1_out2 + data2_out2\n",
    "    \n",
    "    return X_t, initial_ensembles, weighted_alogp, weighted_psa, model_1, model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e15b0bf7-ba00-40bc-933b-c1c3e062e98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 21:31:58.690635: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :\n",
      "2023-06-12 21:31:58.690660: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-12 21:31:58.690674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (c2518.crane.hcc.unl.edu): /proc/driver/nvidia/version does not exist\n",
      "2023-06-12 21:31:58.690866: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "samp_ann =  ann(hidden = 16, input_shape = 32, output_shape = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af3dd570-7ab3-4eae-bd8e-9a57a333b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = samp_ann.count_params()*4 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e820b010-4396-4b7a-8781-a8e6d503aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5fbaaf7-afae-4008-a26c-e0691ef9b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = total_weights//reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5111536-1a97-4390-9658-c9848a136a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dad93ee9-a527-4663-9e18-d72039909c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t, initial_ensembles, initial_ensembles_for_weights = get_initial_X_t(smiles_feats_train, rdkit_feats_train, size_ens = size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9c1bbad1-127a-4c27-8fb9-23783b072a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ensembles = np.hstack((initial_ensembles, initial_ensembles_for_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f598992-73d6-4b5a-906d-3184f1b9625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_t = [[1, 0, 1, 0], [0, 1, 0, 1]]\n",
    "G_t = np.array(G_t).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3073d2ce-5b22-47bb-80a3-9ad86ac3d6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a84cb0e3-2f5e-4207-b092-d2768b52205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data1, data2, initial_ensembles): \n",
    "    _,_, weighted_alogp, weighted_psa, w1, w2 = forward_operation(data1, data2, initial_ensembles, size_ens = size_ens)\n",
    "    weighted_alogp = np.expand_dims(weighted_alogp,-1)\n",
    "    weighted_psa = np.expand_dims(weighted_psa,-1)\n",
    "    preds = np.concatenate((weighted_alogp, weighted_psa),-1)\n",
    "    return preds, w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3af0a9b9-6202-40e2-911f-3c890213099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mu_bar_G_bar(data1, data2, initial_ensembles):\n",
    "    H_t = np.hstack((np.identity(data1.shape[0]), np.zeros((data1.shape[0], samp_ann.count_params() + 1))))\n",
    "    mu_bar = initial_ensembles.mean(0)\n",
    "    X_t,_, _, _, _, _ = forward_operation(data1, data2, initial_ensembles, size_ens = size_ens)\n",
    "    X_t = X_t.transpose((0,2,1))\n",
    "    X_t = X_t.reshape(X_t.shape[0], X_t.shape[1]*X_t.shape[2])\n",
    "    script_H_t = np.kron(G_t.T, H_t)\n",
    "    G_u = (script_H_t@X_t.T)\n",
    "    G_u = G_u.T\n",
    "    G_bar = (G_u.mean(0)).ravel()\n",
    "    return mu_bar.reshape(-1,1), G_bar.reshape(-1,1), G_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7334c80c-cfcd-4d5b-b844-11cfb8c137df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_C_u(initial_ensembles, mu_bar, G_bar, G_u): \n",
    "    u_j_minus_u_bar = initial_ensembles - mu_bar.reshape(1,-1)\n",
    "    G_u_minus_G_bar = G_u -  G_bar.reshape(1,-1)\n",
    "    c = np.zeros((total_weights, G_bar.shape[0]))\n",
    "    for i in range(0, size_ens): \n",
    "        c += np.kron(u_j_minus_u_bar[i, :].T.reshape(-1,1), G_u_minus_G_bar[i,:].reshape(-1,1).T)\n",
    "    return c/size_ens, G_u_minus_G_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9148779c-1a3f-455d-a6ad-00fc1bf69c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_D_u( G_bar, G_u): \n",
    "    G_u_minus_G_bar = G_u -  G_bar.reshape(1,-1)\n",
    "    d = np.zeros((G_bar.shape[0], G_bar.shape[0]))\n",
    "    for i in range(0, size_ens): \n",
    "        d += np.kron(G_u_minus_G_bar[i,:].T.reshape(-1,1), G_u_minus_G_bar[i,:].reshape(-1,1).T)\n",
    "    return d/size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e8459b0-68c1-4d1f-851e-3d7b99f0ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_updated_ensemble(data1, data2, initial_ensembles, size_ens = size_ens, inflation_factor = 1.02):\n",
    "    mu_bar, G_bar, G_u = calculate_mu_bar_G_bar(data1, data2, initial_ensembles)\n",
    "    C, G_u_minus_G_bar = calculate_C_u(initial_ensembles, mu_bar, G_bar, G_u)\n",
    "    D = calculate_D_u( G_bar, G_u)\n",
    "    # _, R_t = create_cov(data1.shape[0],initial_ensembles)\n",
    "    # all_covs = np.array(all_covs)\n",
    "    inflation = np.identity(R_t.shape[0])*inflation_factor\n",
    "    D_plus_cov = D + (R_t *inflation_factor)\n",
    "    D_plus_cov_inv = np.linalg.inv(D_plus_cov)\n",
    "    mid_quant = C@D_plus_cov_inv\n",
    "    noise_vec_mean = np.zeros((R_t.shape[0], ))\n",
    "    noise_mvn = mvn(noise_vec_mean, R_t)\n",
    "    fudging = noise_mvn.rvs(size_ens)\n",
    "    interim = (y_train.T.flatten().reshape(1,-1) + fudging)\n",
    "    right_quant = interim - G_u\n",
    "    # print(mid_quant.shape, right_quant.shape)\n",
    "    mid_times_right = mid_quant@right_quant.T\n",
    "    updated_ensemble = (initial_ensembles + mid_times_right.T)\n",
    "    return updated_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c14b236d-6ebf-40e3-9085-97afd2990e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "346d07bc-5b61-4e75-a816-a6e22ffe9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_D = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc3a216a-4dbb-474d-8219-5f6c071250a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(data, idx):\n",
    "    data_cur = data[idx, :, :]\n",
    "    inv_data_cur = std_targets.inverse_transform(data_cur)\n",
    "    return inv_data_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5abd35fb-ea92-449d-894a-162ed1f4aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bf21e9-92c6-4824-93c3-87274b072afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5557693296043877, 0.18819909589029235]\n",
      "[ 2.95620194 77.74091529] [1. 1.] [  88.59076873 2049.52155638]\n",
      "[ 2.24238792 72.32664916] [1. 1.] [  88.44222162 2028.68107386]\n",
      "[0.607140568450584, 0.15223947755334757]\n",
      "[ 2.50629915 40.14037782] [1. 1.] [  57.33286934 1228.54456706]\n",
      "[ 2.09565917 37.92861338] [1. 1.] [  56.70959498 1217.37281817]\n",
      "[0.6132935922716222, 0.12948962889659085]\n",
      "[ 1.66929276 39.71466258] [1. 1.] [ 41.64673612 913.12921657]\n",
      "[ 1.3693206  35.31480238] [1. 1.] [ 41.52224419 904.90605339]\n",
      "[0.629065496269045, 0.11046336564520817]\n",
      "[ 1.73803029 35.72476084] [1. 1.] [ 32.6008677 674.0642341]\n",
      "[ 1.53590875 31.45236286] [1. 1.] [ 32.34683112 664.80818299]\n",
      "[0.6669729706470664, 0.09425972874675698]\n",
      "[ 1.59630734 34.89358734] [1. 1.] [ 21.37879881 500.53254476]\n",
      "[ 1.5019889  31.71997876] [1. 1.] [ 21.1921768  491.15782294]\n",
      "[0.6616142056502576, 0.08691381558089438]\n",
      "[ 2.3984956  36.62396722] [1. 1.] [ 17.21982491 408.44031581]\n",
      "[ 2.29505946 33.85781055] [1. 1.] [ 17.19546278 402.68353886]\n",
      "[0.701292758305756, 0.07152227139090332]\n",
      "[ 2.67318309 22.698193  ] [1. 1.] [ 11.99663766 282.82813463]\n",
      "[ 2.52074598 20.98216374] [1. 1.] [ 11.86850361 277.60127893]\n",
      "[0.7287896099704692, 0.0601578806462824]\n",
      "[ 1.78692342 23.31114461] [1. 1.] [  7.41214074 190.79576969]\n",
      "[ 1.67370475 21.2475775 ] [1. 1.] [  7.38716608 188.12207979]\n",
      "[0.7504125494174781, 0.048789245683556484]\n",
      "[ 1.4023307  12.43614358] [1. 1.] [  5.42136165 128.00593964]\n",
      "[ 1.25383377 11.8405872 ] [1. 1.] [  5.4381416  125.96162156]\n",
      "[0.7453631910554502, 0.03939228505902237]\n",
      "[ 1.11744966 10.59985757] [0.99165508 1.        ] [ 3.81168848 88.75134158]\n",
      "[ 0.92067654 10.20522525] [0.99166667 1.        ] [ 3.81494586 88.41745176]\n",
      "[0.7444613948559794, 0.03454991194030704]\n",
      "[0.74065162 9.5949607 ] [0.97774687 0.99582754] [ 2.65781899 61.80965135]\n",
      "[0.57678818 8.75092739] [0.98333333 1.        ] [ 2.64271277 61.68991478]\n",
      "[0.7265526008383202, 0.033571124378608715]\n",
      "[ 0.48391053 10.2738335 ] [0.97635605 0.98748261] [ 2.08274904 49.61896268]\n",
      "[0.40011452 9.64740792] [0.975      0.99583333] [ 2.07316745 49.72793663]\n",
      "[0.7250087712207542, 0.030155591267818752]\n",
      "[ 0.4101076  10.93717149] [0.93602225 0.945758  ] [ 1.54642233 37.09162528]\n",
      "[ 0.38068047 10.46403024] [0.94166667 0.96666667] [ 1.55146185 37.18029009]\n",
      "[0.7231097174971511, 0.027648890645977333]\n",
      "[ 0.4121242  10.03501855] [0.86230876 0.88317107] [ 1.24402311 28.84076457]\n",
      "[0.39611947 9.65730613] [0.88333333 0.93333333] [ 1.24658796 28.84073479]\n",
      "[0.7227149616674707, 0.025348004754950634]\n",
      "[ 0.42807543 10.24715285] [0.7635605  0.79972184] [ 1.01022366 23.6703404 ]\n",
      "[0.40673874 9.91134424] [0.775      0.85833333] [ 1.02240126 23.90964125]\n",
      "[0.7182650350379172, 0.024222237647796695]\n",
      "[ 0.42837897 10.25903929] [0.69123783 0.70653686] [ 0.85904961 20.31688597]\n",
      "[ 0.40523876 10.0009276 ] [0.7        0.72916667] [ 0.86511683 20.40481478]\n"
     ]
    }
   ],
   "source": [
    "w1_catch = []\n",
    "w2_catch = []\n",
    "w1_sd_catch = []\n",
    "w2_sd_catch = []\n",
    "for i in range(0,10000):\n",
    "    \n",
    "    initial_ensembles = get_updated_ensemble(smiles_feats_train, rdkit_feats_train, initial_ensembles)\n",
    "    G_u_train, w1, w2 = get_predictions(smiles_feats_train, rdkit_feats_train, initial_ensembles)\n",
    "    \n",
    "    w1_catch.append(w1.mean())\n",
    "    w1_sd_catch.append(w1.std())\n",
    "    \n",
    "    w2_catch.append(w2.mean())\n",
    "    w2_sd_catch.append(w2.std())  \n",
    "    \n",
    "    print([w1.mean(), w1.std()])\n",
    "    # print(w2.mean(), w2.std())\n",
    "    \n",
    "    # G_u_train = get_targets_with_weights(smiles_feats_train, rdkit_feats_train, initial_ensembles, size_ens = size_ens)\n",
    "    catch = Parallel(n_jobs = 15, verbose = 0)(delayed(inverse_transform)(G_u_train, i)  for i in range(G_u_train.shape[0]))\n",
    "    G_u_train = np.array(catch)\n",
    "    \n",
    "    y_train_cur = std_targets.inverse_transform(y_train_actual)\n",
    "    \n",
    "    li_train = np.percentile(G_u_train, axis = 0, q = (2.5, 97.5))[0,:,:]   \n",
    "    ui_train = np.percentile(G_u_train, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "    \n",
    "    width_train = ui_train - li_train\n",
    "    avg_width_train = width_train.mean(0)\n",
    "    \n",
    "    ind_train = (y_train_cur >= li_train) & (y_train_cur <= ui_train)\n",
    "    coverage_train= ind_train.mean(0)\n",
    "    \n",
    "    averaged_targets_train = G_u_train.mean(0)\n",
    "    rmse_train = np.sqrt(((y_train_cur -averaged_targets_train)**2).mean(0))\n",
    "    # print(rmse_train, coverage_train, avg_width_train)\n",
    "    \n",
    "    G_u_test, _, _ = get_predictions(smiles_feats_valid, rdkit_feats_valid, initial_ensembles)\n",
    "    \n",
    "    catch = Parallel(n_jobs = 15, verbose = 0)(delayed(inverse_transform)(G_u_test, i)  for i in range(G_u_test.shape[0]))\n",
    "    G_u_test = np.array(catch)\n",
    "    \n",
    "    y_valid_cur = std_targets.inverse_transform(y_valid_actual)    \n",
    "    \n",
    "    li_test = np.percentile(G_u_test, axis = 0, q = (2.5, 97.5))[0,:,:]   \n",
    "    ui_test = np.percentile(G_u_test, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "    \n",
    "    width_test = ui_test - li_test\n",
    "    avg_width_test = width_test.mean(0)\n",
    "    \n",
    "    ind_test = (y_valid_cur >= li_test) & (y_valid_cur <= ui_test)\n",
    "    coverage_test= ind_test.mean(0)\n",
    "    \n",
    "    averaged_targets_test = G_u_test.mean(0)\n",
    "    rmse_test = np.sqrt(((y_valid_cur -averaged_targets_test)**2).mean(0))    \n",
    "    \n",
    "#     plt.scatter(y_valid_cur[:, 0], averaged_targets_test[:,0])\n",
    "#     plt.axline((0,0), slope = 1, c= \"black\")\n",
    "#     plt.show()\n",
    "    \n",
    "#     plt.scatter(y_valid_cur[:,1], averaged_targets_test[:, 1])\n",
    "#     plt.axline((0,0), slope = 1, c= \"black\")\n",
    "#     plt.show()\n",
    "    \n",
    "    # if coverage_train.mean() < 0.95:\n",
    "    #     break\n",
    "    print(rmse_train, coverage_train, avg_width_train)\n",
    "    print(rmse_test, coverage_test, avg_width_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81eb6c3-e084-4e43-aa5e-3f9b0f5ee016",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_u_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8df43-9ae3-47f6-9c69-ac77c38a6eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47207771-df91-48f0-9963-9a78989bcfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = random.sample(range(y_valid_cur.shape[0]), k = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f17ea-a47c-421d-bd32-7a0dc0f1af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(8, 2,figsize=(15, 15))\n",
    "# axs = axs.ravel()\n",
    "# counter = 0\n",
    "for idx, i in enumerate(random_idx):\n",
    "    # print(counter)\n",
    "    truth = y_valid_cur[i,:]\n",
    "    preds = G_u_test[:, i,:]\n",
    "    percts = np.percentile(preds, axis = 0, q = (2.5, 97.5))\n",
    "    lis = percts[0,:]\n",
    "    uis = percts[1,:]\n",
    "    \n",
    "    \n",
    "    axs[idx, 0].hist(preds[:,0])\n",
    "    axs[idx, 0].axvline(truth[0], color='green', linewidth=2)\n",
    "    axs[idx, 0].axvline(lis[0], color='red', linewidth=2)\n",
    "    axs[idx, 0].axvline(uis[0], color='red', linewidth=2)\n",
    "    \n",
    "    axs[idx, 1].hist(preds[:,1])\n",
    "    axs[idx, 1].axvline(truth[1], color='green', linewidth=2)\n",
    "    axs[idx, 1].axvline(lis[1], color='red', linewidth=2)\n",
    "    axs[idx, 1].axvline(uis[1], color='red', linewidth=2)\n",
    "    \n",
    "    # counter+=2\n",
    "    # print(counter)\n",
    "    \n",
    "    # plt.show()\n",
    "plt.savefig('prediction_intervals.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3230a62b-f36f-4ec0-9c7d-0ba75c9de369",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_valid_cur[:, 0], averaged_targets_test[:,0])\n",
    "plt.axline((0,0), slope = 1, c= \"black\")\n",
    "plt.show()\n",
    "plt.scatter(y_valid_cur[:,1], averaged_targets_test[:, 1])\n",
    "plt.axline((0,0), slope = 1, c= \"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a36715c-20fa-406e-9ac6-55a56152d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(range(0, len(w1_catch)), w1_catch, w1_sd_catch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
