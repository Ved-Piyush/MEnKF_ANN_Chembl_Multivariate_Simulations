{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa53e19a-64db-4b1d-9378-c19c8efacd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 00:25:33.257224: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-16 00:25:33.259618: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-16 00:25:33.297275: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-16 00:25:33.298066: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-16 00:25:34.419459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import block_diag\n",
    "import warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6028973-9799-4d8a-b919-a8dd6283faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d459b853-f520-4181-a9a9-310a6dd20de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, initial_ensembles, size_ens): \n",
    "    \n",
    "    target_dim = 1\n",
    "    \n",
    "    # weights_ann_1 = ann.get_weights()\n",
    "    \n",
    "    # h1  = ann.layers[1].output.shape[-1]\n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "    \n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "    \n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, target_dim)\n",
    "\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + target_dim)].reshape(size_ens, 1, target_dim)\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "    \n",
    "    final_output_1 = final_output_1[:,:, 0]\n",
    "    \n",
    "    # print(final_output_1.shape, initial_ensembles.shape)\n",
    "    \n",
    "    stack = np.hstack((final_output_1, initial_ensembles))\n",
    "\n",
    "    \n",
    "    return final_output_1, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a66ee4c-4112-4dca-a9cc-68a60d4e316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 32, input_shape = 256, output_shape = 1): \n",
    "    input_layer = tf.keras.layers.Input(shape = (input_shape))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(output_shape, activation = \"relu\")\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0b9ef03-af61-4ce4-99ff-2f0b5dca639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_ensembles(num_weights, lambda1, size_ens):\n",
    "    mean_vec = np.zeros((num_weights,))\n",
    "    cov_matrix = lambda1*np.identity(num_weights)\n",
    "    mvn_samp = mvn(mean_vec, cov_matrix)\n",
    "    return mvn_samp.rvs(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe2ea2b5-13a4-41c4-8257-c6c18708501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "758ac30a-bcc7-4b5e-9314-7fb85f284f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_ann =  ann(hidden = 16, input_shape = 32, output_shape = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2548f2de-a4c3-4850-b5cc-439634f5c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ann_1 = samp_ann.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1338dc89-5540-4867-95a6-3d0ea7639cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1  = samp_ann.layers[1].output.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "427b0370-90df-4ab4-85b9-691d082750bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_ann.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06982568-e5c1-4712-895c-7b3d49a09040",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a71c4646-23a6-45ca-9ccc-aa4c3566d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_ann_params = samp_ann.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "790b6dbd-22de-4e94-9a76-953531ed2494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_ensembles_for_weights = generate_initial_ensembles(4, 1, 250)\n",
    "# initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ce42026-267e-420d-93ef-e88962e8c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax_weights = tf.math.softmax(initial_ensembles_for_weights).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9decedfe-1393-4c7c-989a-966ff3312f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "309700fc-dd6c-4fec-a354-cdc7712cd8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8f7aff4-a7de-4003-b49d-a031c0307b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax_weights[:2, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6043df79-7cc6-45fd-8160-683e79e2f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax_weights[:,:2].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e7fef7e-9046-49ce-b7bd-e3e82b9c1689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax_weights[:2,:,:2].sum(-1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f09cd707-d205-46ce-b6ac-2ab22b93a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax_weights[:2,:,2:].sum(-1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c40ee77c-55d5-47a0-a43c-638b89372e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = softmax_weights[:,:2].sum(1).reshape(-1,1)\n",
    "    \n",
    "# model_2 = softmax_weights[:,2:].sum(1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c08f62c-d114-4bee-a335-ba4734f6bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 + model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12ba54e5-987a-408a-8a1a-21f7bbde8d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_ensembles_for_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5f741d7-ba99-4803-8441-5bf2ad3d72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_X_t(data1, data2, size_ens, var_weights = 1.0, var_weight_weights = 4.0):\n",
    "    # samp_ann =  ann(hidden = hidden_neurons, input_shape = 32, output_shape = 1)\n",
    "    \n",
    "    initial_ensembles1 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data1_out1, data1_stack1 = get_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens)\n",
    "    \n",
    "    initial_ensembles2 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data1_out2, data1_stack2 = get_targets_with_weights(data1, initial_ensembles2, size_ens = size_ens)\n",
    "    \n",
    "    initial_ensembles3 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data2_out1, data2_stack1 = get_targets_with_weights(data2, initial_ensembles3, size_ens = size_ens)\n",
    "    \n",
    "    initial_ensembles4 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data2_out2, data2_stack2 = get_targets_with_weights(data2, initial_ensembles4, size_ens = size_ens)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles_for_weights = generate_initial_ensembles(4, var_weight_weights, size_ens)\n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    initial_ensembles_for_L = generate_initial_ensembles(4, var_weights, size_ens)\n",
    "    initial_ensembles_for_L = np.expand_dims(initial_ensembles_for_L,1)    \n",
    "    \n",
    "    initial_ensembles_for_D1 = generate_initial_ensembles(1, var_weights, size_ens).reshape(-1,1)\n",
    "    initial_ensembles_for_D2 = generate_initial_ensembles(1, var_weights, size_ens).reshape(-1,1)\n",
    "    \n",
    "    initial_ensembles_for_D1_zero = np.zeros((size_ens,1,1)).reshape(-1,1)\n",
    "    initial_ensembles_for_D2_zero = np.zeros((size_ens,1,1)).reshape(-1,1)\n",
    "    \n",
    "    initial_ensembles_for_D = np.concatenate((np.expand_dims(initial_ensembles_for_D1,1),\n",
    "                                                       np.expand_dims(initial_ensembles_for_D1_zero,1), \n",
    "                                                      np.expand_dims(initial_ensembles_for_D2,1),\n",
    "                                                       np.expand_dims(initial_ensembles_for_D2_zero,1)), axis = 2)\n",
    "    \n",
    "    # print(X_t.shape, initial_ensembles_for_weights.shape)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D), axis = 1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4))\n",
    "    \n",
    "    return X_t, initial_ensembles, initial_ensembles_for_weights[:,0,:], initial_ensembles_for_L[:,0,:], initial_ensembles_for_D[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ac49c8c-6da0-4ee2-9561-e1d19365f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_targets_with_weights(batch_data, initial_ensembles, size_ens, weights): \n",
    "    \n",
    "    target_dim = 1\n",
    "    \n",
    "    # weights_ann_1 = ann.get_weights()\n",
    "    \n",
    "    # h1  = ann.layers[1].output.shape[-1]\n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "    \n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "    \n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, target_dim)\n",
    "\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + target_dim)].reshape(size_ens, 1, target_dim)\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "    \n",
    "    final_output_1 = final_output_1[:,:, 0]\n",
    "    \n",
    "    final_output_1 = final_output_1*weights\n",
    "    \n",
    "    # print(final_output_1.shape, initial_ensembles.shape)\n",
    "    \n",
    "    stack = np.hstack((final_output_1, initial_ensembles))\n",
    "\n",
    "    \n",
    "    return final_output_1, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b697b7f9-3d50-4d71-a436-cdc6434909a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_targets = pickle.load( open('..//Data//target_scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ace8608-8da1-4b4e-b051-a7b49feae636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_t = np.array([[0.02, 0], [0, 0.02]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d156603a-c127-45b6-a74d-2735987d03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var1 = R_t[0,0]\n",
    "# var2 = R_t[1,1]\n",
    "# cov = R_t[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5a2f9ca-f4b4-445a-ab5f-e0f0557f54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44ed09c8-f6b0-4b40-86e0-1975541fd0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fudging_beta = beta(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d1a4f5e-7a0d-42b7-ad45-59c708b7b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_operation(data1, data2, combined_ensembles , size_ens, fudging_beta):\n",
    "    # samp_ann =  ann(hidden = hidden_neurons, input_shape = 32, output_shape = 1)\n",
    "    params = samp_ann_params\n",
    "    initial_ensembles1 = combined_ensembles[:, :params]\n",
    "    initial_ensembles2 = combined_ensembles[:, params:(2*params)]\n",
    "    initial_ensembles3 = combined_ensembles[:, (2*params):(3*params)]\n",
    "    initial_ensembles4 = combined_ensembles[:, (3*params):(4*params)]\n",
    "\n",
    "    \n",
    "    initial_ensembles_for_weights = combined_ensembles[:, (4*params):(4*params + 4)]\n",
    "    \n",
    "    initial_ensembles_for_L = combined_ensembles[:, (4*params + 4):(4*params + 4 + 4)]\n",
    "    \n",
    "    initial_ensembles_for_D = combined_ensembles[:,(4*params + 4 + 4):(4*params + 4 + 4 + 4)]\n",
    "    \n",
    "    \n",
    "    softmax_weights = tf.math.softmax(initial_ensembles_for_weights).numpy()\n",
    "    \n",
    "    model_1 = softmax_weights[:, :2].sum(1).reshape(-1,1) +  fudging_beta.rvs(size_ens).reshape(-1,1)\n",
    "    \n",
    "    # model_1 = np.min(model_1 -fudging_factor)\n",
    "    \n",
    "    model_2 = softmax_weights[:, 2:].sum(1).reshape(-1,1) +  fudging_beta.rvs(size_ens).reshape(-1,1)\n",
    "    \n",
    "    \n",
    "    model_1_plus_model_2 = model_1 + model_2\n",
    "    \n",
    "    model_1 = model_1/model_1_plus_model_2\n",
    "    \n",
    "    model_2 = model_2/model_1_plus_model_2\n",
    "    \n",
    "    \n",
    "    # print(np.mean(model_1 + model_2))\n",
    "    \n",
    "    data1_out1, data1_stack1 = get_weighted_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens,\n",
    "                                                                  weights=model_1)\n",
    "    \n",
    "    data1_out2, data1_stack2 = get_weighted_targets_with_weights(data1, initial_ensembles2, size_ens = size_ens,\n",
    "                                                                weights=model_1)\n",
    "    \n",
    "    data2_out1, data2_stack1 = get_weighted_targets_with_weights(data2, initial_ensembles3, size_ens = size_ens,\n",
    "                                                                 weights=model_2)\n",
    "    \n",
    "    data2_out2, data2_stack2 = get_weighted_targets_with_weights(data2, initial_ensembles4, size_ens = size_ens,\n",
    "                                                                  weights=model_2)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4, \n",
    "                        initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D))\n",
    "    \n",
    "    # print(X_t.shape)\n",
    "    \n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    initial_ensembles_for_L = np.expand_dims(initial_ensembles_for_L,1)\n",
    "    \n",
    "    initial_ensembles_for_D = np.expand_dims(initial_ensembles_for_D,1)\n",
    "    \n",
    "    # print(initial_ensembles_for_weights.shape)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D), axis = 1)\n",
    "    \n",
    "    weighted_alogp = data1_out1 + data2_out1\n",
    "    \n",
    "    weighted_psa = data1_out2 + data2_out2\n",
    "    \n",
    "    return X_t, initial_ensembles, weighted_alogp, weighted_psa, model_1, model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6bd2eb3-86b7-41ed-81b4-4dd8e44e106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_operation_test(data1, data2, combined_ensembles , size_ens):\n",
    "    # samp_ann =  ann(hidden = hidden_neurons, input_shape = 32, output_shape = 1)\n",
    "    params = samp_ann_params\n",
    "    initial_ensembles1 = combined_ensembles[:, :params]\n",
    "    initial_ensembles2 = combined_ensembles[:, params:(2*params)]\n",
    "    initial_ensembles3 = combined_ensembles[:, (2*params):(3*params)]\n",
    "    initial_ensembles4 = combined_ensembles[:, (3*params):(4*params)]\n",
    "\n",
    "    \n",
    "    initial_ensembles_for_weights = combined_ensembles[:, (4*params):(4*params + 4)]\n",
    "    \n",
    "    initial_ensembles_for_L = combined_ensembles[:, (4*params + 4):(4*params + 4 + 4)]\n",
    "    \n",
    "    initial_ensembles_for_D = combined_ensembles[:,(4*params + 4 + 4):(4*params + 4 + 4 + 4)]\n",
    "    \n",
    "    \n",
    "    softmax_weights = tf.math.softmax(initial_ensembles_for_weights).numpy()\n",
    "    \n",
    "    model_1 = softmax_weights[:, :2].sum(1).reshape(-1,1) \n",
    "    \n",
    "    # model_1 = np.min(model_1 -fudging_factor)\n",
    "    \n",
    "    model_2 = softmax_weights[:, 2:].sum(1).reshape(-1,1) \n",
    "    \n",
    "    \n",
    "#     model_1_plus_model_2 = model_1 + model_2\n",
    "    \n",
    "#     model_1 = model_1/model_1_plus_model_2\n",
    "    \n",
    "#     model_2 = model_2/model_1_plus_model_2\n",
    "    \n",
    "    \n",
    "    # print(np.mean(model_1 + model_2))\n",
    "    \n",
    "    data1_out1, data1_stack1 = get_weighted_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens,\n",
    "                                                                  weights=model_1)\n",
    "    \n",
    "    data1_out2, data1_stack2 = get_weighted_targets_with_weights(data1, initial_ensembles2, size_ens = size_ens,\n",
    "                                                                weights=model_1)\n",
    "    \n",
    "    data2_out1, data2_stack1 = get_weighted_targets_with_weights(data2, initial_ensembles3, size_ens = size_ens,\n",
    "                                                                 weights=model_2)\n",
    "    \n",
    "    data2_out2, data2_stack2 = get_weighted_targets_with_weights(data2, initial_ensembles4, size_ens = size_ens,\n",
    "                                                                  weights=model_2)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4, \n",
    "                        initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D))\n",
    "    \n",
    "    # print(X_t.shape)\n",
    "    \n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    initial_ensembles_for_L = np.expand_dims(initial_ensembles_for_L,1)\n",
    "    \n",
    "    initial_ensembles_for_D = np.expand_dims(initial_ensembles_for_D,1)\n",
    "    \n",
    "    # print(initial_ensembles_for_weights.shape)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D), axis = 1)\n",
    "    \n",
    "    weighted_alogp = data1_out1 + data2_out1\n",
    "    \n",
    "    weighted_psa = data1_out2 + data2_out2\n",
    "    \n",
    "    return X_t, initial_ensembles, weighted_alogp, weighted_psa, model_1, model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e15b0bf7-ba00-40bc-933b-c1c3e062e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samp_ann =  ann(hidden = 16, input_shape = 32, output_shape = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af3dd570-7ab3-4eae-bd8e-9a57a333b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = 4*(samp_ann.count_params() + 1 + 1 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e820b010-4396-4b7a-8781-a8e6d503aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5fbaaf7-afae-4008-a26c-e0691ef9b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = total_weights//reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5111536-1a97-4390-9658-c9848a136a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f598992-73d6-4b5a-906d-3184f1b9625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_t = [[1, 0, 1, 0], [0, 1, 0, 1]]\n",
    "G_t = np.array(G_t).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3073d2ce-5b22-47bb-80a3-9ad86ac3d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a84cb0e3-2f5e-4207-b092-d2768b52205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data1, data2, initial_ensembles, fudging_beta  =fudging_beta): \n",
    "    _,_, weighted_alogp, weighted_psa, w1, w2 = forward_operation(data1, data2, initial_ensembles, size_ens = size_ens, fudging_beta = fudging_beta)\n",
    "    weighted_alogp = np.expand_dims(weighted_alogp,-1)\n",
    "    weighted_psa = np.expand_dims(weighted_psa,-1)\n",
    "    preds = np.concatenate((weighted_alogp, weighted_psa),-1)\n",
    "    return preds, w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37b60b37-92b1-4784-85fc-59a865d2398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_test(data1, data2, initial_ensembles): \n",
    "    _,_, weighted_alogp, weighted_psa, w1, w2 = forward_operation_test(data1, data2, initial_ensembles, size_ens = size_ens)\n",
    "    weighted_alogp = np.expand_dims(weighted_alogp,-1)\n",
    "    weighted_psa = np.expand_dims(weighted_psa,-1)\n",
    "    preds = np.concatenate((weighted_alogp, weighted_psa),-1)\n",
    "    return preds, w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3af0a9b9-6202-40e2-911f-3c890213099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mu_bar_G_bar(data1, data2, initial_ensembles, fudging_beta):\n",
    "    H_t = np.hstack((np.identity(data1.shape[0]), np.zeros((data1.shape[0], samp_ann_params + 1 + 1 + 1))))\n",
    "    mu_bar = initial_ensembles.mean(0)\n",
    "    X_t,_, _, _, _, _ = forward_operation(data1, data2, initial_ensembles, size_ens = size_ens, fudging_beta = fudging_beta)\n",
    "    X_t = X_t.transpose((0,2,1))\n",
    "    X_t = X_t.reshape(X_t.shape[0], X_t.shape[1]*X_t.shape[2])\n",
    "    script_H_t = np.kron(G_t.T, H_t)\n",
    "    G_u = (script_H_t@X_t.T)\n",
    "    G_u = G_u.T\n",
    "    # weighted_alogp = np.expand_dims(weighted_alogp,-1)\n",
    "    # weighted_psa = np.expand_dims(weighted_psa,-1)\n",
    "    # G_u = np.concatenate((weighted_alogp, weighted_psa), axis = -1)\n",
    "    # G_u = G_u.transpose((0,2,1))\n",
    "    # G_u = G_u.reshape(G_u.shape[0], G_u.shape[1]*G_u.shape[2])\n",
    "    # G_u\n",
    "    G_bar = (G_u.mean(0)).ravel()\n",
    "    return mu_bar.reshape(-1,1), G_bar.reshape(-1,1), G_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7334c80c-cfcd-4d5b-b844-11cfb8c137df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_C_u(initial_ensembles, mu_bar, G_bar, G_u): \n",
    "    u_j_minus_u_bar = initial_ensembles - mu_bar.reshape(1,-1)\n",
    "    G_u_minus_G_bar = G_u -  G_bar.reshape(1,-1)\n",
    "    c = np.zeros((total_weights, G_bar.shape[0]))\n",
    "    for i in range(0, size_ens): \n",
    "        c += np.kron(u_j_minus_u_bar[i, :].T.reshape(-1,1), G_u_minus_G_bar[i,:].reshape(-1,1).T)\n",
    "    return c/size_ens, G_u_minus_G_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9148779c-1a3f-455d-a6ad-00fc1bf69c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_D_u( G_bar, G_u): \n",
    "    G_u_minus_G_bar = G_u -  G_bar.reshape(1,-1)\n",
    "    d = np.zeros((G_bar.shape[0], G_bar.shape[0]))\n",
    "    for i in range(0, size_ens): \n",
    "        d += np.kron(G_u_minus_G_bar[i,:].T.reshape(-1,1), G_u_minus_G_bar[i,:].reshape(-1,1).T)\n",
    "    return d/size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e8459b0-68c1-4d1f-851e-3d7b99f0ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_updated_ensemble(data1, data2, initial_ensembles, y_train, size_ens = size_ens, inflation_factor = 1.0, fudging_beta = fudging_beta):\n",
    "    mu_bar, G_bar, G_u = calculate_mu_bar_G_bar(data1, data2, initial_ensembles, fudging_beta)\n",
    "    C, G_u_minus_G_bar = calculate_C_u(initial_ensembles, mu_bar, G_bar, G_u)\n",
    "    D = calculate_D_u( G_bar, G_u)\n",
    "    _, R_t = create_cov(data1.shape[0],initial_ensembles)\n",
    "    inflation = np.identity(R_t.shape[0])*inflation_factor\n",
    "    D_plus_cov = D + (R_t *inflation_factor)\n",
    "    # all_covs = np.array(all_covs)\n",
    "    # D_plus_cov = D + R_t\n",
    "    D_plus_cov_inv = np.linalg.inv(D_plus_cov)\n",
    "    mid_quant = C@D_plus_cov_inv\n",
    "    noise_vec_mean = np.zeros((R_t.shape[0], ))\n",
    "    noise_mvn = mvn(noise_vec_mean, R_t)\n",
    "    fudging = noise_mvn.rvs(size_ens)\n",
    "    interim = (y_train.T.flatten().reshape(1,-1) + fudging)\n",
    "    right_quant = interim - G_u\n",
    "    # print(mid_quant.shape, right_quant.shape)\n",
    "    mid_times_right = mid_quant@right_quant.T\n",
    "    updated_ensemble = (initial_ensembles + mid_times_right.T)\n",
    "    return updated_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c14b236d-6ebf-40e3-9085-97afd2990e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "346d07bc-5b61-4e75-a816-a6e22ffe9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_D = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc3a216a-4dbb-474d-8219-5f6c071250a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(data, idx):\n",
    "    data_cur = data[idx, :, :]\n",
    "    inv_data_cur = std_targets.inverse_transform(data_cur)\n",
    "    return inv_data_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5abd35fb-ea92-449d-894a-162ed1f4aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "381fc654-8877-41fd-840a-4b35153f923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cov(shape, initial_ensembles):\n",
    "    cov_part = initial_ensembles[:, -8:-4]\n",
    "    cov_part = cov_part.mean(0)\n",
    "    # variances = tf.math.softplus(cov_part[:2]).numpy()\n",
    "    variances = cov_part[:2]\n",
    "    covariances = cov_part[2:]\n",
    "    base_cov = np.identity(target_dim)\n",
    "    base_cov[0,0] = variances[0]\n",
    "    base_cov[1,1] = variances[1]\n",
    "    base_cov[0,1] = covariances[0]\n",
    "    base_cov[1,0] = covariances[1]\n",
    "    \n",
    "    variances1 = tf.math.softplus(initial_ensembles[:, -4:]).numpy()\n",
    "    variances1 = variances1.mean(0)\n",
    "    base_variances = np.identity(target_dim)\n",
    "    base_variances[0,0] = variances1[0]\n",
    "    base_variances[1,1] = variances1[2]\n",
    "    \n",
    "    final = np.linalg.cholesky(base_cov@base_cov.T + base_variances)\n",
    "    cov_mat = final@final.T\n",
    "    cov_mat_final = cov_mat\n",
    "    # cov_mat_final = cov_mat@cov_mat.T\n",
    "    \n",
    "    if is_pos_def(cov_mat_final) != True:\n",
    "        print(\"resulting cov matrix is not positive semi definite\")\n",
    "        pass\n",
    "    \n",
    "    # print(np.linalg.det(cov_mat_final))\n",
    "    \n",
    "    var1 = cov_mat_final[0,0]\n",
    "    var2 = cov_mat_final[1,1]\n",
    "    cov = cov_mat_final[1,0]\n",
    "\n",
    "    n = shape\n",
    "    \n",
    "    ul = var1*np.identity(n)\n",
    "    lr = var2*np.identity(n)\n",
    "    ur = cov*np.identity(n)\n",
    "    ll = ur.T    \n",
    "    \n",
    "    first_row = np.hstack((ul, ur))\n",
    "    second_row = np.hstack((ll, lr))\n",
    "    \n",
    "    R_t = np.vstack((first_row, second_row))\n",
    "    \n",
    "    # R_t = block_diag(*([cov_mat_final] * n))\n",
    "    \n",
    "    # R_t = np.linalg.inv(R_t)\n",
    "    \n",
    "    return cov_mat_final, R_t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30aea5e4-361f-44ae-9ea3-d1d8743e6ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed1f9938-cdc5-400f-8bab-22c180a6d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"..//Data//smiles_to_rdkit_80_20_with_cov_minus_0.2_var.pickle\", \"rb\") as f: \n",
    "    catch = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7c59ea29-6484-40d5-8777-80cf9ca6cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "176445fb-4f30-421a-a710-339955111baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(idx, var_weights = 1.0, var_weight_weights = 4.0): \n",
    "    catch_idx = catch[idx]\n",
    "    x_train, x_valid, y_train, y_valid = catch_idx[0], catch_idx[1], catch_idx[2], catch_idx[3]\n",
    "    y_train_actual, y_train = y_train[:,:2], y_train[:,2:]\n",
    "    y_valid_actual, y_valid = y_valid[:,:2], y_valid[:,2:]\n",
    "    smiles_feats_train = x_train[:, :32]\n",
    "    rdkit_feats_train = x_train[:, 32:]\n",
    "    smiles_feats_valid = x_valid[:, :32]\n",
    "    rdkit_feats_valid = x_valid[:, 32:]\n",
    "\n",
    "    X_t, initial_ensembles, initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D = get_initial_X_t(smiles_feats_train, rdkit_feats_train, size_ens = size_ens, var_weights = var_weights, var_weight_weights = var_weight_weights)\n",
    "    initial_ensembles = np.hstack((initial_ensembles, initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D))\n",
    "    \n",
    "    return smiles_feats_train, rdkit_feats_train, smiles_feats_valid, rdkit_feats_valid, y_train, y_train_actual, y_valid, y_valid_actual, initial_ensembles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "82d67093-cbd5-4a2b-bdbc-aa33a082e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smiles_feats_train, rdkit_feats_train, smiles_feats_valid, rdkit_feats_valid, y_train, y_train_actual, y_valid, y_valid_actual, initial_ensembles  = prepare_data(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa640128-df71-44ec-b20b-6922bdb5b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dc0c894d-db8c-4d88-bd51-ef23ca80fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5cffacb-8558-45ca-bff9-e803e3fd6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a2e8d41-0775-457c-97a2-4060fd72634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta(1,19).rvs(size_ens).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "65bf21e9-92c6-4824-93c3-87274b072afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(idx, var_weights = 1.0, var_weight_weights = 1.0, inflation_factor = 1.2, fudging_beta = beta(1,19)):\n",
    "    # print('var_weights' + str(var_weights))\n",
    "    # print('inflation_factor' + str(inflation_factor))\n",
    "    # print('var_weight_weights' + str(var_weight_weights))\n",
    "    smiles_feats_train, rdkit_feats_train, smiles_feats_valid, rdkit_feats_valid, y_train, y_train_actual, y_valid, y_valid_actual, initial_ensembles  = prepare_data(idx, var_weights = var_weights, var_weight_weights =var_weight_weights)\n",
    "    # print(R_t.shape)\n",
    "    best_train_width_mean = 100000\n",
    "    \n",
    "    for i in range(0,10000):\n",
    "        # print(i)\n",
    "    \n",
    "        c = np.zeros((2,2))\n",
    "        initial_ensembles = get_updated_ensemble(smiles_feats_train, rdkit_feats_train, initial_ensembles, y_train, size_ens, inflation_factor = inflation_factor, fudging_beta = fudging_beta)\n",
    "        # print(inflation_factor)\n",
    "        G_u_train, w1, w2 = get_predictions(smiles_feats_train, rdkit_feats_train, initial_ensembles, fudging_beta)\n",
    "\n",
    "        catch = Parallel(n_jobs = 15, verbose = 0)(delayed(inverse_transform)(G_u_train, i)  for i in range(G_u_train.shape[0]))\n",
    "        G_u_train = np.array(catch)\n",
    "    \n",
    "        y_train_cur = std_targets.inverse_transform(y_train_actual)\n",
    "    \n",
    "        li_train = np.percentile(G_u_train, axis = 0, q = (2.5, 97.5))[0,:,:]   \n",
    "        ui_train = np.percentile(G_u_train, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "    \n",
    "        width_train = ui_train - li_train\n",
    "        avg_width_train = width_train.mean(0)\n",
    "    \n",
    "        ind_train = (y_train_cur >= li_train) & (y_train_cur <= ui_train)\n",
    "        coverage_train= ind_train.mean(0)\n",
    "    \n",
    "        averaged_targets_train = G_u_train.mean(0)\n",
    "        rmse_train = np.sqrt(((y_train_cur -averaged_targets_train)**2).mean(0))\n",
    "    # print(rmse_train, coverage_train, avg_width_train)\n",
    "    \n",
    "        G_u_test, _, _ = get_predictions_test(smiles_feats_valid, rdkit_feats_valid, initial_ensembles)\n",
    "    \n",
    "        catch = Parallel(n_jobs = 15, verbose = 0)(delayed(inverse_transform)(G_u_test, i)  for i in range(G_u_test.shape[0]))\n",
    "        G_u_test = np.array(catch)\n",
    "    \n",
    "        y_valid_cur = std_targets.inverse_transform(y_valid_actual)    \n",
    "    \n",
    "        li_test = np.percentile(G_u_test, axis = 0, q = (2.5, 97.5))[0,:,:]   \n",
    "        ui_test = np.percentile(G_u_test, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "    \n",
    "        width_test = ui_test - li_test\n",
    "        avg_width_test = width_test.mean(0)\n",
    "    \n",
    "        ind_test = (y_valid_cur >= li_test) & (y_valid_cur <= ui_test)\n",
    "        coverage_test= ind_test.mean(0)\n",
    "    \n",
    "        averaged_targets_test = G_u_test.mean(0)\n",
    "        rmse_test = np.sqrt(((y_valid_cur -averaged_targets_test)**2).mean(0))    \n",
    "    \n",
    "        # weight_norms = np.array(norm(initial_ensembles, ord = 2, axis = 1))\n",
    "        # weight_norm_mean.append(weight_norms.mean())\n",
    "        # weight_norm_sd.append(weight_norms.std())\n",
    "    \n",
    "        cov_mat_final, _ = create_cov(smiles_feats_train.shape[0],initial_ensembles)\n",
    "        \n",
    "        # print(\"standardized_scale_R_t\")\n",
    "        # print(np.diag(cov_mat_final), cov_mat_final[0,1])\n",
    "        \n",
    "        # print(w1.shape)\n",
    "        \n",
    "        li_smiles_weight = np.percentile(w1, axis = 0, q = (2.5, 97.5))[0][0]\n",
    "        \n",
    "        # print(np.percentile(w1, axis = 0, q = (2.5, 97.5)))\n",
    "        \n",
    "        ui_smiles_weight = np.percentile(w1, axis = 0, q = (2.5, 97.5))[1][0]      \n",
    "        \n",
    "        # print(coverage_train.tolist(), avg_width_train.tolist(), rmse_train.tolist())\n",
    "        # print(coverage_test.tolist(), avg_width_test.tolist(), rmse_test.tolist())\n",
    "        # print(w1.mean())\n",
    "        # print(li_smiles_weight, ui_smiles_weight)\n",
    "        # print(avg_width_train.tolist(), coverage_train.tolist(), rmse_train.tolist(), avg_width_test.tolist(), coverage_test.tolist(), rmse_test.tolist(), w1.mean())\n",
    "\n",
    "        if (avg_width_train.mean() < best_train_width_mean) & (coverage_train.mean() > 0.95): \n",
    "            # print(\"went here\")\n",
    "            best_train_width_mean = avg_width_train.mean()\n",
    "            best_train_width = avg_width_train\n",
    "            best_smiles_weight = w1.mean()\n",
    "            best_coverage_train = coverage_train\n",
    "            best_rmse_train = rmse_train\n",
    "        \n",
    "            best_test_width = avg_width_test\n",
    "\n",
    "            best_coverage_test = coverage_test    \n",
    "            best_rmse_test = rmse_test\n",
    "            \n",
    "            best_li_smiles_weight = li_smiles_weight\n",
    "            \n",
    "            best_ui_smiles_weight = ui_smiles_weight\n",
    "    \n",
    "        if coverage_train.mean() < 0.95:\n",
    "            \n",
    "            # print()\n",
    "            # print(best_train_width.tolist(), best_coverage_train.tolist(), best_rmse_train.tolist(), best_test_width.tolist(), best_coverage_test.tolist(), best_rmse_test.tolist(), best_smiles_weight, flush = True)\n",
    "            print(\"done for fold\" + str(idx), flush = True)\n",
    "            print(\"train_width\" + str(best_train_width.tolist()), flush = True)\n",
    "            print(\"test_width\" + str(best_test_width.tolist()), flush = True)\n",
    "            print(\"smiles_weight\" + str(best_smiles_weight), flush = True)\n",
    "            print(\"rmse_train\" + str(best_rmse_train.tolist()), flush = True)\n",
    "            print(\"rmse_test\" + str(best_rmse_test.tolist()), flush = True)\n",
    "            print(\"smiles_weight_ci\" + str([best_li_smiles_weight, best_ui_smiles_weight]), flush = True)\n",
    "            \n",
    "            return [best_train_width.tolist(), best_coverage_train.tolist(), best_rmse_train.tolist(), best_test_width.tolist(), best_coverage_test.tolist(), best_rmse_test.tolist(), best_smiles_weight, best_li_smiles_weight, best_ui_smiles_weight]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "201d8498-7742-4509-94de-4fb1f5d84e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "14658528-ea1a-4a6f-83bd-f708df0bcd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 3 µs, total: 7 µs\n",
      "Wall time: 15 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get_results(43, var_weights = 1.0, var_weight_weights = 3.0, inflation_factor =1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ac41ba9-2b9e-4b10-b6ad-e415030e40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c0033c73-c13a-492a-8caa-fb16a2d51405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold7\n",
      "train_width[1.028217658245113, 19.918152623422174]\n",
      "test_width[0.7832813767136059, 16.72435879163351]\n",
      "smiles_weight0.8583966846432027\n",
      "rmse_train[0.19118678473273484, 4.891198418213594]\n",
      "rmse_test[0.22115313962242414, 5.1093333597455635]\n",
      "smiles_weight_ci[0.7634459502605591, 0.9252457666095533]\n",
      "done for fold3\n",
      "train_width[0.9979384585007818, 17.204860030537088]\n",
      "test_width[0.811638932156154, 15.453465849167227]\n",
      "smiles_weight0.8142826482071414\n",
      "rmse_train[0.14974368078505582, 4.02789560849838]\n",
      "rmse_test[0.28516889299002857, 5.090890416224484]\n",
      "smiles_weight_ci[0.7277850432363241, 0.8816834586296635]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:  3.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold11\n",
      "train_width[0.9267781147571184, 20.64666103923149]\n",
      "test_width[0.8637769099558347, 20.137200487342866]\n",
      "smiles_weight0.769630493176236\n",
      "rmse_train[0.19929888936321996, 4.539256521081818]\n",
      "rmse_test[0.24190980160000738, 5.255805294209136]\n",
      "smiles_weight_ci[0.6715622846788758, 0.8417135016669796]\n",
      "done for fold8\n",
      "train_width[0.8380044227975543, 16.141878619170843]\n",
      "test_width[0.6537114945491932, 13.855393840918651]\n",
      "smiles_weight0.8395969738333481\n",
      "rmse_train[0.22845900559644794, 4.416452855745062]\n",
      "rmse_test[0.2038715361190169, 3.5969009751735093]\n",
      "smiles_weight_ci[0.7544774007014892, 0.897268869165638]\n",
      "done for fold0\n",
      "train_width[0.9950223845174654, 17.99902222442868]\n",
      "test_width[0.5854828478948891, 12.67010640301545]\n",
      "smiles_weight0.8762587475309068\n",
      "rmse_train[0.1938240202031454, 4.566290198801293]\n",
      "rmse_test[0.16817298043990125, 3.185644486217468]\n",
      "smiles_weight_ci[0.7947320355604692, 0.9284041635105827]\n",
      "done for fold5\n",
      "train_width[0.8891293003611547, 17.761620548217266]\n",
      "test_width[0.6104797951057885, 13.852289175120118]\n",
      "smiles_weight0.8596660414390019\n",
      "rmse_train[0.16582988581596914, 4.610281359187856]\n",
      "rmse_test[0.20185939290302107, 3.8954972836973303]\n",
      "smiles_weight_ci[0.7580206544210925, 0.9269753901958262]\n",
      "done for fold9\n",
      "train_width[0.7385665538873031, 12.686119520846526]\n",
      "test_width[0.5000592198593589, 10.312213025428825]\n",
      "smiles_weight0.8348071541375952\n",
      "rmse_train[0.1593299898852315, 3.3424968376052426]\n",
      "rmse_test[0.1565436894365269, 2.4594646992756544]\n",
      "smiles_weight_ci[0.7421874343345939, 0.8913205477679303]\n",
      "done for fold10\n",
      "train_width[0.7771837911265791, 14.793960058245373]\n",
      "test_width[0.6010401239998091, 12.612512861041546]\n",
      "smiles_weight0.8047199439724078\n",
      "rmse_train[0.1880334174019667, 4.098326271024713]\n",
      "rmse_test[0.12955210614136656, 3.1471463871066065]\n",
      "smiles_weight_ci[0.6955354245487786, 0.871122581448766]\n",
      "done for fold1\n",
      "train_width[0.7795168884881268, 16.50351751653361]\n",
      "test_width[0.5532636977163466, 14.302602124643586]\n",
      "smiles_weight0.8497606587499279\n",
      "rmse_train[0.1559649507602767, 4.079450195880003]\n",
      "rmse_test[0.22068098695941318, 4.297948006213533]\n",
      "smiles_weight_ci[0.762374707397837, 0.9074099929823389]\n",
      "done for fold6\n",
      "train_width[0.7722341507769617, 15.101827771197922]\n",
      "test_width[0.5790866707264766, 13.288501397755715]\n",
      "smiles_weight0.8523422994150145\n",
      "rmse_train[0.1511460828461161, 3.8102813343731885]\n",
      "rmse_test[0.2977675874117044, 7.148772872928095]\n",
      "smiles_weight_ci[0.7638372495794417, 0.9048794857701979]\n",
      "done for fold12\n",
      "train_width[0.8195750280499415, 13.926352291142246]\n",
      "test_width[0.5344424941511313, 10.74935690731658]\n",
      "smiles_weight0.8774443788446395\n",
      "rmse_train[0.1706883202155502, 3.52772204709434]\n",
      "rmse_test[0.19938620395331716, 4.262680656227402]\n",
      "smiles_weight_ci[0.7778223766917416, 0.9305559195535801]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  11 tasks      | elapsed:  4.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold14\n",
      "train_width[0.7923165630679898, 14.555226225846454]\n",
      "test_width[0.5081451086068707, 10.647550515802262]\n",
      "smiles_weight0.8776075044540096\n",
      "rmse_train[0.14805497064044865, 3.7834420430793503]\n",
      "rmse_test[0.19771830319109263, 2.736652580059646]\n",
      "smiles_weight_ci[0.779162199150479, 0.9317196049548354]\n",
      "done for fold13\n",
      "train_width[0.6265788580946292, 13.781116642628062]\n",
      "test_width[0.5092933893142725, 12.290207733177734]\n",
      "smiles_weight0.8391605361719505\n",
      "rmse_train[0.12186616538464211, 3.7511822967533575]\n",
      "rmse_test[0.17884565059622504, 4.561992304733684]\n",
      "smiles_weight_ci[0.7504639358932799, 0.8906174788441447]\n",
      "done for fold2\n",
      "train_width[0.8750312845856395, 12.581071274403987]\n",
      "test_width[0.6027943645605945, 10.491304902619106]\n",
      "smiles_weight0.8582733130722382\n",
      "rmse_train[0.142703960759211, 3.1426093305159526]\n",
      "rmse_test[0.27130077714872886, 4.613985937724497]\n",
      "smiles_weight_ci[0.7502049960705107, 0.9127541680432455]\n",
      "done for fold4\n",
      "train_width[0.6466567999413313, 11.47099370992976]\n",
      "test_width[0.511387408037675, 10.420135433115197]\n",
      "smiles_weight0.8417673783424665\n",
      "rmse_train[0.13855327523685207, 2.8093683357775907]\n",
      "rmse_test[0.6011781372398843, 8.370914752464158]\n",
      "smiles_weight_ci[0.7599330816503922, 0.8915553591254927]\n",
      "done for fold16\n",
      "train_width[0.7619384646305273, 17.01023415833004]\n",
      "test_width[0.5396562431336596, 14.020201168318838]\n",
      "smiles_weight0.8340180020973929\n",
      "rmse_train[0.18030933953062167, 3.9214856008473205]\n",
      "rmse_test[0.2149487733478316, 4.119956501844005]\n",
      "smiles_weight_ci[0.745726800720168, 0.8895291480151449]\n",
      "done for fold23\n",
      "train_width[0.744592454654919, 16.662219598684363]\n",
      "test_width[0.6228644833659795, 14.369219815244573]\n",
      "smiles_weight0.7964542216959584\n",
      "rmse_train[0.19189160828496765, 3.589957529683621]\n",
      "rmse_test[0.19538601110678466, 3.6177233820172954]\n",
      "smiles_weight_ci[0.717220967520402, 0.8503798076719362]\n",
      "done for fold17\n",
      "train_width[0.8595166531556963, 15.75063656189921]\n",
      "test_width[0.629348198768134, 13.699613479512324]\n",
      "smiles_weight0.8629277319434075\n",
      "rmse_train[0.185812610919183, 3.959039722606036]\n",
      "rmse_test[0.5561435931972721, 3.5765890725903704]\n",
      "smiles_weight_ci[0.7693813946289034, 0.922954221436496]\n",
      "done for fold15\n",
      "train_width[0.972188097052855, 17.248957733161944]\n",
      "test_width[0.626270017297683, 13.652525801179193]\n",
      "smiles_weight0.8696339800716728\n",
      "rmse_train[0.21005801194869478, 4.647360559767274]\n",
      "rmse_test[0.157765422739239, 3.6200593325449875]\n",
      "smiles_weight_ci[0.775844219063309, 0.9286548654990077]\n",
      "done for fold19\n",
      "train_width[0.791210176425641, 18.165195070869373]\n",
      "test_width[0.5501239192637094, 14.182721150333428]\n",
      "smiles_weight0.8568123417673909\n",
      "rmse_train[0.187902550930716, 4.1757836094534]\n",
      "rmse_test[0.17266031471150772, 3.884609256779344]\n",
      "smiles_weight_ci[0.7502037354945451, 0.9126954789211399]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:  6.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold26\n",
      "train_width[0.9826196358537204, 18.61361752729782]\n",
      "test_width[0.7845924759877765, 15.987612926855913]\n",
      "smiles_weight0.8498706087963207\n",
      "rmse_train[0.19949699921666048, 4.3091525197731695]\n",
      "rmse_test[0.1829285507004624, 3.8773979760629964]\n",
      "smiles_weight_ci[0.7521384972483585, 0.9162563691101232]\n",
      "done for fold20\n",
      "train_width[0.9302189458875374, 17.077417163701224]\n",
      "test_width[0.6535343226932453, 13.280380767241699]\n",
      "smiles_weight0.8472831429121112\n",
      "rmse_train[0.19246414127950234, 4.292990367095551]\n",
      "rmse_test[0.20697886310723548, 3.4597757788748775]\n",
      "smiles_weight_ci[0.7639399561910224, 0.9039251762322208]\n",
      "done for fold25\n",
      "train_width[0.7489516624395126, 15.784656586128797]\n",
      "test_width[0.615917959529284, 13.395461388929457]\n",
      "smiles_weight0.7920680080626132\n",
      "rmse_train[0.15049582690020827, 4.0615322659943365]\n",
      "rmse_test[0.16293856239131174, 3.6311184403105057]\n",
      "smiles_weight_ci[0.7120537270450203, 0.8636049477300722]\n",
      "done for fold22\n",
      "train_width[0.834292086947836, 14.411680149429703]\n",
      "test_width[0.5475139939087402, 11.895491421747263]\n",
      "smiles_weight0.856471271195974\n",
      "rmse_train[0.1987097370302606, 3.9448308589001018]\n",
      "rmse_test[0.15114687493980283, 3.423755821941315]\n",
      "smiles_weight_ci[0.7563580396965206, 0.9154878402991508]\n",
      "done for fold18\n",
      "train_width[0.6870660635075333, 14.307406990882116]\n",
      "test_width[0.5673650199920035, 12.702317679315522]\n",
      "smiles_weight0.8028926864310675\n",
      "rmse_train[0.1671615999193529, 3.451160164971989]\n",
      "rmse_test[0.17026347519564772, 3.5359744474676904]\n",
      "smiles_weight_ci[0.7091143299823942, 0.8640646881275182]\n",
      "done for fold27\n",
      "train_width[0.7497912601927899, 15.038819132580203]\n",
      "test_width[0.5608473355514719, 12.863004213176787]\n",
      "smiles_weight0.8276266819645688\n",
      "rmse_train[0.18056969522364988, 3.0084626982215212]\n",
      "rmse_test[0.16318579068585026, 2.379651777603817]\n",
      "smiles_weight_ci[0.7339646169215986, 0.8844861305240145]\n",
      "done for fold24\n",
      "train_width[0.8049597783498905, 13.702817713720078]\n",
      "test_width[0.4834352028539526, 10.63539691729555]\n",
      "smiles_weight0.890841240802096\n",
      "rmse_train[0.11890174399163586, 3.7235542604002263]\n",
      "rmse_test[0.20571031277681795, 3.121492276484268]\n",
      "smiles_weight_ci[0.8006095812757521, 0.9396033612941556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  27 out of  50 | elapsed:  7.9min remaining:  6.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold28\n",
      "train_width[0.7821485911939134, 16.528738778231954]\n",
      "test_width[0.5735945789005625, 14.23630798123761]\n",
      "smiles_weight0.8664718492915234\n",
      "rmse_train[0.17604162061010098, 3.2542525089484107]\n",
      "rmse_test[0.2148935491827686, 7.116765166149208]\n",
      "smiles_weight_ci[0.7680225741011414, 0.9209280107061398]\n",
      "done for fold21\n",
      "train_width[0.623331354083685, 12.12241812785319]\n",
      "test_width[0.4236547791074596, 9.360811120526641]\n",
      "smiles_weight0.8351420950560899\n",
      "rmse_train[0.15472313344733882, 3.322040788220075]\n",
      "rmse_test[0.1206282178778505, 2.6768031769222227]\n",
      "smiles_weight_ci[0.7562777537661357, 0.890184465775808]\n",
      "done for fold29\n",
      "train_width[0.7863041003859131, 18.712136699437295]\n",
      "test_width[0.6108462775500375, 15.616233954270898]\n",
      "smiles_weight0.788287613379178\n",
      "rmse_train[0.17253618466582554, 3.969309728594759]\n",
      "rmse_test[0.15062726491938938, 3.327269649810201]\n",
      "smiles_weight_ci[0.6947630456994037, 0.8506409863573143]\n",
      "done for fold30\n",
      "train_width[0.8399746482054328, 16.24751995522616]\n",
      "test_width[0.636400081740532, 13.66894987935512]\n",
      "smiles_weight0.8677207349069366\n",
      "rmse_train[0.14883851561509, 3.6857567421192994]\n",
      "rmse_test[0.23916613295871228, 3.2804353927701566]\n",
      "smiles_weight_ci[0.7706549215410978, 0.9220077268621837]\n",
      "done for fold32\n",
      "train_width[0.8239805208472818, 16.329510800319948]\n",
      "test_width[0.7023911277261118, 15.07287311747459]\n",
      "smiles_weight0.7845618804389448\n",
      "rmse_train[0.19563585241715983, 4.091959602138649]\n",
      "rmse_test[0.16433130584079295, 5.890778352816412]\n",
      "smiles_weight_ci[0.6939505681053207, 0.8540462512430669]\n",
      "done for fold38\n",
      "train_width[0.9799711856062691, 19.81500616397649]\n",
      "test_width[0.7454541796760042, 16.663312582905252]\n",
      "smiles_weight0.8293075740636925\n",
      "rmse_train[0.21911731207433638, 4.297493193788774]\n",
      "rmse_test[0.22647289979031998, 4.125912360453093]\n",
      "smiles_weight_ci[0.7358969814387275, 0.8958119611900357]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  33 out of  50 | elapsed: 10.4min remaining:  5.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold31\n",
      "train_width[0.7494676878442282, 14.899565450951487]\n",
      "test_width[0.4465375475912631, 11.501841994182096]\n",
      "smiles_weight0.8620460091116382\n",
      "rmse_train[0.1619969454068722, 3.180706581939025]\n",
      "rmse_test[0.15356217716427958, 3.382178009939997]\n",
      "smiles_weight_ci[0.7690178308109582, 0.9109448942364136]\n",
      "done for fold39\n",
      "train_width[1.0345805125331455, 19.610105324459333]\n",
      "test_width[0.6981655128664317, 15.922999971113216]\n",
      "smiles_weight0.8830899338017887\n",
      "rmse_train[0.2055141477843167, 4.238516865489392]\n",
      "rmse_test[0.4134477762069829, 7.36575607262497]\n",
      "smiles_weight_ci[0.7869506541869062, 0.9370753033985033]\n",
      "done for fold37\n",
      "train_width[0.7980128718191105, 15.543197936432863]\n",
      "test_width[0.6382568494213603, 13.964891578066956]\n",
      "smiles_weight0.8230175474650353\n",
      "rmse_train[0.14082690984953664, 4.433505268246651]\n",
      "rmse_test[0.19154199447795603, 5.895113572313701]\n",
      "smiles_weight_ci[0.736895902470599, 0.8844573424410911]\n",
      "done for fold35\n",
      "train_width[0.7930311369896854, 16.650641339575277]\n",
      "test_width[0.6126664570063067, 13.934885384887332]\n",
      "smiles_weight0.8184779518421469\n",
      "rmse_train[0.16654806004973163, 3.8833478281995046]\n",
      "rmse_test[0.14280929991051194, 3.4997509236467743]\n",
      "smiles_weight_ci[0.7328220084760856, 0.8765804365374031]\n",
      "done for fold34\n",
      "train_width[0.780649328801003, 16.014367705526727]\n",
      "test_width[0.6740871032390168, 14.245733634733709]\n",
      "smiles_weight0.8157718517311672\n",
      "rmse_train[0.16194250414728592, 3.9946735998839453]\n",
      "rmse_test[1.0096716866177928, 13.550171722219961]\n",
      "smiles_weight_ci[0.7221523635022217, 0.8863657732628013]\n",
      "done for fold33\n",
      "train_width[0.7734865223823125, 14.887518336679689]\n",
      "test_width[0.4667772171755337, 10.517117466370765]\n",
      "smiles_weight0.8850097357979143\n",
      "rmse_train[0.16179988660141234, 3.536380449888546]\n",
      "rmse_test[0.223371876576046, 3.78869364262115]\n",
      "smiles_weight_ci[0.7896667887761204, 0.9307574373434533]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  39 out of  50 | elapsed: 11.1min remaining:  3.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold36\n",
      "train_width[0.7045612717775518, 13.248476009103014]\n",
      "test_width[0.537544066700329, 11.21754893856171]\n",
      "smiles_weight0.8396593538827849\n",
      "rmse_train[0.16286007763984622, 3.5467523727661994]\n",
      "rmse_test[0.14756145677037338, 3.2073990864903794]\n",
      "smiles_weight_ci[0.7533466448266477, 0.8974114504648555]\n",
      "done for fold43\n",
      "train_width[0.9104394576621412, 19.23044203228581]\n",
      "test_width[0.7732333056673132, 17.61418447388062]\n",
      "smiles_weight0.8094205049824522\n",
      "rmse_train[0.2187220717376831, 4.75094585744699]\n",
      "rmse_test[0.19787042677766623, 4.238248297374717]\n",
      "smiles_weight_ci[0.7013547851384807, 0.8737683927399844]\n",
      "done for fold42\n",
      "train_width[0.930666927935112, 15.261387598636]\n",
      "test_width[0.5970300946582614, 11.857114252551272]\n",
      "smiles_weight0.8641922440697108\n",
      "rmse_train[0.1747330425491649, 4.094292041731957]\n",
      "rmse_test[0.16972901969900434, 3.8162389046957896]\n",
      "smiles_weight_ci[0.7707567902033535, 0.9207783903147835]\n",
      "done for fold40\n",
      "train_width[0.7976607367933605, 15.246730981398253]\n",
      "test_width[0.44226093481954304, 9.867366112775649]\n",
      "smiles_weight0.8918868686154122\n",
      "rmse_train[0.15280778828729047, 3.5375558213948715]\n",
      "rmse_test[0.1695081026981448, 3.829704324113958]\n",
      "smiles_weight_ci[0.8016425182959519, 0.9437461232961879]\n",
      "done for fold44\n",
      "train_width[0.9343312041573337, 18.196617850326298]\n",
      "test_width[0.6305284779910098, 13.804322642664728]\n",
      "smiles_weight0.8720489438124762\n",
      "rmse_train[0.1705280594001389, 4.98972147660925]\n",
      "rmse_test[0.1544802658868869, 3.3246952210733203]\n",
      "smiles_weight_ci[0.783164100428883, 0.9273907567412584]\n",
      "done for fold41\n",
      "train_width[0.5740973071455009, 12.953820806623288]\n",
      "test_width[0.4230157206682718, 10.911878774758982]\n",
      "smiles_weight0.8429843433799308\n",
      "rmse_train[0.11517531249262072, 3.520871759074262]\n",
      "rmse_test[0.17162507462216733, 3.3244557301685047]\n",
      "smiles_weight_ci[0.7524317490620066, 0.8987028232903366]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  45 out of  50 | elapsed: 11.9min remaining:  1.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold47\n",
      "train_width[0.9358551131088968, 19.345412866913833]\n",
      "test_width[0.7339328665930396, 16.23949638082471]\n",
      "smiles_weight0.8400979345209861\n",
      "rmse_train[0.18152466973004858, 4.636274001914887]\n",
      "rmse_test[0.19642851714836673, 4.3953793302603605]\n",
      "smiles_weight_ci[0.7369769151825263, 0.8989710090521675]\n",
      "done for fold49\n",
      "train_width[1.0227528909379073, 21.605950632108325]\n",
      "test_width[0.8090615124982631, 17.97023040128501]\n",
      "smiles_weight0.8123257037332223\n",
      "rmse_train[0.22553732066484317, 5.308249877522639]\n",
      "rmse_test[0.1979336914767578, 4.170666246223914]\n",
      "smiles_weight_ci[0.721041298634362, 0.880570885771976]\n",
      "done for fold46\n",
      "train_width[0.8709195634434983, 17.212127169795608]\n",
      "test_width[0.8064241994142544, 16.520370042882647]\n",
      "smiles_weight0.7996139569097761\n",
      "rmse_train[0.19674500736026748, 4.269467552220937]\n",
      "rmse_test[0.2221304640954859, 3.9971720014603056]\n",
      "smiles_weight_ci[0.7075777093629543, 0.8695076395880544]\n",
      "done for fold45\n",
      "train_width[0.6469365483641017, 13.721425246855636]\n",
      "test_width[0.4474134422360445, 10.779710679107648]\n",
      "smiles_weight0.8095913127282829\n",
      "rmse_train[0.14867010595629562, 3.2348898545008997]\n",
      "rmse_test[0.15165020933085524, 2.946369468560267]\n",
      "smiles_weight_ci[0.7093629165989391, 0.8758502390458173]\n",
      "done for fold48\n",
      "train_width[0.8913223161925947, 13.736388220444537]\n",
      "test_width[0.46817388880798344, 10.114689657914226]\n",
      "smiles_weight0.8794184246566555\n",
      "rmse_train[0.1593694636628282, 3.6317590927405177]\n",
      "rmse_test[0.21059471652287656, 3.296557184161756]\n",
      "smiles_weight_ci[0.7793393062634, 0.9341360951682889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  50 out of  50 | elapsed: 14.0min finished\n"
     ]
    }
   ],
   "source": [
    "catch_all = Parallel(n_jobs = 15, verbose = 10)(delayed(get_results)(idx,var_weights = 1.0, var_weight_weights = 3.0, inflation_factor =1.0) for idx in range(0,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f857358-e5f0-4d43-bf0a-d4d7d034cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ee2282b-2100-4ed9-972b-ea78eabe2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_all[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "857dc418-a018-4330-868a-47ae36a9f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e456d98-c381-450b-964d-fdbdbd1bd45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_catch = []\n",
    "for item in catch_all:\n",
    "    catch_inner = []\n",
    "    for inner in item:\n",
    "        if type(inner) == list:\n",
    "            for inner1 in inner:\n",
    "                catch_inner.append(inner1)\n",
    "        if type(inner) != list:\n",
    "            catch_inner.append(inner)\n",
    "    all_catch.append(catch_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b17ec0ba-5448-4130-b54f-c8cf20f76128",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(all_catch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "21f8792e-1721-412d-a84e-39bf7ad3c070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 15)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "610306d1-f54e-42be-86c2-70ef6d4fdd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6accc813-8aa7-48a0-abae-f89b6e5f5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.iloc[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "81b223ac-16c3-4547-bb99-9a2e08bbb03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"Alop_Train_Width\", \"PSA_Train_Width\", \"Alop_Train_Coverage\", \"PSA_Train_Coverage\", \n",
    "            \"Alop_Train_RMSE\", \"PSA_Train_RMSE\", \"Alop_Test_Width\", \"PSA_Test_Width\", \"Alop_Test_Coverage\", \"PSA_Test_Coverage\", \n",
    "            \"Alop_Test_RMSE\", \"PSA_Test_RMSE\", \"Smiles_Avg_Weight\", \"Lower_Interval_Smiles_Weight\", \"Upper_Interval_Smiles_Weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1124c374-99bf-4282-9e32-1074a5033ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e52823b-19de-4bed-ae04-519af1d5021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a4fd350f-4f0a-4f9a-af19-52590d875782",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"indicator\"] = (results_df[\"Lower_Interval_Smiles_Weight\"].values < 0.80) & (results_df[\"Upper_Interval_Smiles_Weight\"].values >= 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b5283a6-b5f6-4752-a693-9b1dea85ba9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results_df[\"indicator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cc59d51b-355c-47af-af15-34da30579a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.read_csv(\"..//Data//smiles_rdkit_80_20__with_cov_minus_0.2_Simulation_added_beat_noise.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "272ba30f-cb1b-4356-9b74-38683acfef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"width_weight_CI\"] = results_df[\"Upper_Interval_Smiles_Weight\"].values - results_df[\"Lower_Interval_Smiles_Weight\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "033f4b53-811b-4faa-8331-be8978b24454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f36d6343-cfa2-475d-a8dd-01007676f993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alop_Train_Width</td>\n",
       "      <td>0.827092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PSA_Train_Width</td>\n",
       "      <td>16.119311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alop_Train_Coverage</td>\n",
       "      <td>0.963894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PSA_Train_Coverage</td>\n",
       "      <td>0.951961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alop_Train_RMSE</td>\n",
       "      <td>0.172813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PSA_Train_RMSE</td>\n",
       "      <td>3.957806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alop_Test_Width</td>\n",
       "      <td>0.605736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PSA_Test_Width</td>\n",
       "      <td>13.401880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alop_Test_Coverage</td>\n",
       "      <td>0.906167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PSA_Test_Coverage</td>\n",
       "      <td>0.939750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alop_Test_RMSE</td>\n",
       "      <td>0.227104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PSA_Test_RMSE</td>\n",
       "      <td>4.288565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Smiles_Avg_Weight</td>\n",
       "      <td>0.841215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lower_Interval_Smiles_Weight</td>\n",
       "      <td>0.748243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Upper_Interval_Smiles_Weight</td>\n",
       "      <td>0.900110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>indicator</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>width_weight_CI</td>\n",
       "      <td>0.151867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           index          0\n",
       "0               Alop_Train_Width   0.827092\n",
       "1                PSA_Train_Width  16.119311\n",
       "2            Alop_Train_Coverage   0.963894\n",
       "3             PSA_Train_Coverage   0.951961\n",
       "4                Alop_Train_RMSE   0.172813\n",
       "5                 PSA_Train_RMSE   3.957806\n",
       "6                Alop_Test_Width   0.605736\n",
       "7                 PSA_Test_Width  13.401880\n",
       "8             Alop_Test_Coverage   0.906167\n",
       "9              PSA_Test_Coverage   0.939750\n",
       "10                Alop_Test_RMSE   0.227104\n",
       "11                 PSA_Test_RMSE   4.288565\n",
       "12             Smiles_Avg_Weight   0.841215\n",
       "13  Lower_Interval_Smiles_Weight   0.748243\n",
       "14  Upper_Interval_Smiles_Weight   0.900110\n",
       "15                     indicator   0.960000\n",
       "16               width_weight_CI   0.151867"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "219dc442-7e2b-4fd0-952d-fe7676e77a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# results_df = pd.read_csv(\"..//Data//smiles_rdkit_80_20__with_cov_minus_0.2_Simulation_added_beat_noise.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0636ac66-6077-4a54-9423-542338c64072",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"..//Data//smiles_rdkit_80_20__with_cov_minus_0.2_Simulation_added_beat_noise.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c862684b-36b7-4cb5-9a6c-bd877cce7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(\"..//Data//smiles_rdkit_80_20__with_cov_minus_0.2_Simulation_added_beat_noise.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "01c13c40-04e4-405d-86b4-f6eee24b0e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alop_Train_Width</th>\n",
       "      <th>PSA_Train_Width</th>\n",
       "      <th>Alop_Train_Coverage</th>\n",
       "      <th>PSA_Train_Coverage</th>\n",
       "      <th>Alop_Train_RMSE</th>\n",
       "      <th>PSA_Train_RMSE</th>\n",
       "      <th>Alop_Test_Width</th>\n",
       "      <th>PSA_Test_Width</th>\n",
       "      <th>Alop_Test_Coverage</th>\n",
       "      <th>PSA_Test_Coverage</th>\n",
       "      <th>Alop_Test_RMSE</th>\n",
       "      <th>PSA_Test_RMSE</th>\n",
       "      <th>Smiles_Avg_Weight</th>\n",
       "      <th>Lower_Interval_Smiles_Weight</th>\n",
       "      <th>Upper_Interval_Smiles_Weight</th>\n",
       "      <th>indicator</th>\n",
       "      <th>width_weight_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.804960</td>\n",
       "      <td>13.702818</td>\n",
       "      <td>0.983310</td>\n",
       "      <td>0.919332</td>\n",
       "      <td>0.118902</td>\n",
       "      <td>3.723554</td>\n",
       "      <td>0.483435</td>\n",
       "      <td>10.635397</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.205710</td>\n",
       "      <td>3.121492</td>\n",
       "      <td>0.890841</td>\n",
       "      <td>0.800610</td>\n",
       "      <td>0.939603</td>\n",
       "      <td>False</td>\n",
       "      <td>0.138994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.797661</td>\n",
       "      <td>15.246731</td>\n",
       "      <td>0.965229</td>\n",
       "      <td>0.954103</td>\n",
       "      <td>0.152808</td>\n",
       "      <td>3.537556</td>\n",
       "      <td>0.442261</td>\n",
       "      <td>9.867366</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.169508</td>\n",
       "      <td>3.829704</td>\n",
       "      <td>0.891887</td>\n",
       "      <td>0.801643</td>\n",
       "      <td>0.943746</td>\n",
       "      <td>False</td>\n",
       "      <td>0.142104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Alop_Train_Width  PSA_Train_Width  Alop_Train_Coverage   \n",
       "24          0.804960        13.702818             0.983310  \\\n",
       "40          0.797661        15.246731             0.965229   \n",
       "\n",
       "    PSA_Train_Coverage  Alop_Train_RMSE  PSA_Train_RMSE  Alop_Test_Width   \n",
       "24            0.919332         0.118902        3.723554         0.483435  \\\n",
       "40            0.954103         0.152808        3.537556         0.442261   \n",
       "\n",
       "    PSA_Test_Width  Alop_Test_Coverage  PSA_Test_Coverage  Alop_Test_RMSE   \n",
       "24       10.635397            0.837500           0.916667        0.205710  \\\n",
       "40        9.867366            0.808333           0.862500        0.169508   \n",
       "\n",
       "    PSA_Test_RMSE  Smiles_Avg_Weight  Lower_Interval_Smiles_Weight   \n",
       "24       3.121492           0.890841                      0.800610  \\\n",
       "40       3.829704           0.891887                      0.801643   \n",
       "\n",
       "    Upper_Interval_Smiles_Weight  indicator  width_weight_CI  \n",
       "24                      0.939603      False         0.138994  \n",
       "40                      0.943746      False         0.142104  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df[\"indicator\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b0011c31-34af-4b51-96ea-cb85310115ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alop_Train_Width</td>\n",
       "      <td>0.827092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PSA_Train_Width</td>\n",
       "      <td>16.119311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alop_Train_Coverage</td>\n",
       "      <td>0.963894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PSA_Train_Coverage</td>\n",
       "      <td>0.951961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alop_Train_RMSE</td>\n",
       "      <td>0.172813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PSA_Train_RMSE</td>\n",
       "      <td>3.957806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alop_Test_Width</td>\n",
       "      <td>0.605736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PSA_Test_Width</td>\n",
       "      <td>13.401880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alop_Test_Coverage</td>\n",
       "      <td>0.906167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PSA_Test_Coverage</td>\n",
       "      <td>0.939750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alop_Test_RMSE</td>\n",
       "      <td>0.227104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PSA_Test_RMSE</td>\n",
       "      <td>4.288565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Smiles_Avg_Weight</td>\n",
       "      <td>0.841215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lower_Interval_Smiles_Weight</td>\n",
       "      <td>0.748243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Upper_Interval_Smiles_Weight</td>\n",
       "      <td>0.900110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>indicator</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>width_weight_CI</td>\n",
       "      <td>0.151867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           index          0\n",
       "0               Alop_Train_Width   0.827092\n",
       "1                PSA_Train_Width  16.119311\n",
       "2            Alop_Train_Coverage   0.963894\n",
       "3             PSA_Train_Coverage   0.951961\n",
       "4                Alop_Train_RMSE   0.172813\n",
       "5                 PSA_Train_RMSE   3.957806\n",
       "6                Alop_Test_Width   0.605736\n",
       "7                 PSA_Test_Width  13.401880\n",
       "8             Alop_Test_Coverage   0.906167\n",
       "9              PSA_Test_Coverage   0.939750\n",
       "10                Alop_Test_RMSE   0.227104\n",
       "11                 PSA_Test_RMSE   4.288565\n",
       "12             Smiles_Avg_Weight   0.841215\n",
       "13  Lower_Interval_Smiles_Weight   0.748243\n",
       "14  Upper_Interval_Smiles_Weight   0.900110\n",
       "15                     indicator   0.960000\n",
       "16               width_weight_CI   0.151867"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "747d11c8-4f75-4ec9-aacc-930747d74047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5cb7839f-ac6e-4930-85ec-e58da91ec1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
