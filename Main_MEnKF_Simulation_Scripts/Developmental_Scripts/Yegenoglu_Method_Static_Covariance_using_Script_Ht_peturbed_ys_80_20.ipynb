{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "aa53e19a-64db-4b1d-9378-c19c8efacd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import block_diag\n",
    "import warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a6028973-9799-4d8a-b919-a8dd6283faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d459b853-f520-4181-a9a9-310a6dd20de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, initial_ensembles, size_ens): \n",
    "    \n",
    "    target_dim = 1\n",
    "    \n",
    "    # weights_ann_1 = ann.get_weights()\n",
    "    \n",
    "    # h1  = ann.layers[1].output.shape[-1]\n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "    \n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "    \n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, target_dim)\n",
    "\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + target_dim)].reshape(size_ens, 1, target_dim)\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "    \n",
    "    final_output_1 = final_output_1[:,:, 0]\n",
    "    \n",
    "    # print(final_output_1.shape, initial_ensembles.shape)\n",
    "    \n",
    "    stack = np.hstack((final_output_1, initial_ensembles))\n",
    "\n",
    "    \n",
    "    return final_output_1, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2a66ee4c-4112-4dca-a9cc-68a60d4e316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 32, input_shape = 256, output_shape = 1): \n",
    "    input_layer = tf.keras.layers.Input(shape = (input_shape))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(output_shape, activation = \"relu\")\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e0b9ef03-af61-4ce4-99ff-2f0b5dca639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_ensembles(num_weights, lambda1, size_ens):\n",
    "    mean_vec = np.zeros((num_weights,))\n",
    "    cov_matrix = lambda1*np.identity(num_weights)\n",
    "    mvn_samp = mvn(mean_vec, cov_matrix)\n",
    "    return mvn_samp.rvs(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fe2ea2b5-13a4-41c4-8257-c6c18708501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "758ac30a-bcc7-4b5e-9314-7fb85f284f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_ann =  ann(hidden = 16, input_shape = 32, output_shape = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "2548f2de-a4c3-4850-b5cc-439634f5c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ann_1 = samp_ann.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1338dc89-5540-4867-95a6-3d0ea7639cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1  = samp_ann.layers[1].output.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "427b0370-90df-4ab4-85b9-691d082750bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_ann.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a71c4646-23a6-45ca-9ccc-aa4c3566d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_ann_params = samp_ann.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b5f741d7-ba99-4803-8441-5bf2ad3d72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_X_t(data1, data2, size_ens, var_weights = 2.0):\n",
    "    \n",
    "    initial_ensembles1 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data1_out1, data1_stack1 = get_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens)\n",
    "    \n",
    "    initial_ensembles2 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data1_out2, data1_stack2 = get_targets_with_weights(data1, initial_ensembles2, size_ens = size_ens)\n",
    "    \n",
    "    initial_ensembles3 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data2_out1, data2_stack1 = get_targets_with_weights(data2, initial_ensembles3, size_ens = size_ens)\n",
    "    \n",
    "    initial_ensembles4 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data2_out2, data2_stack2 = get_targets_with_weights(data2, initial_ensembles4, size_ens = size_ens)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles_for_weights = generate_initial_ensembles(4, var_weights, size_ens)\n",
    "    \n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights), axis = 1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4))\n",
    "    \n",
    "    return X_t, initial_ensembles, initial_ensembles_for_weights[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6ac49c8c-6da0-4ee2-9561-e1d19365f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_targets_with_weights(batch_data, initial_ensembles, size_ens, weights): \n",
    "    \n",
    "    target_dim = 1\n",
    "    \n",
    "    # weights_ann_1 = ann.get_weights()\n",
    "    \n",
    "    # h1  = ann.layers[1].output.shape[-1]\n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "    \n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "    \n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, target_dim)\n",
    "\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + target_dim)].reshape(size_ens, 1, target_dim)\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "    \n",
    "    final_output_1 = final_output_1[:,:, 0]\n",
    "    \n",
    "    final_output_1 = final_output_1*weights\n",
    "    \n",
    "    # print(final_output_1.shape, initial_ensembles.shape)\n",
    "    \n",
    "    stack = np.hstack((final_output_1, initial_ensembles))\n",
    "\n",
    "    \n",
    "    return final_output_1, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b697b7f9-3d50-4d71-a436-cdc6434909a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_targets = pickle.load( open('..//Data//target_scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9ace8608-8da1-4b4e-b051-a7b49feae636",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_t = np.array([[0.02, 0], [0, 0.02]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d156603a-c127-45b6-a74d-2735987d03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = R_t[0,0]\n",
    "var2 = R_t[1,1]\n",
    "cov = R_t[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9d1a4f5e-7a0d-42b7-ad45-59c708b7b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_operation(data1, data2, combined_ensembles , size_ens ):\n",
    "    params = samp_ann_params\n",
    "    initial_ensembles1 = combined_ensembles[:, :params]\n",
    "    initial_ensembles2 = combined_ensembles[:, params:(2*params)]\n",
    "    initial_ensembles3 = combined_ensembles[:, (2*params):(3*params)]\n",
    "    initial_ensembles4 = combined_ensembles[:, (3*params):(4*params)]\n",
    "\n",
    "    \n",
    "    initial_ensembles_for_weights = combined_ensembles[:, (4*params):]\n",
    "    softmax_weights = tf.math.softmax(initial_ensembles_for_weights).numpy()\n",
    "    \n",
    "    model_1 = softmax_weights[:,:2].sum(1).reshape(-1,1)\n",
    "    \n",
    "    model_2 = softmax_weights[:,2:].sum(1).reshape(-1,1)\n",
    "    \n",
    "    data1_out1, data1_stack1 = get_weighted_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens,\n",
    "                                                                 weights=model_1)\n",
    "    \n",
    "    data1_out2, data1_stack2 = get_weighted_targets_with_weights(data1, initial_ensembles2, size_ens = size_ens,\n",
    "                                                                  weights=model_1)\n",
    "    \n",
    "    data2_out1, data2_stack1 = get_weighted_targets_with_weights(data2, initial_ensembles3, size_ens = size_ens,\n",
    "                                                                  weights=model_2)\n",
    "    \n",
    "    data2_out2, data2_stack2 = get_weighted_targets_with_weights(data2, initial_ensembles4, size_ens = size_ens,\n",
    "                                                                  weights=model_2)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4, \n",
    "                        initial_ensembles_for_weights))\n",
    "    \n",
    "    # print(X_t.shape)\n",
    "    \n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    # print(initial_ensembles_for_weights.shape)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights), axis = 1)\n",
    "    \n",
    "    weighted_alogp = data1_out1 + data2_out1\n",
    "    \n",
    "    weighted_psa = data1_out2 + data2_out2\n",
    "    \n",
    "    return X_t, initial_ensembles, weighted_alogp, weighted_psa, model_1, model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e15b0bf7-ba00-40bc-933b-c1c3e062e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samp_ann =  ann(hidden = 16, input_shape = 32, output_shape = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "af3dd570-7ab3-4eae-bd8e-9a57a333b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = samp_ann.count_params()*4 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e820b010-4396-4b7a-8781-a8e6d503aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e5fbaaf7-afae-4008-a26c-e0691ef9b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = total_weights//reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a5111536-1a97-4390-9658-c9848a136a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3f598992-73d6-4b5a-906d-3184f1b9625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_t = [[1, 0, 1, 0], [0, 1, 0, 1]]\n",
    "G_t = np.array(G_t).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3073d2ce-5b22-47bb-80a3-9ad86ac3d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a84cb0e3-2f5e-4207-b092-d2768b52205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data1, data2, initial_ensembles): \n",
    "    _,_, weighted_alogp, weighted_psa, w1, w2 = forward_operation(data1, data2, initial_ensembles, size_ens = size_ens)\n",
    "    weighted_alogp = np.expand_dims(weighted_alogp,-1)\n",
    "    weighted_psa = np.expand_dims(weighted_psa,-1)\n",
    "    preds = np.concatenate((weighted_alogp, weighted_psa),-1)\n",
    "    return preds, w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3af0a9b9-6202-40e2-911f-3c890213099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mu_bar_G_bar(data1, data2, initial_ensembles):\n",
    "    H_t = np.hstack((np.identity(data1.shape[0]), np.zeros((data1.shape[0], samp_ann_params + 1))))\n",
    "    mu_bar = initial_ensembles.mean(0)\n",
    "    X_t,_, _, _, _, _ = forward_operation(data1, data2, initial_ensembles, size_ens = size_ens)\n",
    "    X_t = X_t.transpose((0,2,1))\n",
    "    X_t = X_t.reshape(X_t.shape[0], X_t.shape[1]*X_t.shape[2])\n",
    "    script_H_t = np.kron(G_t.T, H_t)\n",
    "    G_u = (script_H_t@X_t.T)\n",
    "    G_u = G_u.T\n",
    "    G_bar = (G_u.mean(0)).ravel()\n",
    "    return mu_bar.reshape(-1,1), G_bar.reshape(-1,1), G_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "7334c80c-cfcd-4d5b-b844-11cfb8c137df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_C_u(initial_ensembles, mu_bar, G_bar, G_u): \n",
    "    u_j_minus_u_bar = initial_ensembles - mu_bar.reshape(1,-1)\n",
    "    G_u_minus_G_bar = G_u -  G_bar.reshape(1,-1)\n",
    "    c = np.zeros((total_weights, G_bar.shape[0]))\n",
    "    for i in range(0, size_ens): \n",
    "        c += np.kron(u_j_minus_u_bar[i, :].T.reshape(-1,1), G_u_minus_G_bar[i,:].reshape(-1,1).T)\n",
    "    return c/size_ens, G_u_minus_G_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "9148779c-1a3f-455d-a6ad-00fc1bf69c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_D_u( G_bar, G_u): \n",
    "    G_u_minus_G_bar = G_u -  G_bar.reshape(1,-1)\n",
    "    d = np.zeros((G_bar.shape[0], G_bar.shape[0]))\n",
    "    for i in range(0, size_ens): \n",
    "        d += np.kron(G_u_minus_G_bar[i,:].T.reshape(-1,1), G_u_minus_G_bar[i,:].reshape(-1,1).T)\n",
    "    return d/size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "6e8459b0-68c1-4d1f-851e-3d7b99f0ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_updated_ensemble(data1, data2, initial_ensembles, R_t, y_train, size_ens = size_ens, inflation_factor = 1.0):\n",
    "    mu_bar, G_bar, G_u = calculate_mu_bar_G_bar(data1, data2, initial_ensembles)\n",
    "    C, G_u_minus_G_bar = calculate_C_u(initial_ensembles, mu_bar, G_bar, G_u)\n",
    "    D = calculate_D_u( G_bar, G_u)\n",
    "    # _, R_t = create_cov(data1.shape[0],initial_ensembles)\n",
    "    # all_covs = np.array(all_covs)\n",
    "    inflation = np.identity(R_t.shape[0])*inflation_factor\n",
    "    D_plus_cov = D + (R_t *inflation_factor)\n",
    "    D_plus_cov_inv = np.linalg.inv(D_plus_cov)\n",
    "    mid_quant = C@D_plus_cov_inv\n",
    "    noise_vec_mean = np.zeros((R_t.shape[0], ))\n",
    "    noise_mvn = mvn(noise_vec_mean, R_t)\n",
    "    fudging = noise_mvn.rvs(size_ens)\n",
    "    interim = (y_train.T.flatten().reshape(1,-1) + fudging)\n",
    "    right_quant = interim - G_u\n",
    "    # print(mid_quant.shape, right_quant.shape)\n",
    "    mid_times_right = mid_quant@right_quant.T\n",
    "    updated_ensemble = (initial_ensembles + mid_times_right.T)\n",
    "    return updated_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c14b236d-6ebf-40e3-9085-97afd2990e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "346d07bc-5b61-4e75-a816-a6e22ffe9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_D = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "dc3a216a-4dbb-474d-8219-5f6c071250a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(data, idx):\n",
    "    data_cur = data[idx, :, :]\n",
    "    inv_data_cur = std_targets.inverse_transform(data_cur)\n",
    "    return inv_data_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5abd35fb-ea92-449d-894a-162ed1f4aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ed1f9938-cdc5-400f-8bab-22c180a6d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"..//Data//smiles_to_rdkit_80_20.pickle\", \"rb\") as f: \n",
    "    catch = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7c59ea29-6484-40d5-8777-80cf9ca6cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "176445fb-4f30-421a-a710-339955111baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(idx): \n",
    "    catch_idx = catch[idx]\n",
    "    x_train, x_valid, y_train, y_valid = catch_idx[0], catch_idx[1], catch_idx[2], catch_idx[3]\n",
    "    y_train_actual, y_train = y_train[:,:2], y_train[:,2:]\n",
    "    y_valid_actual, y_valid = y_valid[:,:2], y_valid[:,2:]\n",
    "    smiles_feats_train = x_train[:, :32]\n",
    "    rdkit_feats_train = x_train[:, 32:]\n",
    "    smiles_feats_valid = x_valid[:, :32]\n",
    "    rdkit_feats_valid = x_valid[:, 32:]\n",
    "    ul = var1*np.identity(x_train.shape[0])\n",
    "    lr = var2*np.identity(x_train.shape[0])\n",
    "    ur = cov*np.identity(x_train.shape[0])\n",
    "    ll = ur.T\n",
    "    first_row = np.hstack((ul, ur))\n",
    "    second_row = np.hstack((ll, lr))\n",
    "    R_t = np.vstack((first_row, second_row))\n",
    "    X_t, initial_ensembles, initial_ensembles_for_weights = get_initial_X_t(smiles_feats_train, rdkit_feats_train, size_ens = size_ens)\n",
    "    initial_ensembles = np.hstack((initial_ensembles, initial_ensembles_for_weights))\n",
    "    \n",
    "    return smiles_feats_train, rdkit_feats_train, smiles_feats_valid, rdkit_feats_valid, y_train, y_train_actual, y_valid, y_valid_actual, R_t, initial_ensembles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "65bf21e9-92c6-4824-93c3-87274b072afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(idx):\n",
    "    smiles_feats_train, rdkit_feats_train, smiles_feats_valid, rdkit_feats_valid, y_train, y_train_actual, y_valid, y_valid_actual, R_t, initial_ensembles  = prepare_data(idx)\n",
    "    # print(R_t.shape)\n",
    "    best_train_width_mean = 100000\n",
    "    \n",
    "    for i in range(0,10000):\n",
    "        # print(i)\n",
    "    \n",
    "        initial_ensembles = get_updated_ensemble(smiles_feats_train, rdkit_feats_train, initial_ensembles, R_t, y_train)\n",
    "        G_u_train, w1, w2 = get_predictions(smiles_feats_train, rdkit_feats_train, initial_ensembles)\n",
    "\n",
    "        catch = Parallel(n_jobs = 15, verbose = 0)(delayed(inverse_transform)(G_u_train, i)  for i in range(G_u_train.shape[0]))\n",
    "        G_u_train = np.array(catch)\n",
    "    \n",
    "        y_train_cur = std_targets.inverse_transform(y_train_actual)\n",
    "    \n",
    "        li_train = np.percentile(G_u_train, axis = 0, q = (2.5, 97.5))[0,:,:]   \n",
    "        ui_train = np.percentile(G_u_train, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "    \n",
    "        width_train = ui_train - li_train\n",
    "        avg_width_train = width_train.mean(0)\n",
    "    \n",
    "        ind_train = (y_train_cur >= li_train) & (y_train_cur <= ui_train)\n",
    "        coverage_train= ind_train.mean(0)\n",
    "    \n",
    "        averaged_targets_train = G_u_train.mean(0)\n",
    "        rmse_train = np.sqrt(((y_train_cur -averaged_targets_train)**2).mean(0))\n",
    "\n",
    "    \n",
    "        G_u_test, _, _ = get_predictions(smiles_feats_valid, rdkit_feats_valid, initial_ensembles)\n",
    "    \n",
    "        catch = Parallel(n_jobs = 15, verbose = 0)(delayed(inverse_transform)(G_u_test, i)  for i in range(G_u_test.shape[0]))\n",
    "        G_u_test = np.array(catch)\n",
    "    \n",
    "        y_valid_cur = std_targets.inverse_transform(y_valid_actual)    \n",
    "    \n",
    "        li_test = np.percentile(G_u_test, axis = 0, q = (2.5, 97.5))[0,:,:]   \n",
    "        ui_test = np.percentile(G_u_test, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "        \n",
    "        # print(li_test.shape)\n",
    "        \n",
    "        \n",
    "        width_test = ui_test - li_test\n",
    "        avg_width_test = width_test.mean(0)\n",
    "    \n",
    "        ind_test = (y_valid_cur >= li_test) & (y_valid_cur <= ui_test)\n",
    "        coverage_test= ind_test.mean(0)\n",
    "    \n",
    "        averaged_targets_test = G_u_test.mean(0)\n",
    "        rmse_test = np.sqrt(((y_valid_cur -averaged_targets_test)**2).mean(0))    \n",
    "        \n",
    "        \n",
    "        # print(w1.shape)\n",
    "        \n",
    "        li_smiles_weight = np.percentile(w1, axis = 0, q = (2.5, 97.5))[0][0]\n",
    "        \n",
    "        # print(np.percentile(w1, axis = 0, q = (2.5, 97.5)))\n",
    "        \n",
    "        ui_smiles_weight = np.percentile(w1, axis = 0, q = (2.5, 97.5))[1][0]      \n",
    "        \n",
    "        print(coverage_train.tolist(), avg_width_train.tolist(), rmse_train.tolist())\n",
    "        print(coverage_test.tolist(), avg_width_test.tolist(), rmse_test.tolist())\n",
    "        print(w1.mean())\n",
    "        print(li_smiles_weight, ui_smiles_weight)\n",
    "        # print(avg_width_train.tolist(), coverage_train.tolist(), rmse_train.tolist(), avg_width_test.tolist(), coverage_test.tolist(), rmse_test.tolist(), w1.mean())\n",
    "\n",
    "        if (avg_width_train.mean() < best_train_width_mean) & (coverage_train.mean() > 0.95): \n",
    "            # print(\"went here\")\n",
    "            best_train_width_mean = avg_width_train.mean()\n",
    "            best_train_width = avg_width_train\n",
    "            best_smiles_weight = w1.mean()\n",
    "            best_coverage_train = coverage_train\n",
    "            best_rmse_train = rmse_train\n",
    "        \n",
    "            best_test_width = avg_width_test\n",
    "\n",
    "            best_coverage_test = coverage_test    \n",
    "            best_rmse_test = rmse_test\n",
    "            \n",
    "            best_li_smiles_weight = li_smiles_weight\n",
    "            \n",
    "            best_ui_smiles_weight = ui_smiles_weight\n",
    "    \n",
    "        if coverage_train.mean() < 0.95:\n",
    "            # print(best_train_width.tolist(), best_coverage_train.tolist(), best_rmse_train.tolist(), best_test_width.tolist(), best_coverage_test.tolist(), best_rmse_test.tolist(), best_smiles_weight, flush = True)\n",
    "            # print(\"\\n\")\n",
    "            return [best_train_width.tolist(), best_coverage_train.tolist(), best_rmse_train.tolist(), best_test_width.tolist(), best_coverage_test.tolist(), best_rmse_test.tolist(), best_smiles_weight, best_li_smiles_weight, best_ui_smiles_weight]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "14658528-ea1a-4a6f-83bd-f708df0bcd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0] [189.113286076157, 4438.591797372838] [2.667649680095705, 141.58844013281714]\n",
      "[1.0, 1.0] [199.4156945694068, 4677.753482579997] [2.677499489119128, 147.38520009517674]\n",
      "0.6041158733756737\n",
      "0.16685116222379176 0.9432592557051122\n",
      "[1.0, 1.0] [127.87360784117705, 2803.1129239616957] [3.7281359410529293, 68.96911579825672]\n",
      "[1.0, 1.0] [135.82314222384554, 2964.9327401234864] [3.953339451591571, 76.25912666578958]\n",
      "0.6464235530721558\n",
      "0.24187400958089786 0.939468289251671\n",
      "[1.0, 1.0] [94.40082116282957, 2108.1891072814174] [2.288943898508224, 59.768367747301255]\n",
      "[1.0, 1.0] [100.14623382551191, 2229.2056727276017] [2.4836177829408363, 66.8280855823792]\n",
      "0.6662588829257707\n",
      "0.29848455540984387 0.9383229772322498\n",
      "[1.0, 1.0] [80.70587668350178, 1735.9934892340218] [1.8812871118747396, 42.07628434202537]\n",
      "[1.0, 1.0] [85.18514016157476, 1841.7486390055703] [2.069239356162358, 43.6079587686961]\n",
      "0.6902412489308509\n",
      "0.38516848854488156 0.9397151223602048\n",
      "[1.0, 1.0] [65.95244585619217, 1505.3835781580465] [1.7310352024327036, 41.91550410838595]\n",
      "[1.0, 1.0] [69.54974418520914, 1578.7889644927475] [1.918050225485504, 42.473721178547194]\n",
      "0.6966013062227264\n",
      "0.4182656297324575 0.9372589239125554\n",
      "[1.0, 1.0] [58.426831599251585, 1303.166620651866] [1.6163775260415931, 42.45143231605919]\n",
      "[1.0, 1.0] [61.48875372340698, 1371.9533504027893] [1.7944272611111256, 44.50434920411977]\n",
      "0.7055546617425893\n",
      "0.4303734260030263 0.9408474898888683\n",
      "[1.0, 1.0] [52.61266279221754, 1194.974416159142] [1.3843265257440682, 37.86386095165012]\n",
      "[1.0, 1.0] [55.42500970482237, 1249.4671866929598] [1.510457654160863, 41.03005997626439]\n",
      "0.7021031993425711\n",
      "0.4278587345539596 0.9336137600774809\n",
      "[1.0, 1.0] [47.299803405144324, 1054.6566317105626] [1.5312630917809407, 38.61125495648202]\n",
      "[1.0, 1.0] [49.98545174464544, 1106.7062272042415] [1.6718595632403097, 42.062890294149675]\n",
      "0.701865437118175\n",
      "0.43429153760178174 0.9348346469717305\n",
      "[1.0, 1.0] [42.3540758301158, 993.0823940770873] [1.420637155445815, 37.09974525774055]\n",
      "[1.0, 1.0] [44.5441065230589, 1043.628462596456] [1.5279523314441557, 39.250002417296365]\n",
      "0.7065510957797159\n",
      "0.4476346098807573 0.9345453622892341\n",
      "[1.0, 1.0] [38.002775299435804, 916.9362793696544] [1.354399917157767, 36.44988968096338]\n",
      "[1.0, 1.0] [40.228291177563996, 961.7730938977226] [1.466299638200694, 37.522248247829175]\n",
      "0.7082199506375609\n",
      "0.4774391142915849 0.9233410727925013\n",
      "[1.0, 1.0] [35.4400925769268, 861.6991925797215] [0.9546515014199561, 35.076008610696086]\n",
      "[1.0, 1.0] [37.426842305009544, 903.7669305562315] [1.062344281227967, 36.89729442133698]\n",
      "0.7098947049956114\n",
      "0.48936849435169955 0.9331288508140465\n",
      "[1.0, 1.0] [31.855846605822265, 763.7022322532118] [0.9055755396521975, 33.69949184493809]\n",
      "[1.0, 1.0] [33.44122341497571, 799.1406911513797] [0.9920167143124563, 37.02559180229172]\n",
      "0.7182655518621988\n",
      "0.5121423349975734 0.9381771867236568\n",
      "[1.0, 1.0] [29.478680766424745, 687.8264973038767] [0.8418862687167471, 34.22154168799333]\n",
      "[1.0, 1.0] [30.842021090649478, 721.7372352742218] [0.9332577097307113, 36.99497056293543]\n",
      "0.7260577131009608\n",
      "0.5281469987060758 0.9298462070160194\n",
      "[1.0, 1.0] [27.384060461355542, 618.9297491155442] [0.7544183085603978, 33.69807060814871]\n",
      "[1.0, 1.0] [28.85032294766945, 648.5829646850068] [0.8508473710950645, 36.849899973013095]\n",
      "0.725506935375579\n",
      "0.5364434874932714 0.9206995964906806\n",
      "[1.0, 1.0] [23.659736479694626, 533.1339018257594] [0.713271947347222, 25.703878997227033]\n",
      "[1.0, 1.0] [25.031901971137994, 558.7659433492946] [0.7974882834813185, 29.127665451999427]\n",
      "0.7308216352470593\n",
      "0.5491618541806776 0.9241644740939324\n",
      "[1.0, 1.0] [19.836039120957842, 458.5663053888864] [0.7530749973218411, 25.653862604590056]\n",
      "[1.0, 1.0] [20.835121489751206, 481.1092382977106] [0.8455556229195127, 28.239604062293356]\n",
      "0.7458326329858465\n",
      "0.580822292320104 0.9254956402053401\n",
      "[1.0, 1.0] [17.046329469358888, 398.535831310168] [0.6870711095005075, 23.13558410833554]\n",
      "[1.0, 1.0] [17.933990405524145, 419.5911729013077] [0.7600733725968863, 25.515532043396714]\n",
      "0.747355038297926\n",
      "0.5737423267224765 0.9112158069693831\n",
      "[1.0, 1.0] [15.293068612463802, 338.2956036707988] [0.6606356973595673, 20.2023290949414]\n",
      "[1.0, 1.0] [15.988455214962089, 355.85819537895] [0.7248052239174596, 22.083188412577236]\n",
      "0.7573223096483078\n",
      "0.6061445445931636 0.9123861496592928\n",
      "[1.0, 1.0] [11.903846432803451, 266.69750318890493] [0.4660502263295183, 16.912969134630632]\n",
      "[1.0, 1.0] [12.478739187563043, 279.14031580804425] [0.4693400091124274, 18.20867497463788]\n",
      "0.7695293754310454\n",
      "0.6429900485202162 0.90066317503605\n",
      "[1.0, 1.0] [9.550528031819018, 211.69618679708697] [0.3916463240876746, 19.086509686472954]\n",
      "[1.0, 1.0] [10.046081866427576, 221.41055083655908] [0.40030771231089096, 19.487294324344195]\n",
      "0.7887440405351465\n",
      "0.6911150796503963 0.9009756550010574\n",
      "[1.0, 1.0] [7.318390910968206, 173.60093385738344] [0.42340097326239534, 18.726944103737537]\n",
      "[1.0, 1.0] [7.618297185830633, 181.0814751438801] [0.43184506053366106, 19.390947175170485]\n",
      "0.7867933440022533\n",
      "0.7002443170203413 0.8913950012199833\n",
      "[1.0, 1.0] [5.2392021008632295, 129.05945457812004] [0.4038453234431881, 8.149141498736109]\n",
      "[1.0, 1.0] [5.4914729827737006, 134.60429640225794] [0.35627123549157874, 7.633264404266445]\n",
      "0.8010578645446216\n",
      "0.7229475722081998 0.8852835865481345\n",
      "[1.0, 1.0] [3.7037448037745486, 90.60780034394598] [0.4728995106505163, 8.722556129107527]\n",
      "[1.0, 1.0] [3.860175301557347, 93.863189425685] [0.4279279937007857, 8.627186181825495]\n",
      "0.8030165891456512\n",
      "0.7413239007387878 0.8698278730576223\n",
      "[1.0, 1.0] [2.8160952795644993, 63.555036389205384] [0.5544452785372002, 5.842928960741059]\n",
      "[1.0, 1.0] [2.9474283202453457, 65.91779861633937] [0.5271552902459534, 5.670244750564275]\n",
      "0.7984641625511776\n",
      "0.7393804859843048 0.8535586707229964\n",
      "[1.0, 1.0] [1.9347356835012746, 45.33687731549148] [0.4133088819220673, 2.8405993623052463]\n",
      "[1.0, 1.0] [2.0162122157527196, 47.073245383049944] [0.4187457751423236, 2.8344738624937915]\n",
      "0.8102237273171193\n",
      "0.7638215267704039 0.851697929055091\n",
      "[1.0, 1.0] [1.3280739209351684, 30.094617486221896] [0.1427981987523098, 2.420456920114248]\n",
      "[1.0, 1.0] [1.3848664450159582, 31.12312376333862] [0.1543800879673463, 2.1203175988832905]\n",
      "0.8135780489297215\n",
      "0.7775629792477308 0.8474908304619928\n",
      "[1.0, 1.0] [0.8006678306359147, 19.456286385146985] [0.09411197272178115, 2.099844176804007]\n",
      "[1.0, 1.0] [0.8315220406079585, 20.205578591855534] [0.10134752133563742, 2.255160534710614]\n",
      "0.8205367341860348\n",
      "0.7911930338445651 0.8481200879239836\n",
      "[1.0, 1.0] [0.5322775518736391, 13.625283469218232] [0.07125368233582992, 1.8497705419540986]\n",
      "[1.0, 1.0] [0.5536444264663848, 14.164066230537896] [0.08285903734026875, 1.9679649990003594]\n",
      "0.819589020775771\n",
      "0.7950481084257135 0.8440050265085937\n",
      "[0.9916550764951322, 0.9888734353268428] [0.37397408136765503, 9.064161449705724] [0.06379149166315957, 1.6332637659655047]\n",
      "[0.975, 0.9875] [0.3897252389583867, 9.447245242514358] [0.073615559961623, 1.8200832506522573]\n",
      "0.8185799993093039\n",
      "0.7978897066358743 0.8405770745078864\n",
      "[0.9485396383866481, 0.9499304589707928] [0.27564584358264343, 6.589050995797611] [0.06548155910737206, 1.6146502088693655]\n",
      "[0.9458333333333333, 0.9125] [0.2891285433442791, 6.86787824729817] [0.07574324302282422, 1.8385326030723448]\n",
      "0.8180357192773197\n",
      "0.7937643158958771 0.8382463263011912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.37397408136765503, 9.064161449705724],\n",
       " [0.9916550764951322, 0.9888734353268428],\n",
       " [0.06379149166315957, 1.6332637659655047],\n",
       " [0.3897252389583867, 9.447245242514358],\n",
       " [0.975, 0.9875],\n",
       " [0.073615559961623, 1.8200832506522573],\n",
       " 0.8185799993093039,\n",
       " 0.7978897066358743,\n",
       " 0.8405770745078864]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_results(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac41ba9-2b9e-4b10-b6ad-e415030e40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0033c73-c13a-492a-8caa-fb16a2d51405",
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_all = Parallel(n_jobs = 15, verbose = 10)(delayed(get_results)(idx) for idx in range(0,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f857358-e5f0-4d43-bf0a-d4d7d034cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e456d98-c381-450b-964d-fdbdbd1bd45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_catch = []\n",
    "for item in catch_all:\n",
    "    catch_inner = []\n",
    "    for inner in item:\n",
    "        if type(inner) == list:\n",
    "            for inner1 in inner:\n",
    "                catch_inner.append(inner1)\n",
    "    if type(inner) != list:\n",
    "        catch_inner.append(inner)\n",
    "    all_catch.append(catch_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ec0ba-5448-4130-b54f-c8cf20f76128",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(all_catch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6accc813-8aa7-48a0-abae-f89b6e5f5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.iloc[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b223ac-16c3-4547-bb99-9a2e08bbb03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"Alop_Train_Width\", \"PSA_Train_Width\", \"Alop_Train_Coverage\", \"PSA_Train_Coverage\", \n",
    "            \"Alop_Train_RMSE\", \"PSA_Train_RMSE\", \"Alop_Test_Width\", \"PSA_Test_Width\", \"Alop_Test_Coverage\", \"PSA_Test_Coverage\", \n",
    "            \"Alop_Test_RMSE\", \"PSA_Test_RMSE\", \"Smiles_Avg_Weight\", \"Lower_Interval_Smiles_Weight\", \"Upper_Interval_Smiles_Weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52823b-19de-4bed-ae04-519af1d5021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0636ac66-6077-4a54-9423-542338c64072",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"..//Data//smiles_rdkit_80_20_Simulation.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d11c8-4f75-4ec9-aacc-930747d74047",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb7839f-ac6e-4930-85ec-e58da91ec1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
