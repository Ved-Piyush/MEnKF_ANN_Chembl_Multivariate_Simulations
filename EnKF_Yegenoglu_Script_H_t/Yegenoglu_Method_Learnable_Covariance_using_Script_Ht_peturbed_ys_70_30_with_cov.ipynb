{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aa53e19a-64db-4b1d-9378-c19c8efacd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import block_diag\n",
    "import warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a6028973-9799-4d8a-b919-a8dd6283faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d459b853-f520-4181-a9a9-310a6dd20de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, initial_ensembles, size_ens): \n",
    "    \n",
    "    target_dim = 1\n",
    "    \n",
    "    # weights_ann_1 = ann.get_weights()\n",
    "    \n",
    "    # h1  = ann.layers[1].output.shape[-1]\n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "    \n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "    \n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, target_dim)\n",
    "\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + target_dim)].reshape(size_ens, 1, target_dim)\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "    \n",
    "    final_output_1 = final_output_1[:,:, 0]\n",
    "    \n",
    "    # print(final_output_1.shape, initial_ensembles.shape)\n",
    "    \n",
    "    stack = np.hstack((final_output_1, initial_ensembles))\n",
    "\n",
    "    \n",
    "    return final_output_1, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2a66ee4c-4112-4dca-a9cc-68a60d4e316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 32, input_shape = 256, output_shape = 1): \n",
    "    input_layer = tf.keras.layers.Input(shape = (input_shape))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(output_shape, activation = \"relu\")\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e0b9ef03-af61-4ce4-99ff-2f0b5dca639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_ensembles(num_weights, lambda1, size_ens):\n",
    "    mean_vec = np.zeros((num_weights,))\n",
    "    cov_matrix = lambda1*np.identity(num_weights)\n",
    "    mvn_samp = mvn(mean_vec, cov_matrix)\n",
    "    return mvn_samp.rvs(size_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fe2ea2b5-13a4-41c4-8257-c6c18708501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "758ac30a-bcc7-4b5e-9314-7fb85f284f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_ann =  ann(hidden = 16, input_shape = 32, output_shape = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2548f2de-a4c3-4850-b5cc-439634f5c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_ann_1 = samp_ann.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1338dc89-5540-4867-95a6-3d0ea7639cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1  = samp_ann.layers[1].output.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "427b0370-90df-4ab4-85b9-691d082750bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_ann.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "06982568-e5c1-4712-895c-7b3d49a09040",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_neurons = h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a71c4646-23a6-45ca-9ccc-aa4c3566d8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_ann_params = samp_ann.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b5f741d7-ba99-4803-8441-5bf2ad3d72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_X_t(data1, data2, size_ens, var_weights = 1.0, var_weight_weights = 4.0):\n",
    "    # samp_ann =  ann(hidden = hidden_neurons, input_shape = 32, output_shape = 1)\n",
    "    \n",
    "    initial_ensembles1 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data1_out1, data1_stack1 = get_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens)\n",
    "    \n",
    "    initial_ensembles2 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data1_out2, data1_stack2 = get_targets_with_weights(data1, initial_ensembles2, size_ens = size_ens)\n",
    "    \n",
    "    initial_ensembles3 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data2_out1, data2_stack1 = get_targets_with_weights(data2, initial_ensembles3, size_ens = size_ens)\n",
    "    \n",
    "    initial_ensembles4 = generate_initial_ensembles(samp_ann_params, var_weights, size_ens)\n",
    "    data2_out2, data2_stack2 = get_targets_with_weights(data2, initial_ensembles4, size_ens = size_ens)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles_for_weights = generate_initial_ensembles(4, var_weight_weights, size_ens)\n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    initial_ensembles_for_L = generate_initial_ensembles(4, var_weights, size_ens)\n",
    "    initial_ensembles_for_L = np.expand_dims(initial_ensembles_for_L,1)    \n",
    "    \n",
    "    initial_ensembles_for_D1 = generate_initial_ensembles(1, var_weights, size_ens).reshape(-1,1)\n",
    "    initial_ensembles_for_D2 = generate_initial_ensembles(1, var_weights, size_ens).reshape(-1,1)\n",
    "    \n",
    "    initial_ensembles_for_D1_zero = np.zeros((size_ens,1,1)).reshape(-1,1)\n",
    "    initial_ensembles_for_D2_zero = np.zeros((size_ens,1,1)).reshape(-1,1)\n",
    "    \n",
    "    initial_ensembles_for_D = np.concatenate((np.expand_dims(initial_ensembles_for_D1,1),\n",
    "                                                       np.expand_dims(initial_ensembles_for_D1_zero,1), \n",
    "                                                      np.expand_dims(initial_ensembles_for_D2,1),\n",
    "                                                       np.expand_dims(initial_ensembles_for_D2_zero,1)), axis = 2)\n",
    "    \n",
    "    # print(X_t.shape, initial_ensembles_for_weights.shape)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D), axis = 1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4))\n",
    "    \n",
    "    return X_t, initial_ensembles, initial_ensembles_for_weights[:,0,:], initial_ensembles_for_L[:,0,:], initial_ensembles_for_D[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6ac49c8c-6da0-4ee2-9561-e1d19365f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_targets_with_weights(batch_data, initial_ensembles, size_ens, weights): \n",
    "    \n",
    "    target_dim = 1\n",
    "    \n",
    "\n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "    \n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "    \n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, target_dim)\n",
    "\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + target_dim)].reshape(size_ens, 1, target_dim)\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "    \n",
    "    final_output_1 = final_output_1[:,:, 0]\n",
    "    \n",
    "    final_output_1 = final_output_1*weights\n",
    "    \n",
    "    # print(final_output_1.shape, initial_ensembles.shape)\n",
    "    \n",
    "    stack = np.hstack((final_output_1, initial_ensembles))\n",
    "\n",
    "    \n",
    "    return final_output_1, stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b697b7f9-3d50-4d71-a436-cdc6434909a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_targets = pickle.load( open('..//Data//target_scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9ace8608-8da1-4b4e-b051-a7b49feae636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_t = np.array([[0.02, 0], [0, 0.02]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d156603a-c127-45b6-a74d-2735987d03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# var1 = R_t[0,0]\n",
    "# var2 = R_t[1,1]\n",
    "# cov = R_t[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c5a2f9ca-f4b4-445a-ab5f-e0f0557f54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "44ed09c8-f6b0-4b40-86e0-1975541fd0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fudging_beta = beta(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9d1a4f5e-7a0d-42b7-ad45-59c708b7b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_operation(data1, data2, combined_ensembles , size_ens, fudging_beta):\n",
    "    # samp_ann =  ann(hidden = hidden_neurons, input_shape = 32, output_shape = 1)\n",
    "    params = samp_ann_params\n",
    "    initial_ensembles1 = combined_ensembles[:, :params]\n",
    "    initial_ensembles2 = combined_ensembles[:, params:(2*params)]\n",
    "    initial_ensembles3 = combined_ensembles[:, (2*params):(3*params)]\n",
    "    initial_ensembles4 = combined_ensembles[:, (3*params):(4*params)]\n",
    "\n",
    "    \n",
    "    initial_ensembles_for_weights = combined_ensembles[:, (4*params):(4*params + 4)]\n",
    "    \n",
    "    initial_ensembles_for_L = combined_ensembles[:, (4*params + 4):(4*params + 4 + 4)]\n",
    "    \n",
    "    initial_ensembles_for_D = combined_ensembles[:,(4*params + 4 + 4):(4*params + 4 + 4 + 4)]\n",
    "    \n",
    "    \n",
    "    softmax_weights = tf.math.softmax(initial_ensembles_for_weights).numpy()\n",
    "    \n",
    "    model_1 = softmax_weights[:, :2].sum(1).reshape(-1,1) +  fudging_beta.rvs(size_ens).reshape(-1,1)\n",
    "    \n",
    "    # model_1 = np.min(model_1 -fudging_factor)\n",
    "    \n",
    "    model_2 = softmax_weights[:, 2:].sum(1).reshape(-1,1) +  fudging_beta.rvs(size_ens).reshape(-1,1)\n",
    "    \n",
    "    \n",
    "    model_1_plus_model_2 = model_1 + model_2\n",
    "    \n",
    "    model_1 = model_1/model_1_plus_model_2\n",
    "    \n",
    "    model_2 = model_2/model_1_plus_model_2\n",
    "    \n",
    "    \n",
    "    # print(np.mean(model_1 + model_2))\n",
    "    \n",
    "    data1_out1, data1_stack1 = get_weighted_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens,\n",
    "                                                                  weights=model_1)\n",
    "    \n",
    "    data1_out2, data1_stack2 = get_weighted_targets_with_weights(data1, initial_ensembles2, size_ens = size_ens,\n",
    "                                                                weights=model_1)\n",
    "    \n",
    "    data2_out1, data2_stack1 = get_weighted_targets_with_weights(data2, initial_ensembles3, size_ens = size_ens,\n",
    "                                                                 weights=model_2)\n",
    "    \n",
    "    data2_out2, data2_stack2 = get_weighted_targets_with_weights(data2, initial_ensembles4, size_ens = size_ens,\n",
    "                                                                  weights=model_2)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4, \n",
    "                        initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D))\n",
    "    \n",
    "    # print(X_t.shape)\n",
    "    \n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    initial_ensembles_for_L = np.expand_dims(initial_ensembles_for_L,1)\n",
    "    \n",
    "    initial_ensembles_for_D = np.expand_dims(initial_ensembles_for_D,1)\n",
    "    \n",
    "    # print(initial_ensembles_for_weights.shape)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D), axis = 1)\n",
    "    \n",
    "    weighted_alogp = data1_out1 + data2_out1\n",
    "    \n",
    "    weighted_psa = data1_out2 + data2_out2\n",
    "    \n",
    "    return X_t, initial_ensembles, weighted_alogp, weighted_psa, model_1, model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c6bd2eb3-86b7-41ed-81b4-4dd8e44e106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_operation_test(data1, data2, combined_ensembles , size_ens):\n",
    "    # samp_ann =  ann(hidden = hidden_neurons, input_shape = 32, output_shape = 1)\n",
    "    params = samp_ann_params\n",
    "    initial_ensembles1 = combined_ensembles[:, :params]\n",
    "    initial_ensembles2 = combined_ensembles[:, params:(2*params)]\n",
    "    initial_ensembles3 = combined_ensembles[:, (2*params):(3*params)]\n",
    "    initial_ensembles4 = combined_ensembles[:, (3*params):(4*params)]\n",
    "\n",
    "    \n",
    "    initial_ensembles_for_weights = combined_ensembles[:, (4*params):(4*params + 4)]\n",
    "    \n",
    "    initial_ensembles_for_L = combined_ensembles[:, (4*params + 4):(4*params + 4 + 4)]\n",
    "    \n",
    "    initial_ensembles_for_D = combined_ensembles[:,(4*params + 4 + 4):(4*params + 4 + 4 + 4)]\n",
    "    \n",
    "    \n",
    "    softmax_weights = tf.math.softmax(initial_ensembles_for_weights).numpy()\n",
    "    \n",
    "    model_1 = softmax_weights[:, :2].sum(1).reshape(-1,1) \n",
    "    \n",
    "    # model_1 = np.min(model_1 -fudging_factor)\n",
    "    \n",
    "    model_2 = softmax_weights[:, 2:].sum(1).reshape(-1,1) \n",
    "    \n",
    "    \n",
    "#     model_1_plus_model_2 = model_1 + model_2\n",
    "    \n",
    "#     model_1 = model_1/model_1_plus_model_2\n",
    "    \n",
    "#     model_2 = model_2/model_1_plus_model_2\n",
    "    \n",
    "    \n",
    "    # print(np.mean(model_1 + model_2))\n",
    "    \n",
    "    data1_out1, data1_stack1 = get_weighted_targets_with_weights(data1, initial_ensembles1, size_ens = size_ens,\n",
    "                                                                  weights=model_1)\n",
    "    \n",
    "    data1_out2, data1_stack2 = get_weighted_targets_with_weights(data1, initial_ensembles2, size_ens = size_ens,\n",
    "                                                                weights=model_1)\n",
    "    \n",
    "    data2_out1, data2_stack1 = get_weighted_targets_with_weights(data2, initial_ensembles3, size_ens = size_ens,\n",
    "                                                                 weights=model_2)\n",
    "    \n",
    "    data2_out2, data2_stack2 = get_weighted_targets_with_weights(data2, initial_ensembles4, size_ens = size_ens,\n",
    "                                                                  weights=model_2)   \n",
    "    \n",
    "    X_t = np.concatenate((np.expand_dims(data1_stack1, -1), np.expand_dims(data1_stack2, -1), \n",
    "                         np.expand_dims(data2_stack1, -1), np.expand_dims(data2_stack2, -1)), axis = -1)\n",
    "    \n",
    "    initial_ensembles = np.hstack((initial_ensembles1, initial_ensembles2, initial_ensembles3, initial_ensembles4, \n",
    "                        initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D))\n",
    "    \n",
    "    # print(X_t.shape)\n",
    "    \n",
    "    initial_ensembles_for_weights = np.expand_dims(initial_ensembles_for_weights,1)\n",
    "    \n",
    "    initial_ensembles_for_L = np.expand_dims(initial_ensembles_for_L,1)\n",
    "    \n",
    "    initial_ensembles_for_D = np.expand_dims(initial_ensembles_for_D,1)\n",
    "    \n",
    "    # print(initial_ensembles_for_weights.shape)\n",
    "    \n",
    "    X_t = np.concatenate((X_t, initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D), axis = 1)\n",
    "    \n",
    "    weighted_alogp = data1_out1 + data2_out1\n",
    "    \n",
    "    weighted_psa = data1_out2 + data2_out2\n",
    "    \n",
    "    return X_t, initial_ensembles, weighted_alogp, weighted_psa, model_1, model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e15b0bf7-ba00-40bc-933b-c1c3e062e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samp_ann =  ann(hidden = 16, input_shape = 32, output_shape = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "af3dd570-7ab3-4eae-bd8e-9a57a333b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = 4*(samp_ann.count_params() + 1 + 1 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e820b010-4396-4b7a-8781-a8e6d503aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e5fbaaf7-afae-4008-a26c-e0691ef9b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_ens = total_weights//reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a5111536-1a97-4390-9658-c9848a136a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3f598992-73d6-4b5a-906d-3184f1b9625f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_t = [[1, 0, 1, 0], [0, 1, 0, 1]]\n",
    "G_t = np.array(G_t).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a84cb0e3-2f5e-4207-b092-d2768b52205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data1, data2, initial_ensembles, fudging_beta  =fudging_beta): \n",
    "    _,_, weighted_alogp, weighted_psa, w1, w2 = forward_operation(data1, data2, initial_ensembles, size_ens = size_ens, fudging_beta = fudging_beta)\n",
    "    weighted_alogp = np.expand_dims(weighted_alogp,-1)\n",
    "    weighted_psa = np.expand_dims(weighted_psa,-1)\n",
    "    preds = np.concatenate((weighted_alogp, weighted_psa),-1)\n",
    "    return preds, w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "37b60b37-92b1-4784-85fc-59a865d2398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_test(data1, data2, initial_ensembles): \n",
    "    _,_, weighted_alogp, weighted_psa, w1, w2 = forward_operation_test(data1, data2, initial_ensembles, size_ens = size_ens)\n",
    "    weighted_alogp = np.expand_dims(weighted_alogp,-1)\n",
    "    weighted_psa = np.expand_dims(weighted_psa,-1)\n",
    "    preds = np.concatenate((weighted_alogp, weighted_psa),-1)\n",
    "    return preds, w1, w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3af0a9b9-6202-40e2-911f-3c890213099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mu_bar_G_bar(data1, data2, initial_ensembles, fudging_beta):\n",
    "    H_t = np.hstack((np.identity(data1.shape[0]), np.zeros((data1.shape[0], samp_ann_params + 1 + 1 + 1))))\n",
    "    mu_bar = initial_ensembles.mean(0)\n",
    "    X_t,_, _, _, _, _ = forward_operation(data1, data2, initial_ensembles, size_ens = size_ens, fudging_beta = fudging_beta)\n",
    "    X_t = X_t.transpose((0,2,1))\n",
    "    X_t = X_t.reshape(X_t.shape[0], X_t.shape[1]*X_t.shape[2])\n",
    "    script_H_t = np.kron(G_t.T, H_t)\n",
    "    G_u = (script_H_t@X_t.T)\n",
    "    G_u = G_u.T\n",
    "    G_bar = (G_u.mean(0)).ravel()\n",
    "    return mu_bar.reshape(-1,1), G_bar.reshape(-1,1), G_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7334c80c-cfcd-4d5b-b844-11cfb8c137df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_C_u(initial_ensembles, mu_bar, G_bar, G_u): \n",
    "    u_j_minus_u_bar = initial_ensembles - mu_bar.reshape(1,-1)\n",
    "    G_u_minus_G_bar = G_u -  G_bar.reshape(1,-1)\n",
    "    c = np.zeros((total_weights, G_bar.shape[0]))\n",
    "    for i in range(0, size_ens): \n",
    "        c += np.kron(u_j_minus_u_bar[i, :].T.reshape(-1,1), G_u_minus_G_bar[i,:].reshape(-1,1).T)\n",
    "    return c/size_ens, G_u_minus_G_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9148779c-1a3f-455d-a6ad-00fc1bf69c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_D_u( G_bar, G_u): \n",
    "    G_u_minus_G_bar = G_u -  G_bar.reshape(1,-1)\n",
    "    d = np.zeros((G_bar.shape[0], G_bar.shape[0]))\n",
    "    for i in range(0, size_ens): \n",
    "        d += np.kron(G_u_minus_G_bar[i,:].T.reshape(-1,1), G_u_minus_G_bar[i,:].reshape(-1,1).T)\n",
    "    return d/size_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6e8459b0-68c1-4d1f-851e-3d7b99f0ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_updated_ensemble(data1, data2, initial_ensembles, y_train, size_ens = size_ens, inflation_factor = 1.0, fudging_beta = fudging_beta):\n",
    "    mu_bar, G_bar, G_u = calculate_mu_bar_G_bar(data1, data2, initial_ensembles, fudging_beta)\n",
    "    C, G_u_minus_G_bar = calculate_C_u(initial_ensembles, mu_bar, G_bar, G_u)\n",
    "    D = calculate_D_u( G_bar, G_u)\n",
    "    _, R_t = create_cov(data1.shape[0],initial_ensembles)\n",
    "    inflation = np.identity(R_t.shape[0])*inflation_factor\n",
    "    D_plus_cov = D + (R_t *inflation_factor)\n",
    "    D_plus_cov_inv = np.linalg.inv(D_plus_cov)\n",
    "    mid_quant = C@D_plus_cov_inv\n",
    "    noise_vec_mean = np.zeros((R_t.shape[0], ))\n",
    "    noise_mvn = mvn(noise_vec_mean, R_t)\n",
    "    fudging = noise_mvn.rvs(size_ens)\n",
    "    interim = (y_train.T.flatten().reshape(1,-1) + fudging)\n",
    "    right_quant = interim - G_u\n",
    "    mid_times_right = mid_quant@right_quant.T\n",
    "    updated_ensemble = (initial_ensembles + mid_times_right.T)\n",
    "    return updated_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c14b236d-6ebf-40e3-9085-97afd2990e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "346d07bc-5b61-4e75-a816-a6e22ffe9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_D = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dc3a216a-4dbb-474d-8219-5f6c071250a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(data, idx):\n",
    "    data_cur = data[idx, :, :]\n",
    "    inv_data_cur = std_targets.inverse_transform(data_cur)\n",
    "    return inv_data_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5abd35fb-ea92-449d-894a-162ed1f4aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "381fc654-8877-41fd-840a-4b35153f923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cov(shape, initial_ensembles):\n",
    "    cov_part = initial_ensembles[:, -8:-4]\n",
    "    cov_part = cov_part.mean(0)\n",
    "    # variances = tf.math.softplus(cov_part[:2]).numpy()\n",
    "    variances = cov_part[:2]\n",
    "    covariances = cov_part[2:]\n",
    "    base_cov = np.identity(target_dim)\n",
    "    base_cov[0,0] = variances[0]\n",
    "    base_cov[1,1] = variances[1]\n",
    "    base_cov[0,1] = covariances[0]\n",
    "    base_cov[1,0] = covariances[1]\n",
    "    \n",
    "    variances1 = tf.math.softplus(initial_ensembles[:, -4:]).numpy()\n",
    "    variances1 = variances1.mean(0)\n",
    "    base_variances = np.identity(target_dim)\n",
    "    base_variances[0,0] = variances1[0]\n",
    "    base_variances[1,1] = variances1[2]\n",
    "    \n",
    "    final = np.linalg.cholesky(base_cov@base_cov.T + base_variances)\n",
    "    cov_mat = final@final.T\n",
    "    cov_mat_final = cov_mat\n",
    "    # cov_mat_final = cov_mat@cov_mat.T\n",
    "    \n",
    "    if is_pos_def(cov_mat_final) != True:\n",
    "        print(\"resulting cov matrix is not positive semi definite\")\n",
    "        pass\n",
    "    \n",
    "    # print(np.linalg.det(cov_mat_final))\n",
    "    \n",
    "    var1 = cov_mat_final[0,0]\n",
    "    var2 = cov_mat_final[1,1]\n",
    "    cov = cov_mat_final[1,0]\n",
    "\n",
    "    n = shape\n",
    "    \n",
    "    ul = var1*np.identity(n)\n",
    "    lr = var2*np.identity(n)\n",
    "    ur = cov*np.identity(n)\n",
    "    ll = ur.T    \n",
    "    \n",
    "    first_row = np.hstack((ul, ur))\n",
    "    second_row = np.hstack((ll, lr))\n",
    "    \n",
    "    R_t = np.vstack((first_row, second_row))\n",
    "    \n",
    "    return cov_mat_final, R_t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "30aea5e4-361f-44ae-9ea3-d1d8743e6ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ed1f9938-cdc5-400f-8bab-22c180a6d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"..//Data//smiles_to_rdkit_70_30_with_cov_minus_0.27_var.pickle\", \"rb\") as f: \n",
    "    catch = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7c59ea29-6484-40d5-8777-80cf9ca6cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "176445fb-4f30-421a-a710-339955111baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(idx, var_weights = 1.0, var_weight_weights = 4.0): \n",
    "    catch_idx = catch[idx]\n",
    "    x_train, x_valid, y_train, y_valid = catch_idx[0], catch_idx[1], catch_idx[2], catch_idx[3]\n",
    "    y_train_actual, y_train = y_train[:,:2], y_train[:,2:]\n",
    "    y_valid_actual, y_valid = y_valid[:,:2], y_valid[:,2:]\n",
    "    smiles_feats_train = x_train[:, :32]\n",
    "    rdkit_feats_train = x_train[:, 32:]\n",
    "    smiles_feats_valid = x_valid[:, :32]\n",
    "    rdkit_feats_valid = x_valid[:, 32:]\n",
    "\n",
    "    X_t, initial_ensembles, initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D = get_initial_X_t(smiles_feats_train, rdkit_feats_train, size_ens = size_ens, var_weights = var_weights, var_weight_weights = var_weight_weights)\n",
    "    initial_ensembles = np.hstack((initial_ensembles, initial_ensembles_for_weights, initial_ensembles_for_L, initial_ensembles_for_D))\n",
    "    \n",
    "    return smiles_feats_train, rdkit_feats_train, smiles_feats_valid, rdkit_feats_valid, y_train, y_train_actual, y_valid, y_valid_actual, initial_ensembles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "82d67093-cbd5-4a2b-bdbc-aa33a082e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smiles_feats_train, rdkit_feats_train, smiles_feats_valid, rdkit_feats_valid, y_train, y_train_actual, y_valid, y_valid_actual, initial_ensembles  = prepare_data(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fa640128-df71-44ec-b20b-6922bdb5b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dc0c894d-db8c-4d88-bd51-ef23ca80fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e5cffacb-8558-45ca-bff9-e803e3fd6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3a2e8d41-0775-457c-97a2-4060fd72634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta(1,19).rvs(size_ens).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "65bf21e9-92c6-4824-93c3-87274b072afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(idx, var_weights = 1.0, var_weight_weights = 1.0, inflation_factor = 1.2, fudging_beta = beta(1,19)):\n",
    "    # print('var_weights' + str(var_weights))\n",
    "    # print('inflation_factor' + str(inflation_factor))\n",
    "    # print('var_weight_weights' + str(var_weight_weights))\n",
    "    smiles_feats_train, rdkit_feats_train, smiles_feats_valid, rdkit_feats_valid, y_train, y_train_actual, y_valid, y_valid_actual, initial_ensembles  = prepare_data(idx, var_weights = var_weights, var_weight_weights =var_weight_weights)\n",
    "    # print(R_t.shape)\n",
    "    best_train_width_mean = 100000\n",
    "    \n",
    "    for i in range(0,10000):\n",
    "        # print(i)\n",
    "    \n",
    "        c = np.zeros((2,2))\n",
    "        initial_ensembles = get_updated_ensemble(smiles_feats_train, rdkit_feats_train, initial_ensembles, y_train, size_ens, inflation_factor = inflation_factor, fudging_beta = fudging_beta)\n",
    "        # print(inflation_factor)\n",
    "        G_u_train, w1, w2 = get_predictions(smiles_feats_train, rdkit_feats_train, initial_ensembles, fudging_beta)\n",
    "\n",
    "        catch = Parallel(n_jobs = 15, verbose = 0)(delayed(inverse_transform)(G_u_train, i)  for i in range(G_u_train.shape[0]))\n",
    "        G_u_train = np.array(catch)\n",
    "    \n",
    "        y_train_cur = std_targets.inverse_transform(y_train_actual)\n",
    "    \n",
    "        li_train = np.percentile(G_u_train, axis = 0, q = (2.5, 97.5))[0,:,:]   \n",
    "        ui_train = np.percentile(G_u_train, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "    \n",
    "        width_train = ui_train - li_train\n",
    "        avg_width_train = width_train.mean(0)\n",
    "    \n",
    "        ind_train = (y_train_cur >= li_train) & (y_train_cur <= ui_train)\n",
    "        coverage_train= ind_train.mean(0)\n",
    "    \n",
    "        averaged_targets_train = G_u_train.mean(0)\n",
    "        rmse_train = np.sqrt(((y_train_cur -averaged_targets_train)**2).mean(0))\n",
    "    # print(rmse_train, coverage_train, avg_width_train)\n",
    "    \n",
    "        G_u_test, _, _ = get_predictions_test(smiles_feats_valid, rdkit_feats_valid, initial_ensembles)\n",
    "    \n",
    "        catch = Parallel(n_jobs = 15, verbose = 0)(delayed(inverse_transform)(G_u_test, i)  for i in range(G_u_test.shape[0]))\n",
    "        G_u_test = np.array(catch)\n",
    "    \n",
    "        y_valid_cur = std_targets.inverse_transform(y_valid_actual)    \n",
    "    \n",
    "        li_test = np.percentile(G_u_test, axis = 0, q = (2.5, 97.5))[0,:,:]   \n",
    "        ui_test = np.percentile(G_u_test, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "    \n",
    "        width_test = ui_test - li_test\n",
    "        avg_width_test = width_test.mean(0)\n",
    "    \n",
    "        ind_test = (y_valid_cur >= li_test) & (y_valid_cur <= ui_test)\n",
    "        coverage_test= ind_test.mean(0)\n",
    "    \n",
    "        averaged_targets_test = G_u_test.mean(0)\n",
    "        rmse_test = np.sqrt(((y_valid_cur -averaged_targets_test)**2).mean(0))    \n",
    "    \n",
    "        # weight_norms = np.array(norm(initial_ensembles, ord = 2, axis = 1))\n",
    "        # weight_norm_mean.append(weight_norms.mean())\n",
    "        # weight_norm_sd.append(weight_norms.std())\n",
    "    \n",
    "        cov_mat_final, _ = create_cov(smiles_feats_train.shape[0],initial_ensembles)\n",
    "        \n",
    "        # print(\"standardized_scale_R_t\")\n",
    "        # print(np.diag(cov_mat_final), cov_mat_final[0,1])\n",
    "        \n",
    "        # print(w1.shape)\n",
    "        \n",
    "        li_smiles_weight = np.percentile(w1, axis = 0, q = (2.5, 97.5))[0][0]\n",
    "        \n",
    "        # print(np.percentile(w1, axis = 0, q = (2.5, 97.5)))\n",
    "        \n",
    "        ui_smiles_weight = np.percentile(w1, axis = 0, q = (2.5, 97.5))[1][0]      \n",
    "        \n",
    "        # print(coverage_train.tolist(), avg_width_train.tolist(), rmse_train.tolist())\n",
    "        # print(coverage_test.tolist(), avg_width_test.tolist(), rmse_test.tolist())\n",
    "        # print(w1.mean(), w1.std())\n",
    "        # print(li_smiles_weight, ui_smiles_weight)\n",
    "        # print(avg_width_train.tolist(), coverage_train.tolist(), rmse_train.tolist(), avg_width_test.tolist(), coverage_test.tolist(), rmse_test.tolist(), w1.mean())\n",
    "\n",
    "        if (avg_width_train.mean() < best_train_width_mean) & (coverage_train.mean() > 0.95): \n",
    "            # print(\"went here\")\n",
    "            best_train_width_mean = avg_width_train.mean()\n",
    "            best_train_width = avg_width_train\n",
    "            best_smiles_weight = w1.mean()\n",
    "            best_coverage_train = coverage_train\n",
    "            best_rmse_train = rmse_train\n",
    "        \n",
    "            best_test_width = avg_width_test\n",
    "\n",
    "            best_coverage_test = coverage_test    \n",
    "            best_rmse_test = rmse_test\n",
    "            \n",
    "            best_li_smiles_weight = li_smiles_weight\n",
    "            \n",
    "            best_ui_smiles_weight = ui_smiles_weight\n",
    "    \n",
    "        if coverage_train.mean() < 0.95:\n",
    "            \n",
    "            # print()\n",
    "            # print(best_train_width.tolist(), best_coverage_train.tolist(), best_rmse_train.tolist(), best_test_width.tolist(), best_coverage_test.tolist(), best_rmse_test.tolist(), best_smiles_weight, flush = True)\n",
    "            print(\"done for fold\" + str(idx), flush = True)\n",
    "            print(\"train_width\" + str(best_train_width.tolist()), flush = True)\n",
    "            print(\"test_width\" + str(best_test_width.tolist()), flush = True)\n",
    "            print(\"smiles_weight\" + str(best_smiles_weight), flush = True)\n",
    "            print(\"rmse_train\" + str(best_rmse_train.tolist()), flush = True)\n",
    "            print(\"rmse_test\" + str(best_rmse_test.tolist()), flush = True)\n",
    "            print(\"smiles_weight_ci\" + str([best_li_smiles_weight, best_ui_smiles_weight]), flush = True)\n",
    "            \n",
    "            return [best_train_width.tolist(), best_coverage_train.tolist(), best_rmse_train.tolist(), best_test_width.tolist(), best_coverage_test.tolist(), best_rmse_test.tolist(), best_smiles_weight, best_li_smiles_weight, best_ui_smiles_weight]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "201d8498-7742-4509-94de-4fb1f5d84e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df[results_df[\"indicator\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "14658528-ea1a-4a6f-83bd-f708df0bcd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 3 µs, total: 7 µs\n",
      "Wall time: 12.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get_results(45, var_weights = 1.0, var_weight_weights = 2.0, inflation_factor =1.0, fudging_beta = beta(1,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3ac41ba9-2b9e-4b10-b6ad-e415030e40ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c0033c73-c13a-492a-8caa-fb16a2d51405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Using backend LokyBackend with 15 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold2\n",
      "train_width[1.342344545339677, 29.446403530445718]\n",
      "test_width[1.14623533222744, 26.52427261438076]\n",
      "smiles_weight0.6946662916688016\n",
      "rmse_train[0.2580343338435064, 8.230185829805214]\n",
      "rmse_test[0.2007145748718262, 7.2726991094572675]\n",
      "smiles_weight_ci[0.5896863547917883, 0.7771886028037417]\n",
      "done for fold13\n",
      "train_width[1.2695542583529316, 28.858615419372047]\n",
      "test_width[1.121820970398027, 25.930315801058576]\n",
      "smiles_weight0.7401562459133153\n",
      "rmse_train[0.25721261678979224, 7.691257075726726]\n",
      "rmse_test[0.2732691918441032, 7.352549596487283]\n",
      "smiles_weight_ci[0.6292809738107403, 0.8290177595599642]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done   2 tasks      | elapsed:  4.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold3\n",
      "train_width[1.0504821938360112, 23.145921633737903]\n",
      "test_width[0.844149569015977, 18.378450474991233]\n",
      "smiles_weight0.7008752811533934\n",
      "rmse_train[0.23109236033716227, 5.5433687305171935]\n",
      "rmse_test[0.19535947441404855, 5.470823871625542]\n",
      "smiles_weight_ci[0.592449040305265, 0.7995745213422307]\n",
      "done for fold4\n",
      "train_width[1.1650510334234012, 21.011107023526623]\n",
      "test_width[0.8330887280652592, 17.37391221949856]\n",
      "smiles_weight0.7584343727881501\n",
      "rmse_train[0.2578623395921502, 5.098406479784484]\n",
      "rmse_test[0.2228029151099859, 5.468639752587699]\n",
      "smiles_weight_ci[0.657278435542009, 0.8433854681011782]\n",
      "done for fold0\n",
      "train_width[1.3009392252717864, 24.561710159288882]\n",
      "test_width[0.9455052359163918, 19.536938550115504]\n",
      "smiles_weight0.8048454391265286\n",
      "rmse_train[0.21379407811513923, 6.347951875089702]\n",
      "rmse_test[0.24673393923919618, 5.2972972003973915]\n",
      "smiles_weight_ci[0.6855218405927496, 0.8805369807803635]\n",
      "done for fold1\n",
      "train_width[1.0856283447737274, 21.31344171576643]\n",
      "test_width[0.818608953294001, 18.551244365866904]\n",
      "smiles_weight0.7299822301421224\n",
      "rmse_train[0.21962625737425598, 5.074741435738516]\n",
      "rmse_test[0.25516481448724254, 5.192800955367218]\n",
      "smiles_weight_ci[0.6062972784653767, 0.8029444772640503]\n",
      "done for fold10\n",
      "train_width[0.9627167074600759, 19.453330095826075]\n",
      "test_width[0.6865274638722876, 15.906176706537014]\n",
      "smiles_weight0.721946573603757\n",
      "rmse_train[0.20170352536826863, 4.551456985873699]\n",
      "rmse_test[0.1642545346007792, 4.417322809588749]\n",
      "smiles_weight_ci[0.5893780591331569, 0.8000020558802495]\n",
      "done for fold6\n",
      "train_width[1.193234085074872, 23.627496006727633]\n",
      "test_width[0.7384925979448203, 16.923557417961554]\n",
      "smiles_weight0.7804336033943001\n",
      "rmse_train[0.2409854450390199, 5.03420600406288]\n",
      "rmse_test[0.1998915767012962, 3.386058134643132]\n",
      "smiles_weight_ci[0.642730699531657, 0.8582715417185781]\n",
      "done for fold12\n",
      "train_width[1.0031781352188531, 21.52972264565472]\n",
      "test_width[0.6505687840610572, 16.71423325804678]\n",
      "smiles_weight0.7685017448665534\n",
      "rmse_train[0.19585632145037551, 4.562288584645711]\n",
      "rmse_test[0.2512749912289235, 4.1178497040042314]\n",
      "smiles_weight_ci[0.6388339209280923, 0.849575672567942]\n",
      "done for fold9\n",
      "train_width[0.9542483530162186, 20.906205970856824]\n",
      "test_width[0.7471712458774776, 15.978183091475127]\n",
      "smiles_weight0.7395602401839712\n",
      "rmse_train[0.21444010061656835, 5.007359300324033]\n",
      "rmse_test[0.17778880486322973, 4.700370375348221]\n",
      "smiles_weight_ci[0.6391244190500643, 0.8140039321403835]\n",
      "done for fold14\n",
      "train_width[1.0320144201505335, 18.709796498626584]\n",
      "test_width[0.7504788723228305, 14.625227452370599]\n",
      "smiles_weight0.7503984806700968\n",
      "rmse_train[0.24416691662830753, 4.916503537546067]\n",
      "rmse_test[0.29264290081876915, 5.27117708685536]\n",
      "smiles_weight_ci[0.6386246791299658, 0.8194235671028921]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  11 tasks      | elapsed:  5.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold7\n",
      "train_width[0.9749942095889056, 20.188351423497622]\n",
      "test_width[0.6817383503027712, 15.993317016778663]\n",
      "smiles_weight0.7647106582749054\n",
      "rmse_train[0.20797435134652886, 4.262737015384224]\n",
      "rmse_test[0.20204581446536887, 3.6787973383106642]\n",
      "smiles_weight_ci[0.6544855800989602, 0.8501359512741514]\n",
      "done for fold8\n",
      "train_width[0.9811649113197165, 20.357484008674753]\n",
      "test_width[0.6762970399705198, 15.99527052566849]\n",
      "smiles_weight0.7502554248193873\n",
      "rmse_train[0.19819127120598215, 4.841482282905202]\n",
      "rmse_test[0.25643475195607257, 3.8886635379830556]\n",
      "smiles_weight_ci[0.6372807770090502, 0.8374547380158175]\n",
      "done for fold5\n",
      "train_width[1.0249306304898913, 17.93345710020641]\n",
      "test_width[0.6683439655474837, 14.982152799472725]\n",
      "smiles_weight0.7536005302223517\n",
      "rmse_train[0.2259932468974626, 4.318130433094611]\n",
      "rmse_test[0.2734856836742981, 4.633793315951064]\n",
      "smiles_weight_ci[0.639823281152588, 0.8345096096757998]\n",
      "done for fold11\n",
      "train_width[0.9438846741993865, 16.261745210379985]\n",
      "test_width[0.5768657641371123, 12.274970027940084]\n",
      "smiles_weight0.7764719747906146\n",
      "rmse_train[0.2128431956608385, 3.815323208329308]\n",
      "rmse_test[0.2050550769749766, 3.3816201446050544]\n",
      "smiles_weight_ci[0.6422360548627077, 0.8566673349889166]\n",
      "done for fold15\n",
      "train_width[1.209152739045385, 26.689446528425325]\n",
      "test_width[1.0890331001065248, 25.062801980146716]\n",
      "smiles_weight0.7231520050322303\n",
      "rmse_train[0.3184273947051049, 5.531461849654704]\n",
      "rmse_test[0.284719847725768, 5.996083458419102]\n",
      "smiles_weight_ci[0.6111569741318676, 0.8140488589301849]\n",
      "done for fold16\n",
      "train_width[1.1134429038720017, 21.40303466552819]\n",
      "test_width[0.9427864968876967, 19.549666129987582]\n",
      "smiles_weight0.72868625895524\n",
      "rmse_train[0.23517892153272013, 5.014173594701353]\n",
      "rmse_test[1.103999442301632, 8.222332577068265]\n",
      "smiles_weight_ci[0.6137677602336915, 0.8167980169819247]\n",
      "done for fold22\n",
      "train_width[1.1803037857319287, 23.71962897073377]\n",
      "test_width[0.8911218981685685, 19.478300072371187]\n",
      "smiles_weight0.7709382635261902\n",
      "rmse_train[0.25212598448687223, 5.0006312042533505]\n",
      "rmse_test[0.21017649690427287, 4.1473710747064745]\n",
      "smiles_weight_ci[0.6563462235849152, 0.8490830708381714]\n",
      "done for fold19\n",
      "train_width[1.4391564186511197, 25.45352650477695]\n",
      "test_width[1.192576826843747, 22.762449620284713]\n",
      "smiles_weight0.7630037676080098\n",
      "rmse_train[0.3238171727838568, 6.241098852635919]\n",
      "rmse_test[0.22902451910519003, 5.882703558281188]\n",
      "smiles_weight_ci[0.6628726950899664, 0.8509601470260949]\n",
      "done for fold17\n",
      "train_width[0.9835643796425995, 17.717284630664405]\n",
      "test_width[0.777590130422004, 15.424898670912466]\n",
      "smiles_weight0.7254029384425958\n",
      "rmse_train[0.22721763475725107, 4.475526252524381]\n",
      "rmse_test[0.25884930949218204, 4.688798009381952]\n",
      "smiles_weight_ci[0.5907345802661937, 0.8160591827689189]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  20 tasks      | elapsed:  9.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold23\n",
      "train_width[1.0969114566783562, 26.58541562888578]\n",
      "test_width[0.9935427709992608, 24.22659567770113]\n",
      "smiles_weight0.7054934382668328\n",
      "rmse_train[0.2160121003167035, 5.4292960100125285]\n",
      "rmse_test[0.36058810807210173, 15.717683882971631]\n",
      "smiles_weight_ci[0.6101802825782684, 0.7936799443888948]\n",
      "done for fold18\n",
      "train_width[0.935137014886854, 18.01035850793979]\n",
      "test_width[0.5586456921079909, 13.604549645821201]\n",
      "smiles_weight0.8282063585379403\n",
      "rmse_train[0.18040239130341207, 4.678052166274092]\n",
      "rmse_test[0.2850381456604789, 5.310595552205211]\n",
      "smiles_weight_ci[0.7164300642638577, 0.8981619395351573]\n",
      "done for fold27\n",
      "train_width[1.3637567888528437, 22.699519459459648]\n",
      "test_width[0.9901918835651347, 18.822622879677745]\n",
      "smiles_weight0.7610801083675369\n",
      "rmse_train[0.2705834864880231, 5.512161132651812]\n",
      "rmse_test[0.24247487881043633, 4.484260746353197]\n",
      "smiles_weight_ci[0.6534649927681497, 0.8425537016299365]\n",
      "done for fold26\n",
      "train_width[1.2900594660343419, 23.251592576224247]\n",
      "test_width[0.8928063906777896, 19.11214865498427]\n",
      "smiles_weight0.833305026035665\n",
      "rmse_train[0.2537589856484541, 5.577591108736204]\n",
      "rmse_test[0.3293198702834598, 8.647240459171133]\n",
      "smiles_weight_ci[0.732208197626134, 0.911025678416887]\n",
      "done for fold24\n",
      "train_width[1.0954028716358233, 21.300130090821472]\n",
      "test_width[0.7207476409864193, 16.484935948414783]\n",
      "smiles_weight0.7933049471141056\n",
      "rmse_train[0.22441586572718056, 5.0063369844588275]\n",
      "rmse_test[0.24261843655177293, 4.051849531194799]\n",
      "smiles_weight_ci[0.6598252998419415, 0.8667752507895322]\n",
      "done for fold21\n",
      "train_width[0.9920547074440459, 17.48448181954246]\n",
      "test_width[0.7110446079643952, 14.489188533978643]\n",
      "smiles_weight0.740832215383147\n",
      "rmse_train[0.2108004780805154, 4.42879677029889]\n",
      "rmse_test[0.20927166463278715, 3.1603332788301857]\n",
      "smiles_weight_ci[0.6258877095646544, 0.8109805600336015]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  27 out of  50 | elapsed: 10.4min remaining:  8.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold28\n",
      "train_width[1.0441387690825263, 21.12297239656916]\n",
      "test_width[0.7889747911655601, 16.66827207507826]\n",
      "smiles_weight0.7381498250249339\n",
      "rmse_train[0.22738084879200798, 4.868646763939097]\n",
      "rmse_test[0.23728917596035812, 4.623696717647783]\n",
      "smiles_weight_ci[0.6256578676703913, 0.8141353296046844]\n",
      "done for fold25\n",
      "train_width[1.0169451246596626, 18.329058758063464]\n",
      "test_width[0.6309792872210356, 14.008310840104322]\n",
      "smiles_weight0.8007331806749001\n",
      "rmse_train[0.22726495305178857, 4.441501909954528]\n",
      "rmse_test[0.23968097647288306, 3.4955410836964877]\n",
      "smiles_weight_ci[0.6794435205957478, 0.8725261603943306]\n",
      "done for fold20\n",
      "train_width[0.7652679565246745, 15.177796716731049]\n",
      "test_width[0.504050338282113, 11.035096161315092]\n",
      "smiles_weight0.7500864800270122\n",
      "rmse_train[0.1896545012859573, 3.9527107169418416]\n",
      "rmse_test[0.19490720165829623, 3.480232267260877]\n",
      "smiles_weight_ci[0.6507707936158784, 0.8213436587785828]\n",
      "done for fold29\n",
      "train_width[0.961083202150988, 19.047637774650944]\n",
      "test_width[0.6682045373913564, 14.846053041773798]\n",
      "smiles_weight0.7620735563741522\n",
      "rmse_train[0.20253893057766265, 4.713858951351378]\n",
      "rmse_test[0.22798790819088832, 3.7400606905809224]\n",
      "smiles_weight_ci[0.6300644106517239, 0.8415654782144465]\n",
      "done for fold32\n",
      "train_width[1.2466179606203385, 25.996542426482947]\n",
      "test_width[1.1012081510194294, 23.965816324200762]\n",
      "smiles_weight0.7650798340585346\n",
      "rmse_train[0.27791789291015795, 5.300535974044779]\n",
      "rmse_test[0.4803005906672127, 8.79821412358535]\n",
      "smiles_weight_ci[0.6586652239322247, 0.8545219823265884]\n",
      "done for fold35\n",
      "train_width[1.5910590409948848, 30.71998233464315]\n",
      "test_width[1.1751069952799225, 25.02281314930302]\n",
      "smiles_weight0.8031062842466842\n",
      "rmse_train[0.2865977170068107, 6.883530806313621]\n",
      "rmse_test[0.3369313119142907, 7.1325511936821275]\n",
      "smiles_weight_ci[0.6789436438286993, 0.8885376691049147]\n",
      "done for fold30\n",
      "train_width[1.106450276222004, 21.42108082318085]\n",
      "test_width[0.695393753685071, 16.090947306589026]\n",
      "smiles_weight0.7637292335833987\n",
      "rmse_train[0.21461761022157377, 5.242120662135474]\n",
      "rmse_test[0.1971745754540762, 4.89810043669293]\n",
      "smiles_weight_ci[0.6407115785989639, 0.84811310715288]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  33 out of  50 | elapsed: 13.5min remaining:  7.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold33\n",
      "train_width[1.2913845758084128, 23.36604780650913]\n",
      "test_width[0.8666965182556723, 17.374587629891025]\n",
      "smiles_weight0.8135325848114539\n",
      "rmse_train[0.23922337424269086, 5.64231387710761]\n",
      "rmse_test[0.23877203152646018, 5.197952437918724]\n",
      "smiles_weight_ci[0.6867213479082427, 0.892877930065138]\n",
      "done for fold34\n",
      "train_width[1.089222491702365, 21.599005246859527]\n",
      "test_width[0.8746048231937877, 18.52165323341435]\n",
      "smiles_weight0.7436097988478021\n",
      "rmse_train[0.22890710899820566, 4.72929876924728]\n",
      "rmse_test[0.24071635293553859, 4.413066834874326]\n",
      "smiles_weight_ci[0.6069636649221681, 0.8251225402962746]\n",
      "done for fold41\n",
      "train_width[1.622117683046341, 31.96053446193032]\n",
      "test_width[1.2980178403192193, 26.526418187339065]\n",
      "smiles_weight0.7680452939957555\n",
      "rmse_train[0.35350224684181836, 7.90699767744089]\n",
      "rmse_test[0.33293398707375604, 6.481423454450227]\n",
      "smiles_weight_ci[0.6368648473889751, 0.8511739587710891]\n",
      "done for fold31\n",
      "train_width[0.9637655288366379, 19.139220678102518]\n",
      "test_width[0.8100229082248748, 18.121353983312428]\n",
      "smiles_weight0.7030552476322458\n",
      "rmse_train[0.16799663813409368, 4.596566383088956]\n",
      "rmse_test[0.45028058721773817, 6.536488007928663]\n",
      "smiles_weight_ci[0.5888341510677131, 0.812466339396622]\n",
      "done for fold40\n",
      "train_width[1.3719374875750179, 24.224924317052928]\n",
      "test_width[1.0691528868297449, 20.578809827793602]\n",
      "smiles_weight0.7776267415774338\n",
      "rmse_train[0.2810306807203669, 5.65261829446897]\n",
      "rmse_test[1.0801356790280023, 16.26422513508495]\n",
      "smiles_weight_ci[0.6706444919749045, 0.8565030148684813]\n",
      "done for fold39\n",
      "train_width[1.2442774412318527, 19.946924569096574]\n",
      "test_width[0.779469206154539, 15.334346507182861]\n",
      "smiles_weight0.8018030550606751\n",
      "rmse_train[0.20959087403438026, 5.511612798395986]\n",
      "rmse_test[0.22783967677245492, 5.23865044438452]\n",
      "smiles_weight_ci[0.6920754286493772, 0.8829653119348903]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  39 out of  50 | elapsed: 14.6min remaining:  4.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold36\n",
      "train_width[0.9674797590968744, 17.542857220070886]\n",
      "test_width[0.6781859554147603, 14.892593320451024]\n",
      "smiles_weight0.7798365046160911\n",
      "rmse_train[0.19679677256922826, 4.208404570662663]\n",
      "rmse_test[0.36782070279830725, 5.3684928495994315]\n",
      "smiles_weight_ci[0.675671798226206, 0.861417387298091]\n",
      "done for fold37\n",
      "train_width[0.8434938027415355, 16.517200913016843]\n",
      "test_width[0.5901355130312427, 14.298565194530374]\n",
      "smiles_weight0.768124069687399\n",
      "rmse_train[0.17797303810745257, 3.7383011443964085]\n",
      "rmse_test[0.2214868584413996, 3.6825718538145127]\n",
      "smiles_weight_ci[0.6590372482203521, 0.843930618711745]\n",
      "done for fold42\n",
      "train_width[1.128156109341176, 20.205942403890734]\n",
      "test_width[0.782438074165966, 15.567797453542905]\n",
      "smiles_weight0.7663456046358178\n",
      "rmse_train[0.21446015389716114, 5.253212770531536]\n",
      "rmse_test[0.23047129918097392, 4.447073057995823]\n",
      "smiles_weight_ci[0.6293893606025084, 0.8440999769199092]\n",
      "done for fold38\n",
      "train_width[1.0365278412796615, 16.231254660297786]\n",
      "test_width[0.5174143009687313, 11.787143344048097]\n",
      "smiles_weight0.7710652054394256\n",
      "rmse_train[0.17273060744321656, 3.9134325134293557]\n",
      "rmse_test[0.22055744270982938, 3.9061742269846844]\n",
      "smiles_weight_ci[0.6414306987694143, 0.8553000541500736]\n",
      "done for fold43\n",
      "train_width[1.0344060825286796, 21.066767841552096]\n",
      "test_width[0.78607512767705, 17.065830140878806]\n",
      "smiles_weight0.7493989289320735\n",
      "rmse_train[0.19851585425448667, 5.505682199278397]\n",
      "rmse_test[0.23573197624949954, 4.853005008709364]\n",
      "smiles_weight_ci[0.621651943950724, 0.8422794195022304]\n",
      "done for fold44\n",
      "train_width[0.9988610510804482, 23.26006141070666]\n",
      "test_width[0.8242880311520454, 20.335805975391928]\n",
      "smiles_weight0.6853911538632589\n",
      "rmse_train[0.19700893669956354, 5.6532186399511755]\n",
      "rmse_test[0.20285151755751868, 5.3433078462761285]\n",
      "smiles_weight_ci[0.5718164315957311, 0.7770201250479112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  45 out of  50 | elapsed: 15.5min remaining:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for fold46\n",
      "train_width[1.0517779694415559, 19.97656473766907]\n",
      "test_width[0.7718698525483283, 17.025558820842768]\n",
      "smiles_weight0.7497137281128665\n",
      "rmse_train[0.20855255945574921, 4.776260312860472]\n",
      "rmse_test[0.17285157688143113, 3.8279938820086006]\n",
      "smiles_weight_ci[0.6060602775730572, 0.8371752036207404]\n",
      "done for fold47\n",
      "train_width[1.2665098350996296, 23.06101673490192]\n",
      "test_width[0.9211068864642971, 19.07214197347718]\n",
      "smiles_weight0.7648178927081588\n",
      "rmse_train[0.2170355891782304, 5.583943552050668]\n",
      "rmse_test[0.441329842948549, 23.475718609809732]\n",
      "smiles_weight_ci[0.6409832875951731, 0.847354446133436]\n",
      "done for fold49\n",
      "train_width[1.0436640583701828, 22.048658867018954]\n",
      "test_width[0.8737650524015557, 19.3769923282389]\n",
      "smiles_weight0.667033457469279\n",
      "rmse_train[0.28053562037042296, 5.92496420005376]\n",
      "rmse_test[0.2541233192524328, 5.089699162996322]\n",
      "smiles_weight_ci[0.5648400154823114, 0.7702158964837837]\n",
      "done for fold48\n",
      "train_width[1.092268411513275, 23.355135899425946]\n",
      "test_width[0.9918003380221719, 21.461779168939632]\n",
      "smiles_weight0.6651877662349671\n",
      "rmse_train[0.2654202424809643, 5.632602054385376]\n",
      "rmse_test[0.2857748342481328, 5.728843914712466]\n",
      "smiles_weight_ci[0.5631589323306452, 0.7510488779241586]\n",
      "done for fold45\n",
      "train_width[0.8215917769846547, 16.227098680893636]\n",
      "test_width[0.6512974134824778, 15.081494881473807]\n",
      "smiles_weight0.7701746603389357\n",
      "rmse_train[0.17626079528530003, 4.332186498345833]\n",
      "rmse_test[0.3133662115890396, 7.435592444676934]\n",
      "smiles_weight_ci[0.6608764612705085, 0.842888020789058]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=15)]: Done  50 out of  50 | elapsed: 17.5min finished\n"
     ]
    }
   ],
   "source": [
    "catch_all = Parallel(n_jobs = 15, verbose = 10)(delayed(get_results)(idx,var_weights = 1.0, var_weight_weights = 2.0, inflation_factor =1.0, fudging_beta = beta(1,11)) for idx in range(0,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1f857358-e5f0-4d43-bf0a-d4d7d034cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3ee2282b-2100-4ed9-972b-ea78eabe2447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_all[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "857dc418-a018-4330-868a-47ae36a9f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catch_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1e456d98-c381-450b-964d-fdbdbd1bd45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_catch = []\n",
    "for item in catch_all:\n",
    "    catch_inner = []\n",
    "    for inner in item:\n",
    "        if type(inner) == list:\n",
    "            for inner1 in inner:\n",
    "                catch_inner.append(inner1)\n",
    "        if type(inner) != list:\n",
    "            catch_inner.append(inner)\n",
    "    all_catch.append(catch_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b17ec0ba-5448-4130-b54f-c8cf20f76128",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(all_catch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "21f8792e-1721-412d-a84e-39bf7ad3c070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 15)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "610306d1-f54e-42be-86c2-70ef6d4fdd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6accc813-8aa7-48a0-abae-f89b6e5f5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.iloc[:,-1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "81b223ac-16c3-4547-bb99-9a2e08bbb03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"Alop_Train_Width\", \"PSA_Train_Width\", \"Alop_Train_Coverage\", \"PSA_Train_Coverage\", \n",
    "            \"Alop_Train_RMSE\", \"PSA_Train_RMSE\", \"Alop_Test_Width\", \"PSA_Test_Width\", \"Alop_Test_Coverage\", \"PSA_Test_Coverage\", \n",
    "            \"Alop_Test_RMSE\", \"PSA_Test_RMSE\", \"Smiles_Avg_Weight\", \"Lower_Interval_Smiles_Weight\", \"Upper_Interval_Smiles_Weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1124c374-99bf-4282-9e32-1074a5033ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8e52823b-19de-4bed-ae04-519af1d5021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.columns = col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a4fd350f-4f0a-4f9a-af19-52590d875782",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"indicator\"] = (results_df[\"Lower_Interval_Smiles_Weight\"].values < 0.70) & (results_df[\"Upper_Interval_Smiles_Weight\"].values >= 0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5b5283a6-b5f6-4752-a693-9b1dea85ba9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(results_df[\"indicator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b0ebc74a-b0e3-4cb5-8d3f-b2acb6040353",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\"width_weight_CI\"] = results_df[\"Upper_Interval_Smiles_Weight\"].values - results_df[\"Lower_Interval_Smiles_Weight\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f36d6343-cfa2-475d-a8dd-01007676f993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alop_Train_Width</td>\n",
       "      <td>1.111646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PSA_Train_Width</td>\n",
       "      <td>21.663270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alop_Train_Coverage</td>\n",
       "      <td>0.964951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PSA_Train_Coverage</td>\n",
       "      <td>0.952378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alop_Train_RMSE</td>\n",
       "      <td>0.230081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PSA_Train_RMSE</td>\n",
       "      <td>5.203101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alop_Test_Width</td>\n",
       "      <td>0.825925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PSA_Test_Width</td>\n",
       "      <td>17.975331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alop_Test_Coverage</td>\n",
       "      <td>0.914667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PSA_Test_Coverage</td>\n",
       "      <td>0.936750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alop_Test_RMSE</td>\n",
       "      <td>0.292086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PSA_Test_RMSE</td>\n",
       "      <td>5.945968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Smiles_Avg_Weight</td>\n",
       "      <td>0.754719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lower_Interval_Smiles_Weight</td>\n",
       "      <td>0.637944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Upper_Interval_Smiles_Weight</td>\n",
       "      <td>0.837148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>indicator</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>width_weight_CI</td>\n",
       "      <td>0.199204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           index          0\n",
       "0               Alop_Train_Width   1.111646\n",
       "1                PSA_Train_Width  21.663270\n",
       "2            Alop_Train_Coverage   0.964951\n",
       "3             PSA_Train_Coverage   0.952378\n",
       "4                Alop_Train_RMSE   0.230081\n",
       "5                 PSA_Train_RMSE   5.203101\n",
       "6                Alop_Test_Width   0.825925\n",
       "7                 PSA_Test_Width  17.975331\n",
       "8             Alop_Test_Coverage   0.914667\n",
       "9              PSA_Test_Coverage   0.936750\n",
       "10                Alop_Test_RMSE   0.292086\n",
       "11                 PSA_Test_RMSE   5.945968\n",
       "12             Smiles_Avg_Weight   0.754719\n",
       "13  Lower_Interval_Smiles_Weight   0.637944\n",
       "14  Upper_Interval_Smiles_Weight   0.837148\n",
       "15                     indicator   0.960000\n",
       "16               width_weight_CI   0.199204"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0636ac66-6077-4a54-9423-542338c64072",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"..//Data//smiles_rdkit_70_30__with_cov_minus_0.27_Simulation_added_beat_noise.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b6a2dba8-e55c-4931-94e5-b50375e7abf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alop_Train_Width</th>\n",
       "      <th>PSA_Train_Width</th>\n",
       "      <th>Alop_Train_Coverage</th>\n",
       "      <th>PSA_Train_Coverage</th>\n",
       "      <th>Alop_Train_RMSE</th>\n",
       "      <th>PSA_Train_RMSE</th>\n",
       "      <th>Alop_Test_Width</th>\n",
       "      <th>PSA_Test_Width</th>\n",
       "      <th>Alop_Test_Coverage</th>\n",
       "      <th>PSA_Test_Coverage</th>\n",
       "      <th>Alop_Test_RMSE</th>\n",
       "      <th>PSA_Test_RMSE</th>\n",
       "      <th>Smiles_Avg_Weight</th>\n",
       "      <th>Lower_Interval_Smiles_Weight</th>\n",
       "      <th>Upper_Interval_Smiles_Weight</th>\n",
       "      <th>indicator</th>\n",
       "      <th>width_weight_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.935137</td>\n",
       "      <td>18.010359</td>\n",
       "      <td>0.965229</td>\n",
       "      <td>0.938804</td>\n",
       "      <td>0.180402</td>\n",
       "      <td>4.678052</td>\n",
       "      <td>0.558646</td>\n",
       "      <td>13.604550</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.954167</td>\n",
       "      <td>0.285038</td>\n",
       "      <td>5.310596</td>\n",
       "      <td>0.828206</td>\n",
       "      <td>0.716430</td>\n",
       "      <td>0.898162</td>\n",
       "      <td>False</td>\n",
       "      <td>0.181732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.290059</td>\n",
       "      <td>23.251593</td>\n",
       "      <td>0.954103</td>\n",
       "      <td>0.952712</td>\n",
       "      <td>0.253759</td>\n",
       "      <td>5.577591</td>\n",
       "      <td>0.892806</td>\n",
       "      <td>19.112149</td>\n",
       "      <td>0.829167</td>\n",
       "      <td>0.954167</td>\n",
       "      <td>0.329320</td>\n",
       "      <td>8.647240</td>\n",
       "      <td>0.833305</td>\n",
       "      <td>0.732208</td>\n",
       "      <td>0.911026</td>\n",
       "      <td>False</td>\n",
       "      <td>0.178817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Alop_Train_Width  PSA_Train_Width  Alop_Train_Coverage  \\\n",
       "18          0.935137        18.010359             0.965229   \n",
       "26          1.290059        23.251593             0.954103   \n",
       "\n",
       "    PSA_Train_Coverage  Alop_Train_RMSE  PSA_Train_RMSE  Alop_Test_Width  \\\n",
       "18            0.938804         0.180402        4.678052         0.558646   \n",
       "26            0.952712         0.253759        5.577591         0.892806   \n",
       "\n",
       "    PSA_Test_Width  Alop_Test_Coverage  PSA_Test_Coverage  Alop_Test_RMSE  \\\n",
       "18       13.604550            0.712500           0.954167        0.285038   \n",
       "26       19.112149            0.829167           0.954167        0.329320   \n",
       "\n",
       "    PSA_Test_RMSE  Smiles_Avg_Weight  Lower_Interval_Smiles_Weight  \\\n",
       "18       5.310596           0.828206                      0.716430   \n",
       "26       8.647240           0.833305                      0.732208   \n",
       "\n",
       "    Upper_Interval_Smiles_Weight  indicator  width_weight_CI  \n",
       "18                      0.898162      False         0.181732  \n",
       "26                      0.911026      False         0.178817  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df[\"indicator\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "747d11c8-4f75-4ec9-aacc-930747d74047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5cb7839f-ac6e-4930-85ec-e58da91ec1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
